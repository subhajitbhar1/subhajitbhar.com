{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Subhajit Bhar","text":"Hi! I'm Subhajit  <p>Freelance LLM Engineer specializing in Document AI</p> <p>Currently based in the United Kingdom \ud83c\uddec\ud83c\udde7, I work with small and medium-sized businesses in finance, e-commerce, and consultancy across the UK, Europe, and the United States.</p> <p>I help small and medium-sized businesses to resolve document processing bottlenecks by building document processing pipelines using LLMs from various complex PDFs such as invoices, reports, contracts and other documents. My systems replace manual data entry and brittle rule-based approaches with intelligent, production-ready pipelines that include schema validation, guardrails, retry logic, and API endpoints \u2014 delivering complete solutions, not merely models.</p> <p>Book a consultation to discuss your requirements here.</p>"},{"location":"#latest-projects","title":"Latest Projects","text":""},{"location":"#llm-augmented-pdf-data-extraction-pipeline","title":"LLM-Augmented PDF Data Extraction Pipeline","text":"<p>LLM-augmented PDF extraction pipeline that slashed manual data entry by 95% through dual-LLM validation and OpenAI-powered intelligent parsing. Continue reading...</p>"},{"location":"testimonials/","title":"Testimonials","text":"<p>Verification</p> <p>All testimonials are verifiable on my Upwork profile.</p> <p>Client on Upwork</p> <p>Subhajit's professionalism, meticulous attention to detail, and expert handling of our project were apparent from the outset. The results delivered were truly exceptional. Communication was consistently seamless, and Subhajit was always receptive to feedback, making adjustments promptly when required. I wholeheartedly recommend Subhajit to anyone in search of premium freelance services.</p>"},{"location":"blogs/","title":"Blogs","text":"<p>Knowledge Base</p> <p>A growing collection of Python, ML, and data science notes to help you prepare for technical interviews can be found here</p>"},{"location":"blogs/tags/","title":"Tags","text":""},{"location":"blogs/tags/#tag:api","title":"API","text":"<ul> <li>            Beginners Guide to Building and Securing APIs          </li> <li>            Designing Secure and Scalable APIs \u2014 A Comprehensive Guide          </li> </ul>"},{"location":"blogs/tags/#tag:automation","title":"Automation","text":"<ul> <li>            Ruff: Modern Python Linter &amp; Formatter Walkthrough          </li> </ul>"},{"location":"blogs/tags/#tag:cicd","title":"CI/CD","text":"<ul> <li>            How you can set up a Python Code Quality CI Pipeline in 5 minutes          </li> <li>            Ruff: Modern Python Linter &amp; Formatter Walkthrough          </li> </ul>"},{"location":"blogs/tags/#tag:devops","title":"DevOps","text":"<ul> <li>            Git &amp; GitHub: The Definitive Version Control Guide          </li> <li>            Git 101 \u2013 Commands and Workflows Cheat Sheet          </li> <li>            How you can set up a Python Code Quality CI Pipeline in 5 minutes          </li> </ul>"},{"location":"blogs/tags/#tag:document-ai","title":"Document AI","text":"<ul> <li>            Document Summarization: Eval First          </li> <li>            RAG for Knowledge-Intensive Tasks          </li> </ul>"},{"location":"blogs/tags/#tag:embeddings","title":"Embeddings","text":"<ul> <li>            RAG for Knowledge-Intensive Tasks          </li> <li>            RAG with LangChain: Architecture, Code, and Metrics          </li> </ul>"},{"location":"blogs/tags/#tag:fastapi","title":"FastAPI","text":"<ul> <li>            Beginners Guide to Building and Securing APIs          </li> <li>            Designing Secure and Scalable APIs \u2014 A Comprehensive Guide          </li> </ul>"},{"location":"blogs/tags/#tag:git","title":"Git","text":"<ul> <li>            Git &amp; GitHub: The Definitive Version Control Guide          </li> <li>            Git 101 \u2013 Commands and Workflows Cheat Sheet          </li> </ul>"},{"location":"blogs/tags/#tag:github","title":"GitHub","text":"<ul> <li>            Git &amp; GitHub: The Definitive Version Control Guide          </li> </ul>"},{"location":"blogs/tags/#tag:langchain","title":"LangChain","text":"<ul> <li>            LightRAG as a LangChain Retriever          </li> <li>            RAG with LangChain: Architecture, Code, and Metrics          </li> </ul>"},{"location":"blogs/tags/#tag:lightrag","title":"LightRAG","text":"<ul> <li>            BM25 Hybrid Search with LightRAG          </li> <li>            LightRAG as a LangChain Retriever          </li> <li>            LightRAG: Lean RAG with Benchmarks          </li> </ul>"},{"location":"blogs/tags/#tag:nlp","title":"NLP","text":"<ul> <li>            Document Summarization: Eval First          </li> <li>            NLP Entity Matching with Fuzzy Search          </li> </ul>"},{"location":"blogs/tags/#tag:numpy","title":"Numpy","text":"<ul> <li>            Detect and Remove Outliers in Python: IQR and Z-Score          </li> <li>            Difference between reshape() and flatten() in NumPy          </li> </ul>"},{"location":"blogs/tags/#tag:pandas","title":"Pandas","text":"<ul> <li>            Detect and Remove Outliers in Python: IQR and Z-Score          </li> <li>            Handle Missing Values in Pandas Without Losing Information          </li> </ul>"},{"location":"blogs/tags/#tag:rag","title":"RAG","text":"<ul> <li>            BM25 Hybrid Search with LightRAG          </li> <li>            LightRAG as a LangChain Retriever          </li> <li>            LightRAG: Lean RAG with Benchmarks          </li> <li>            RAG for Knowledge-Intensive Tasks          </li> <li>            RAG with LangChain: Architecture, Code, and Metrics          </li> </ul>"},{"location":"blogs/tags/#tag:retrival","title":"Retrival","text":"<ul> <li>            BM25 Hybrid Search with LightRAG          </li> <li>            LightRAG as a LangChain Retriever          </li> <li>            RAG for Knowledge-Intensive Tasks          </li> <li>            RAG with LangChain: Architecture, Code, and Metrics          </li> </ul>"},{"location":"blogs/tags/#tag:ruff","title":"Ruff","text":"<ul> <li>            How you can set up a Python Code Quality CI Pipeline in 5 minutes          </li> <li>            Ruff: Modern Python Linter &amp; Formatter Walkthrough          </li> </ul>"},{"location":"blogs/tags/#tag:scikit-learn","title":"Scikit-learn","text":"<ul> <li>            Detect and Remove Outliers in Python: IQR and Z-Score          </li> </ul>"},{"location":"blogs/tags/#tag:system-design","title":"System Design","text":"<ul> <li>            Designing Secure and Scalable APIs \u2014 A Comprehensive Guide          </li> <li>            System Architecture \u2014 A Comprehensive, Practical Guide          </li> </ul>"},{"location":"blogs/tags/#stay-updated","title":"Stay Updated","text":"<p>Join my newsletter for the latest insights on Document AI, RAG, and LLM technologies:</p>"},{"location":"blogs/tags/#share-this-post","title":"Share This Post","text":"<p>Share on  Share on </p>"},{"location":"blogs/On-Page-SEO-vs-Off-Page-SEO/","title":"On-Page SEO vs Off-Page SEO","text":"<p>Search engine optimization (SEO) is built on two fundamental pillars: on-page and off-page optimization. While both are essential for ranking success, they work in distinctly different ways.</p>"},{"location":"blogs/On-Page-SEO-vs-Off-Page-SEO/#on-page-seo-optimizing-your-content","title":"On-Page SEO: Optimizing Your Content","text":"<p>On-page SEO focuses on elements you can control directly on your website. This includes optimizing your content, HTML tags, and technical structure.</p> <p>Key components:</p> <ul> <li>Title tags and meta descriptions</li> <li>Header tags (H1, H2, H3)</li> <li>Keyword optimization and content quality</li> <li>Internal linking structure</li> <li>Page loading speed</li> <li>Mobile responsiveness</li> <li>URL structure</li> </ul>"},{"location":"blogs/On-Page-SEO-vs-Off-Page-SEO/#off-page-seo-building-authority","title":"Off-Page SEO: Building Authority","text":"<p>Off-page SEO involves activities outside your website that influence your search rankings. It\u2019s primarily about building trust and authority through external signals.</p> <p>Key components:</p> <ul> <li>Backlinks from other websites</li> <li>Social media engagement</li> <li>Brand mentions and citations</li> <li>Guest posting</li> <li>Online reviews and ratings</li> <li>Local SEO signals (for local businesses)</li> </ul>"},{"location":"blogs/On-Page-SEO-vs-Off-Page-SEO/#the-bottom-line","title":"The Bottom Line","text":"<p>On-page SEO is your foundation \u2013 ensuring your site is optimized for both users and search engines. Off-page SEO is your reputation \u2013 proving to search engines that others trust and value your content.</p>"},{"location":"blogs/On-Page-SEO-vs-Off-Page-SEO/#both-strategies-work-together-strong-on-page-optimization-makes-your-content-worthy-of-external-links-while-quality-backlinks-amplify-your-on-page-efforts-success-requires-balancing-both-approaches-for-maximum-impact","title":"Both strategies work together. Strong on-page optimization makes your content worthy of external links, while quality backlinks amplify your on-page efforts. Success requires balancing both approaches for maximum impact.","text":""},{"location":"blogs/On-Page-SEO-vs-Off-Page-SEO/#stay-updated","title":"Stay Updated","text":"<p>Join my newsletter for the latest insights on Document AI, RAG, and LLM technologies:</p>"},{"location":"blogs/On-Page-SEO-vs-Off-Page-SEO/#share-this-post","title":"Share This Post","text":"<p>Share on  Share on </p>"},{"location":"blogs/api-101-beginner-guide/","title":"Beginners Guide to Building and Securing APIs","text":"<p>New to APIs? This guide explains core concepts in clear language, then walks you through building a small FastAPI service with essential security and testing tips. When you\u2019re ready for advanced patterns, read the companion: Designing Secure and Scalable APIs \u2014 A Comprehensive Guide.</p>","tags":["API","FastAPI"]},{"location":"blogs/api-101-beginner-guide/#what-is-an-api","title":"What Is an API?","text":"<p>An API is a contract for software to talk to software. It defines how to request data or perform actions using a consistent format over HTTP.</p>","tags":["API","FastAPI"]},{"location":"blogs/api-101-beginner-guide/#rest-vs-graphql-vs-rpc-high-level","title":"REST vs GraphQL vs RPC (High Level)","text":"<ul> <li>REST: resources (like <code>users</code>, <code>orders</code>) accessed via URLs and HTTP methods.</li> <li>GraphQL: clients ask for exactly the fields they need in a single endpoint.</li> <li>RPC/gRPC: function-style calls for service-to-service, very fast.</li> </ul> <p>For beginners, start with REST.</p>","tags":["API","FastAPI"]},{"location":"blogs/api-101-beginner-guide/#http-essentials-in-2-minutes","title":"HTTP Essentials in 2 Minutes","text":"<ul> <li>Methods: <code>GET</code> (read), <code>POST</code> (create), <code>PATCH</code> (update), <code>DELETE</code> (remove).</li> <li>URLs: <code>https://api.example.com/v1/items/123</code>.</li> <li>Headers: metadata like <code>Authorization</code>, <code>Content-Type</code>.</li> <li>Status codes: 2xx success, 4xx client errors, 5xx server errors.</li> <li>JSON: common data format: <code>{ \"name\": \"Notebook\", \"price\": 9.99 }</code>.</li> </ul>","tags":["API","FastAPI"]},{"location":"blogs/api-101-beginner-guide/#a-minimal-fastapi-service","title":"A Minimal FastAPI Service","text":"<pre><code>from typing import Optional\nfrom fastapi import FastAPI, HTTPException\nfrom pydantic import BaseModel, Field\n\napp = FastAPI(title=\"API 101\", version=\"1.0.0\")\n\nclass ItemIn(BaseModel):\n    name: str = Field(min_length=1, max_length=100)\n    price: float = Field(ge=0)\n    description: Optional[str] = Field(default=None, max_length=280)\n\nclass ItemOut(BaseModel):\n    id: str\n    name: str\n    price: float\n\nDB: dict[str, ItemOut] = {}\n\n@app.get(\"/v1/health\")\nasync def health() -&gt; dict:\n    return {\"status\": \"ok\"}\n\n@app.post(\"/v1/items\", response_model=ItemOut, status_code=201)\nasync def create_item(item: ItemIn) -&gt; ItemOut:\n    new_id = f\"it_{len(DB)+1}\"\n    output = ItemOut(id=new_id, name=item.name, price=item.price)\n    DB[new_id] = output\n    return output\n\n@app.get(\"/v1/items/{item_id}\", response_model=ItemOut)\nasync def get_item(item_id: str) -&gt; ItemOut:\n    if item_id not in DB:\n        raise HTTPException(status_code=404, detail=\"item_not_found\")\n    return DB[item_id]\n</code></pre>","tags":["API","FastAPI"]},{"location":"blogs/api-101-beginner-guide/#requestresponse-flow","title":"Request/Response Flow","text":"<pre><code>sequenceDiagram\n    autonumber\n    participant U as Client\n    participant A as FastAPI\n    participant D as In-memory DB\n    U-&gt;&gt;A: POST /v1/items { name, price }\n    A-&gt;&gt;A: Validate JSON (Pydantic)\n    A-&gt;&gt;D: Save item\n    D--&gt;&gt;A: OK\n    A--&gt;&gt;U: 201 Created + Item JSON</code></pre>","tags":["API","FastAPI"]},{"location":"blogs/api-101-beginner-guide/#input-validation-basics","title":"Input Validation Basics","text":"<ul> <li>Validate types and ranges (e.g., price &gt;= 0).</li> <li>Keep strings bounded (e.g., name &lt;= 100 chars).</li> <li>Return clear errors with <code>400</code>/<code>422</code> for invalid requests.</li> </ul>","tags":["API","FastAPI"]},{"location":"blogs/api-101-beginner-guide/#errors-youll-see-early","title":"Errors You\u2019ll See Early","text":"<ul> <li><code>400/422</code> when the body is malformed or fields fail validation.</li> <li><code>404</code> when an ID doesn\u2019t exist.</li> <li><code>405</code> when the method is wrong (e.g., <code>PUT</code> on a <code>GET</code> endpoint).</li> </ul>","tags":["API","FastAPI"]},{"location":"blogs/api-101-beginner-guide/#tiny-decision-tree","title":"Tiny Decision Tree","text":"<pre><code>flowchart TD\n    A[Request] --&gt; B{Valid input?}\n    B -- No --&gt; E[400/422]\n    B -- Yes --&gt; C{Resource exists?}\n    C -- No --&gt; F[404]\n    C -- Yes --&gt; D[2xx]</code></pre>","tags":["API","FastAPI"]},{"location":"blogs/api-101-beginner-guide/#auth-101-api-keys-vs-bearer-tokens","title":"Auth 101: API Keys vs Bearer Tokens","text":"<ul> <li>API Key: static secret string in header <code>X-API-Key</code>. Simple, rotate often.</li> <li>Bearer Token (JWT): signed token with claims (who you are, scopes). More flexible.</li> </ul> <pre><code>from fastapi import Header, Depends\n\ndef require_api_key(x_api_key: str = Header(alias=\"X-API-Key\")) -&gt; None:\n    if x_api_key != \"demo_secret\":\n        raise HTTPException(status_code=401, detail=\"invalid_api_key\")\n\n@app.get(\"/v1/private\", dependencies=[Depends(require_api_key)])\nasync def private_resource() -&gt; dict:\n    return {\"message\": \"authorized\"}\n</code></pre>","tags":["API","FastAPI"]},{"location":"blogs/api-101-beginner-guide/#cors-for-browser-apps","title":"CORS for Browser Apps","text":"<p>If your frontend runs on a different domain, enable CORS.</p> <pre><code>from fastapi.middleware.cors import CORSMiddleware\n\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"http://localhost:5173\", \"https://app.example.com\"],\n    allow_credentials=True,\n    allow_methods=[\"GET\", \"POST\", \"PATCH\", \"DELETE\"],\n    allow_headers=[\"Authorization\", \"Content-Type\", \"X-API-Key\"],\n)\n</code></pre>","tags":["API","FastAPI"]},{"location":"blogs/api-101-beginner-guide/#pagination-and-filtering-at-a-glance","title":"Pagination and Filtering (At a Glance)","text":"<ul> <li>Offset: <code>GET /v1/items?offset=0&amp;limit=20</code> \u2014 simple, good for small sets.</li> <li>Cursor: <code>GET /v1/items?cursor=abc&amp;limit=20</code> \u2014 better for changing data.</li> </ul>","tags":["API","FastAPI"]},{"location":"blogs/api-101-beginner-guide/#idempotency-why-it-matters","title":"Idempotency (Why It Matters)","text":"<p>If clients retry a <code>POST</code>, you don\u2019t want duplicate creations. Accept <code>X-Idempotency-Key</code> and reuse the original result for the same key.</p>","tags":["API","FastAPI"]},{"location":"blogs/api-101-beginner-guide/#rate-limiting-conceptual","title":"Rate Limiting (Conceptual)","text":"<p>Protect your API with per-user or per-IP limits. On limit exceeded, return <code>429</code> with <code>Retry-After</code> seconds.</p>","tags":["API","FastAPI"]},{"location":"blogs/api-101-beginner-guide/#testing-your-api","title":"Testing Your API","text":"<ul> <li><code>curl</code> quick checks, Postman/Insomnia for collections.</li> <li>Read logs and status codes; verify headers and JSON.</li> </ul>","tags":["API","FastAPI"]},{"location":"blogs/api-101-beginner-guide/#handy-curl-examples","title":"Handy curl Examples","text":"<pre><code>curl -i https://api.example.com/v1/health\ncurl -i -X POST https://api.example.com/v1/items \\\n  -H 'Content-Type: application/json' \\\n  -d '{\"name\":\"Pen\",\"price\":1.25}'\ncurl -i https://api.example.com/v1/items/it_1\n</code></pre>","tags":["API","FastAPI"]},{"location":"blogs/api-101-beginner-guide/#beginner-hardening-checklist","title":"Beginner Hardening Checklist","text":"<ul> <li>Validate all inputs with Pydantic.</li> <li>Set <code>Content-Type: application/json</code> in responses.</li> <li>Turn on CORS only for known origins.</li> <li>Use API keys or bearer tokens; never accept secrets in query strings.</li> <li>Add basic rate limiting and idempotency for writes.</li> <li>Log a <code>request_id</code> and include it in responses.</li> </ul>","tags":["API","FastAPI"]},{"location":"blogs/api-101-beginner-guide/#glossary","title":"Glossary","text":"<ul> <li>JWT: signed token proving identity and permissions.</li> <li>ETag: a version tag for caching and concurrency.</li> <li>CORS: browser rule for cross-origin requests.</li> <li>2xx/4xx/5xx: success/client/server status code families.</li> </ul>","tags":["API","FastAPI"]},{"location":"blogs/api-101-beginner-guide/#whats-next","title":"What\u2019s Next","text":"<p>Ready to go deeper? See the advanced guide for versioning, ETags, RBAC, rate limiting, webhooks security, observability, and more: Designing Secure and Scalable APIs \u2014 A Comprehensive Guide.</p>","tags":["API","FastAPI"]},{"location":"blogs/api-101-beginner-guide/#stay-updated","title":"Stay Updated","text":"<p>Join my newsletter for the latest insights on Document AI, RAG, and LLM technologies:</p>","tags":["API","FastAPI"]},{"location":"blogs/api-101-beginner-guide/#share-this-post","title":"Share This Post","text":"<p>Share on  Share on </p>","tags":["API","FastAPI"]},{"location":"blogs/secure-scalable-apis-guide/","title":"Designing Secure and Scalable APIs \u2014 A Comprehensive Guide","text":"<p>APIs are the connective tissue of modern products. This guide distills proven practices for API design, security, observability, and reliability\u2014covering the most frequent questions and edge cases teams face in production. Examples use FastAPI and Pydantic v2, but the principles generalize to any stack.</p>","tags":["API","FastAPI","System Design"]},{"location":"blogs/secure-scalable-apis-guide/#architecture-overview","title":"Architecture Overview","text":"<pre><code>sequenceDiagram\n    autonumber\n    participant Client\n    participant Gateway as API Gateway/WAF\n    participant API as FastAPI Service\n    participant Auth as Auth Service (JWT/OAuth2)\n    participant RL as Rate Limiter (Redis)\n    participant DB as Database\n\n    Client-&gt;&gt;Gateway: HTTPS request (+ headers)\n    Gateway-&gt;&gt;RL: Check quota + idempotency\n    RL--&gt;&gt;Gateway: Allowed/Denied\n    Gateway-&gt;&gt;API: Forward request\n    API-&gt;&gt;Auth: Validate token/scope\n    Auth--&gt;&gt;API: Claims\n    API-&gt;&gt;API: Validate input (Pydantic)\n    API-&gt;&gt;DB: Query/Write\n    DB--&gt;&gt;API: Data\n    API--&gt;&gt;Gateway: Response (+ ETag/Cache headers)\n    Gateway--&gt;&gt;Client: HTTPS response</code></pre>","tags":["API","FastAPI","System Design"]},{"location":"blogs/secure-scalable-apis-guide/#design-principles","title":"Design Principles","text":"<ul> <li>Clarity over cleverness: predictable URLs, consistent verbs, stable contracts.</li> <li>Backward compatibility: versioning and additive changes; deprecate before removal.</li> <li>Idempotency: safe retries for non-GET operations.</li> <li>Least privilege: scope- and role-based access; tenant isolation.</li> <li>Defense in depth: TLS everywhere, input validation, WAF, rate limiting.</li> <li>Observability by default: correlation IDs, structured logs, metrics, traces.</li> </ul>","tags":["API","FastAPI","System Design"]},{"location":"blogs/secure-scalable-apis-guide/#rest-vs-graphql-vs-grpc","title":"REST vs GraphQL vs gRPC","text":"<ul> <li>REST: simple, cache-friendly, great for public APIs; expressive with query params and headers.</li> <li>GraphQL: flexible querying; beware N+1, authorization at field-level, and cost limits.</li> <li>gRPC: high-performance binary protocol; strong contracts with Protobuf; great for service-to-service.</li> </ul> <p>Pick based on clients, performance profile, and operability. Many orgs mix: REST externally, gRPC internally.</p>","tags":["API","FastAPI","System Design"]},{"location":"blogs/secure-scalable-apis-guide/#resource-modeling-and-urls","title":"Resource Modeling and URLs","text":"<ul> <li>Plural resources: <code>/users</code>, <code>/users/{user_id}</code>.</li> <li>Nesting when it clarifies ownership: <code>/projects/{id}/members</code>.</li> <li>Filtering, sorting, pagination via query params:</li> <li><code>GET /orders?status=shipped&amp;sort=-created_at&amp;limit=50&amp;cursor=...</code></li> <li>Partial responses: <code>fields=name,email</code> or <code>Prefer: return=representation</code>.</li> <li>Standard headers: <code>ETag</code>, <code>If-None-Match</code>, <code>If-Match</code>, <code>Cache-Control</code>.</li> </ul>","tags":["API","FastAPI","System Design"]},{"location":"blogs/secure-scalable-apis-guide/#versioning-strategy","title":"Versioning Strategy","text":"<ul> <li>URL-based: <code>/v1/...</code> for public APIs.</li> <li>Header-based: <code>Accept: application/vnd.example.v2+json</code> for internal APIs.</li> <li>Contract changes must be additive where possible. For breaking changes: run V1 and V2 concurrently; offer migration guides; set an end-of-life date.</li> </ul>","tags":["API","FastAPI","System Design"]},{"location":"blogs/secure-scalable-apis-guide/#error-handling-and-problem-details","title":"Error Handling and Problem Details","text":"<p>Use consistent error shapes and HTTP status codes.</p> <pre><code>{\n  \"type\": \"https://docs.example.com/errors/rate_limited\",\n  \"title\": \"Too Many Requests\",\n  \"status\": 429,\n  \"detail\": \"Try again in 12 seconds\",\n  \"instance\": \"req_01J8Z6...\",\n  \"extras\": {\"retry_after\": 12}\n}\n</code></pre> <p>Map business errors to appropriate statuses: 400 (validation), 401/403 (authz), 404 (not found), 409 (conflict), 422 (semantic validation), 429 (rate limit), 5xx (server).</p>","tags":["API","FastAPI","System Design"]},{"location":"blogs/secure-scalable-apis-guide/#validation-schemas-and-openapi-fastapi-pydantic-v2","title":"Validation, Schemas, and OpenAPI (FastAPI + Pydantic v2)","text":"<pre><code>from typing import Optional, Literal\nfrom fastapi import FastAPI, HTTPException, Header, Depends, status\nfrom pydantic import BaseModel, Field, field_validator\n\napp = FastAPI(title=\"Orders API\", version=\"1.0.0\")\n\nclass CreateOrder(BaseModel):\n    product_id: str = Field(min_length=1)\n    quantity: int = Field(gt=0, le=1000)\n    currency: Literal[\"USD\", \"EUR\", \"INR\"]\n    note: Optional[str] = Field(default=None, max_length=280)\n\n    @field_validator(\"product_id\")\n    @classmethod\n    def validate_product_id(cls, v: str) -&gt; str:\n        if not v.startswith(\"prod_\"):\n            raise ValueError(\"product_id must start with 'prod_'\")\n        return v\n\nclass Order(BaseModel):\n    id: str\n    status: Literal[\"pending\", \"confirmed\"]\n    etag: str\n\ndef require_idempotency_key(x_idempotency_key: Optional[str] = Header(default=None)) -&gt; str:\n    if not x_idempotency_key:\n        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=\"Missing X-Idempotency-Key\")\n    return x_idempotency_key\n\n@app.post(\"/v1/orders\", response_model=Order, status_code=status.HTTP_201_CREATED)\nasync def create_order(payload: CreateOrder, idemp_key: str = Depends(require_idempotency_key)) -&gt; Order:\n    # Pseudocode: check Redis for idempotency key; return stored response if exists\n    # save_idempotency(idemp_key, response_hash)\n    return Order(id=\"ord_123\", status=\"pending\", etag=\"W/\\\"abc123\\\"\")\n</code></pre>","tags":["API","FastAPI","System Design"]},{"location":"blogs/secure-scalable-apis-guide/#pagination-and-filtering","title":"Pagination and Filtering","text":"<ul> <li>Prefer cursor-based pagination for mutable datasets; offset-based for stable datasets.</li> <li>Include <code>Link</code> headers and <code>next_cursor</code> in body. Keep page sizes bounded.</li> </ul>","tags":["API","FastAPI","System Design"]},{"location":"blogs/secure-scalable-apis-guide/#concurrency-control-and-caching","title":"Concurrency Control and Caching","text":"<ul> <li>Use <code>ETag</code> with <code>If-Match</code> for optimistic concurrency updates.</li> <li>Use <code>ETag</code> with <code>If-None-Match</code> for conditional GETs to enable 304 responses.</li> <li>Set <code>Cache-Control</code> wisely; avoid caching personalized responses unless keyed by auth.</li> </ul> <pre><code>from fastapi import Request, Response\n\n@app.get(\"/v1/orders/{order_id}\")\nasync def get_order(order_id: str, request: Request) -&gt; Response:\n    etag = 'W/\"abc123\"'\n    if request.headers.get(\"if-none-match\") == etag:\n        return Response(status_code=304)\n    body = {\"id\": order_id, \"status\": \"confirmed\"}\n    return Response(content=app.openapi_json_dumps(body), media_type=\"application/json\", headers={\"ETag\": etag})\n</code></pre>","tags":["API","FastAPI","System Design"]},{"location":"blogs/secure-scalable-apis-guide/#authentication-and-authorization","title":"Authentication and Authorization","text":"","tags":["API","FastAPI","System Design"]},{"location":"blogs/secure-scalable-apis-guide/#options","title":"Options","text":"<ul> <li>API Keys: simple, rotate often; restrict by IP/referrer; least privilege.</li> <li>OAuth2/JWT: bearer tokens with scopes (<code>read:orders</code>, <code>write:orders</code>). Verify signature, issuer, audience, expiry, and <code>nbf</code>.</li> <li>mTLS: strong service-to-service auth; pin certs; rotate.</li> </ul>","tags":["API","FastAPI","System Design"]},{"location":"blogs/secure-scalable-apis-guide/#scope-and-role-based-access","title":"Scope- and Role-based Access","text":"<pre><code>from typing import List\nfrom fastapi import Security\nfrom fastapi.security import HTTPAuthorizationCredentials, HTTPBearer\n\nbearer = HTTPBearer(auto_error=True)\n\ndef verify_jwt_and_scopes(creds: HTTPAuthorizationCredentials = Security(bearer), required_scopes: List[str] = []) -&gt; dict:\n    token = creds.credentials\n    # Pseudocode: decode and validate token (iss, aud, exp, nbf) and scopes\n    claims = {\"sub\": \"user_1\", \"scopes\": [\"read:orders\", \"write:orders\"], \"tenant\": \"acme\"}\n    if not set(required_scopes).issubset(set(claims[\"scopes\"])):\n        raise HTTPException(status_code=403, detail=\"insufficient_scope\")\n    return claims\n\n@app.get(\"/v1/orders\", dependencies=[Depends(lambda: verify_jwt_and_scopes(required_scopes=[\"read:orders\"]))])\nasync def list_orders() -&gt; dict:\n    return {\"data\": []}\n</code></pre>","tags":["API","FastAPI","System Design"]},{"location":"blogs/secure-scalable-apis-guide/#multi-tenant-isolation","title":"Multi-tenant Isolation","text":"<ul> <li>Include a <code>tenant_id</code> claim and enforce it in every query.</li> <li>Use row-level security (RLS) in the database; never trust the client to filter tenants.</li> </ul>","tags":["API","FastAPI","System Design"]},{"location":"blogs/secure-scalable-apis-guide/#input-hardening-and-output-encoding","title":"Input Hardening and Output Encoding","text":"<ul> <li>Validate types, ranges, and formats with Pydantic; reject unknown fields.</li> <li>Enforce maximum sizes: body, arrays, strings. Limit uploaded file size and type.</li> <li>Normalize Unicode and strip control characters when relevant.</li> <li>Always JSON-encode responses and set <code>Content-Type: application/json; charset=utf-8</code>.</li> </ul>","tags":["API","FastAPI","System Design"]},{"location":"blogs/secure-scalable-apis-guide/#rate-limiting-and-abuse-protection","title":"Rate Limiting and Abuse Protection","text":"<ul> <li>Combine IP + user + token keys. Separate read/write limits.</li> <li>Use sliding window + burst; add Retry-After headers.</li> </ul> <pre><code>import time\nimport hashlib\n\nFAKE_BUCKET: dict[str, list[float]] = {}\n\ndef rate_limit(key: str, limit: int, window_seconds: int = 60) -&gt; None:\n    now = time.time()\n    bucket = FAKE_BUCKET.setdefault(key, [])\n    FAKE_BUCKET[key] = [t for t in bucket if t &gt; now - window_seconds]\n    if len(FAKE_BUCKET[key]) &gt;= limit:\n        raise HTTPException(status_code=429, detail=\"rate_limited\")\n    FAKE_BUCKET[key].append(now)\n\n@app.post(\"/v1/orders/confirm\")\nasync def confirm_order() -&gt; dict:\n    key = hashlib.sha256(b\"anonymous\").hexdigest()\n    rate_limit(key, limit=5, window_seconds=60)\n    return {\"status\": \"ok\"}\n</code></pre>","tags":["API","FastAPI","System Design"]},{"location":"blogs/secure-scalable-apis-guide/#webhooks-security","title":"Webhooks Security","text":"<ul> <li>Sign payloads with an HMAC shared secret; include timestamp to prevent replay.</li> <li>Verify using constant-time comparison.</li> </ul> <pre><code>import hmac, hashlib\nfrom fastapi import Request\n\ndef verify_webhook_signature(request: Request, secret: str) -&gt; None:\n    signature = request.headers.get(\"x-signature\")\n    timestamp = request.headers.get(\"x-timestamp\")\n    if not signature or not timestamp:\n        raise HTTPException(status_code=400, detail=\"missing_signature\")\n    payload = (timestamp + \".\" + (request._body.decode() if hasattr(request, \"_body\") else \"\")).encode()\n    expected = hmac.new(secret.encode(), payload, hashlib.sha256).hexdigest()\n    if not hmac.compare_digest(signature, expected):\n        raise HTTPException(status_code=401, detail=\"invalid_signature\")\n</code></pre>","tags":["API","FastAPI","System Design"]},{"location":"blogs/secure-scalable-apis-guide/#transport-security-tls-and-headers","title":"Transport Security (TLS) and Headers","text":"<ul> <li>Enforce TLS 1.2+; prefer TLS 1.3; disable weak ciphers.</li> <li>HSTS (<code>Strict-Transport-Security</code>), <code>X-Content-Type-Options: nosniff</code>, <code>Referrer-Policy: no-referrer</code>, <code>Content-Security-Policy</code> for portals.</li> <li>Enable <code>gzip/br</code> compression; negotiate via <code>Accept-Encoding</code>.</li> </ul>","tags":["API","FastAPI","System Design"]},{"location":"blogs/secure-scalable-apis-guide/#cors-and-csrf","title":"CORS and CSRF","text":"<p>For browser clients, configure CORS precisely; use CSRF tokens for cookie-based sessions.</p> <pre><code>from fastapi.middleware.cors import CORSMiddleware\n\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"https://app.example.com\"],\n    allow_credentials=True,\n    allow_methods=[\"GET\", \"POST\", \"PATCH\", \"DELETE\"],\n    allow_headers=[\"Authorization\", \"Content-Type\", \"X-Idempotency-Key\"],\n)\n</code></pre>","tags":["API","FastAPI","System Design"]},{"location":"blogs/secure-scalable-apis-guide/#observability-logging-metrics-tracing","title":"Observability: Logging, Metrics, Tracing","text":"<ul> <li>Generate a <code>request_id</code> per request; include it in logs and responses.</li> <li>Emit structured JSON logs; include user, tenant, route, latency, status.</li> <li>Expose Prometheus metrics; instrument with OpenTelemetry for traces.</li> </ul> <pre><code>import uuid\nimport time\nfrom fastapi import Request\n\n@app.middleware(\"http\")\nasync def add_request_context(request: Request, call_next):\n    request_id = str(uuid.uuid4())\n    start = time.time()\n    response = await call_next(request)\n    response.headers[\"x-request-id\"] = request_id\n    response.headers[\"server-timing\"] = f\"app;dur={(time.time()-start)*1000:.1f}\"\n    return response\n</code></pre>","tags":["API","FastAPI","System Design"]},{"location":"blogs/secure-scalable-apis-guide/#reliability-timeouts-retries-circuit-breakers","title":"Reliability: Timeouts, Retries, Circuit Breakers","text":"<ul> <li>Server timeouts must be lower than client timeouts. Never block indefinitely.</li> <li>Retries only on idempotent operations; use exponential backoff + jitter.</li> <li>Circuit breakers to shed load and protect dependencies.</li> </ul>","tags":["API","FastAPI","System Design"]},{"location":"blogs/secure-scalable-apis-guide/#data-privacy-and-compliance","title":"Data Privacy and Compliance","text":"<ul> <li>Classify data (public/internal/confidential/PII). Encrypt at rest and in transit.</li> <li>Minimize logs; redact secrets and PII. Respect data residency.</li> <li>Provide data export and deletion endpoints where required (GDPR/CCPA).</li> </ul>","tags":["API","FastAPI","System Design"]},{"location":"blogs/secure-scalable-apis-guide/#change-management-and-deprecation","title":"Change Management and Deprecation","text":"<ul> <li>Communicate changes: changelog, email, and deprecation headers.</li> <li>Provide a sunset date and migration guide; support old and new versions in parallel.</li> </ul>","tags":["API","FastAPI","System Design"]},{"location":"blogs/secure-scalable-apis-guide/#testing-strategy","title":"Testing Strategy","text":"<ul> <li>Unit-test validators and authorization rules.</li> <li>Contract tests from OpenAPI; validate examples and <code>schemaFormat</code>.</li> <li>Load tests for hot paths; chaos experiments for failure modes.</li> </ul>","tags":["API","FastAPI","System Design"]},{"location":"blogs/secure-scalable-apis-guide/#deployment-topology-reference","title":"Deployment Topology (Reference)","text":"<pre><code>flowchart LR\n    A[Client] --&gt;|HTTPS| B(API Gateway/WAF)\n    B --&gt; C{Rate Limit}\n    C --&gt;|Allow| D(FastAPI Apps)\n    C --&gt;|Deny| E[(429)]\n    D --&gt; F[(Cache/CDN)]\n    D --&gt; G[(DB with RLS)]\n    D --&gt; H[Auth / OIDC]\n    D --&gt; I[Queue]\n    I --&gt; J[Workers]</code></pre>","tags":["API","FastAPI","System Design"]},{"location":"blogs/secure-scalable-apis-guide/#checklist-copypaste","title":"Checklist (Copy/Paste)","text":"<ul> <li>AuthN: JWT validated (iss, aud, exp, nbf), scopes enforced</li> <li>AuthZ: RBAC/ABAC, tenant isolation, RLS in DB</li> <li>Transport: TLS 1.2+, HSTS, secure headers, compression</li> <li>Input: strict schemas, size limits, allowlist validation</li> <li>Output: content-type set, ETag/Cache-Control</li> <li>Idempotency: keys for POST; retries safe</li> <li>Rate limiting: per-IP/user/token; 429 with Retry-After</li> <li>Observability: request_id, structured logs, traces, metrics</li> <li>Reliability: timeouts, backoff, circuit breakers</li> <li>Change mgmt: versioning, deprecation plan, migration docs</li> <li>Privacy: PII minimization/redaction, encryption at rest/in transit</li> </ul>","tags":["API","FastAPI","System Design"]},{"location":"blogs/secure-scalable-apis-guide/#faq-common-questions","title":"FAQ: Common Questions","text":"<ul> <li>\"Should I use UUIDs or integers for IDs?\" \u2192 UUIDv7 is a good default; avoid guessable IDs.</li> <li>\"One big endpoint or many small ones?\" \u2192 Model business resources; avoid RPC over HTTP unless using gRPC.</li> <li>\"When to break a monolith?\" \u2192 When independent scaling, deployment cadence, or ownership boundaries demand it.</li> <li>\"Do I need an API gateway?\" \u2192 Yes for public APIs (WAF, auth offload, rate limiting, routing). Internal-only can defer with service mesh.</li> <li>\"How do I prevent replay attacks?\" \u2192 Require idempotency keys and/or signed, timestamped requests; enforce short clock skew.</li> <li>\"What about GraphQL security?\" \u2192 Enforce query depth/complexity limits; field-level auth; persisted queries.</li> </ul>","tags":["API","FastAPI","System Design"]},{"location":"blogs/secure-scalable-apis-guide/#conclusion","title":"Conclusion","text":"<p>Great APIs are predictable, secure, and observable. Start with clear resource modeling, layer defenses, and instrument from day one. Iterate safely with versioning and robust test coverage. The practices above form a pragmatic baseline you can tailor to your domain.</p>","tags":["API","FastAPI","System Design"]},{"location":"blogs/secure-scalable-apis-guide/#stay-updated","title":"Stay Updated","text":"<p>Join my newsletter for the latest insights on Document AI, RAG, and LLM technologies:</p>","tags":["API","FastAPI","System Design"]},{"location":"blogs/secure-scalable-apis-guide/#share-this-post","title":"Share This Post","text":"<p>Share on  Share on </p>","tags":["API","FastAPI","System Design"]},{"location":"blogs/detect-remove-outliers-python-iqr-zscore/","title":"Detect and Remove Outliers in Python: IQR and Z-Score","text":"<p>Outliers can significantly skew statistical analysis and machine learning model performance. This guide covers statistical and machine learning methods to detect and handle outliers effectively in Python.</p>","tags":["Numpy","Pandas","Scikit-learn"]},{"location":"blogs/detect-remove-outliers-python-iqr-zscore/#what-are-outliers","title":"What Are Outliers","text":"<p>Outliers are data points that significantly differ from the majority of observations in a dataset. They can occur due to:</p> <ul> <li>Measurement errors</li> <li>Data entry mistakes</li> <li>Natural variation in the data</li> <li>Fraudulent activities</li> <li>Equipment malfunctions</li> </ul>","tags":["Numpy","Pandas","Scikit-learn"]},{"location":"blogs/detect-remove-outliers-python-iqr-zscore/#types-of-outliers","title":"Types of Outliers","text":"<ul> <li>1. Univariate Outliers Extreme values in a single variable.</li> <li>2. Multivariate Outliers Points that are outliers when considering multiple variables together.</li> <li>3. Contextual Outliers Values that are outliers in a specific context but normal in others.</li> </ul>","tags":["Numpy","Pandas","Scikit-learn"]},{"location":"blogs/detect-remove-outliers-python-iqr-zscore/#statistical-methods-for-outlier-detection","title":"Statistical Methods for Outlier Detection","text":"","tags":["Numpy","Pandas","Scikit-learn"]},{"location":"blogs/detect-remove-outliers-python-iqr-zscore/#1-z-score-method","title":"1. Z-Score Method","text":"<p>The Z-Score measures how many standard deviations a data point is from the mean.</p> <pre><code>import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\n\n# Create sample dataset\nnp.random.seed(42)\ndata = np.random.normal(100, 15, 1000)\n# Add some outliers\noutliers = np.array([200, 250, -50, -20])\ndata = np.concatenate([data, outliers])\n\ndf = pd.DataFrame({'values': data})\n\n# Calculate Z-scores\ndf['z_score'] = np.abs(stats.zscore(df['values']))\n\n# Define threshold (typically 2 or 3)\nthreshold = 3\ndf['is_outlier_zscore'] = df['z_score'] &gt; threshold\n\nprint(f\"Number of outliers detected: {df['is_outlier_zscore'].sum()}\")\nprint(f\"Outlier values: {df[df['is_outlier_zscore']]['values'].values}\")\n</code></pre>","tags":["Numpy","Pandas","Scikit-learn"]},{"location":"blogs/detect-remove-outliers-python-iqr-zscore/#2-interquartile-range-iqr-method","title":"2. Interquartile Range (IQR) Method","text":"<p>IQR method identifies outliers based on quartiles and is more robust to extreme values.</p> <pre><code>def detect_outliers_iqr(data, column):\n    \"\"\"Detect outliers using IQR method\"\"\"\n    Q1 = data[column].quantile(0.25)\n    Q3 = data[column].quantile(0.75)\n    IQR = Q3 - Q1\n\n    # Calculate bounds\n    lower_bound = Q1 - 1.5 * IQR\n    upper_bound = Q3 + 1.5 * IQR\n\n    # Identify outliers\n    outliers = data[(data[column] &lt; lower_bound) | (data[column] &gt; upper_bound)]\n\n    return outliers, lower_bound, upper_bound\n\n# Apply IQR method\noutliers_iqr, lower_bound, upper_bound = detect_outliers_iqr(df, 'values')\ndf['is_outlier_iqr'] = (df['values'] &lt; lower_bound) | (df['values'] &gt; upper_bound)\n\nprint(f\"IQR bounds: ({lower_bound:.2f}, {upper_bound:.2f})\")\nprint(f\"Number of outliers detected by IQR: {df['is_outlier_iqr'].sum()}\")\n</code></pre>","tags":["Numpy","Pandas","Scikit-learn"]},{"location":"blogs/detect-remove-outliers-python-iqr-zscore/#3-modified-z-score-mad","title":"3. Modified Z-Score (MAD)","text":"<p>More robust than standard Z-Score as it uses median instead of mean.</p> <pre><code>def modified_z_score(data):\n    \"\"\"Calculate modified Z-score using median absolute deviation\"\"\"\n    median = np.median(data)\n    mad = np.median(np.abs(data - median))\n    modified_z_scores = 0.6745 * (data - median) / mad\n    return np.abs(modified_z_scores)\n\n# Apply modified Z-score\ndf['modified_z_score'] = modified_z_score(df['values'])\nthreshold_mad = 3.5\ndf['is_outlier_mad'] = df['modified_z_score'] &gt; threshold_mad\n\nprint(f\"Number of outliers detected by MAD: {df['is_outlier_mad'].sum()}\")\n</code></pre>","tags":["Numpy","Pandas","Scikit-learn"]},{"location":"blogs/detect-remove-outliers-python-iqr-zscore/#machine-learning-methods-for-outlier-detection","title":"Machine Learning Methods for Outlier Detection","text":"","tags":["Numpy","Pandas","Scikit-learn"]},{"location":"blogs/detect-remove-outliers-python-iqr-zscore/#1-isolation-forest","title":"1. Isolation Forest","text":"<p>Isolation Forest isolates anomalies by randomly selecting features and split values.</p> <pre><code>from sklearn.ensemble import IsolationForest\n\n# Create multi-dimensional dataset for better demonstration\nnp.random.seed(42)\nX = np.random.multivariate_normal([50, 50], [[100, 10], [10, 100]], 1000)\n# Add outliers\nX_outliers = np.array([[200, 200], [-50, -50], [300, 50], [50, 300]])\nX = np.vstack([X, X_outliers])\n\ndf_multi = pd.DataFrame(X, columns=['feature1', 'feature2'])\n\n# Apply Isolation Forest\niso_forest = IsolationForest(contamination=0.1, random_state=42)\ndf_multi['outlier_scores'] = iso_forest.fit_predict(df_multi[['feature1', 'feature2']])\ndf_multi['is_outlier_isolation'] = df_multi['outlier_scores'] == -1\n\nprint(f\"Number of outliers detected by Isolation Forest: {df_multi['is_outlier_isolation'].sum()}\")\n</code></pre>","tags":["Numpy","Pandas","Scikit-learn"]},{"location":"blogs/detect-remove-outliers-python-iqr-zscore/#2-local-outlier-factor-lof","title":"2. Local Outlier Factor (LOF)","text":"<p>LOF measures local density deviation of a data point with respect to its neighbors.</p> <pre><code>from sklearn.neighbors import LocalOutlierFactor\n\n# Apply Local Outlier Factor\nlof = LocalOutlierFactor(n_neighbors=20, contamination=0.1)\noutlier_labels = lof.fit_predict(df_multi[['feature1', 'feature2']])\ndf_multi['is_outlier_lof'] = outlier_labels == -1\n\nprint(f\"Number of outliers detected by LOF: {df_multi['is_outlier_lof'].sum()}\")\n</code></pre>","tags":["Numpy","Pandas","Scikit-learn"]},{"location":"blogs/detect-remove-outliers-python-iqr-zscore/#3-one-class-svm","title":"3. One-Class SVM","text":"<p>One-Class SVM learns a decision function for novelty detection.</p> <pre><code>from sklearn.svm import OneClassSVM\n\n# Apply One-Class SVM\none_class_svm = OneClassSVM(nu=0.1, kernel=\"rbf\", gamma=0.1)\noutlier_labels = one_class_svm.fit_predict(df_multi[['feature1', 'feature2']])\ndf_multi['is_outlier_svm'] = outlier_labels == -1\n\nprint(f\"Number of outliers detected by One-Class SVM: {df_multi['is_outlier_svm'].sum()}\")\n</code></pre>","tags":["Numpy","Pandas","Scikit-learn"]},{"location":"blogs/detect-remove-outliers-python-iqr-zscore/#visualization-of-outliers","title":"Visualization of Outliers","text":"","tags":["Numpy","Pandas","Scikit-learn"]},{"location":"blogs/detect-remove-outliers-python-iqr-zscore/#1-box-plot-for-univariate-outliers","title":"1. Box Plot for Univariate Outliers","text":"<pre><code>plt.figure(figsize=(12, 4))\n\n# Box plot\nplt.subplot(1, 3, 1)\nplt.boxplot(df['values'])\nplt.title('Box Plot - Outlier Detection')\nplt.ylabel('Values')\n\n# Histogram with outliers highlighted\nplt.subplot(1, 3, 2)\nplt.hist(df[~df['is_outlier_iqr']]['values'], alpha=0.7, label='Normal', bins=30)\nplt.hist(df[df['is_outlier_iqr']]['values'], alpha=0.7, label='Outliers', bins=30)\nplt.title('Histogram with Outliers')\nplt.xlabel('Values')\nplt.ylabel('Frequency')\nplt.legend()\n\n# Z-score plot\nplt.subplot(1, 3, 3)\nplt.scatter(range(len(df)), df['z_score'], alpha=0.6)\nplt.axhline(y=3, color='r', linestyle='--', label='Threshold (Z=3)')\nplt.title('Z-Score Plot')\nplt.xlabel('Data Point Index')\nplt.ylabel('Z-Score')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n</code></pre>","tags":["Numpy","Pandas","Scikit-learn"]},{"location":"blogs/detect-remove-outliers-python-iqr-zscore/#2-scatter-plot-for-multivariate-outliers","title":"2. Scatter Plot for Multivariate Outliers","text":"<pre><code>plt.figure(figsize=(15, 5))\n\n# Original data\nplt.subplot(1, 3, 1)\nplt.scatter(df_multi['feature1'], df_multi['feature2'], alpha=0.6)\nplt.title('Original Data')\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\n\n# Isolation Forest results\nplt.subplot(1, 3, 2)\nnormal = df_multi[~df_multi['is_outlier_isolation']]\noutliers = df_multi[df_multi['is_outlier_isolation']]\nplt.scatter(normal['feature1'], normal['feature2'], alpha=0.6, label='Normal')\nplt.scatter(outliers['feature1'], outliers['feature2'], alpha=0.8, color='red', label='Outliers')\nplt.title('Isolation Forest Detection')\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\nplt.legend()\n\n# LOF results\nplt.subplot(1, 3, 3)\nnormal_lof = df_multi[~df_multi['is_outlier_lof']]\noutliers_lof = df_multi[df_multi['is_outlier_lof']]\nplt.scatter(normal_lof['feature1'], normal_lof['feature2'], alpha=0.6, label='Normal')\nplt.scatter(outliers_lof['feature1'], outliers_lof['feature2'], alpha=0.8, color='red', label='Outliers')\nplt.title('LOF Detection')\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n</code></pre>","tags":["Numpy","Pandas","Scikit-learn"]},{"location":"blogs/detect-remove-outliers-python-iqr-zscore/#comprehensive-outlier-detection-function","title":"Comprehensive Outlier Detection Function","text":"<pre><code>def comprehensive_outlier_detection(df, columns, methods=['iqr', 'zscore', 'isolation']):\n    \"\"\"\n    Comprehensive outlier detection using multiple methods\n\n    Parameters:\n    df: pandas DataFrame\n    columns: list of column names to analyze\n    methods: list of methods to use\n\n    Returns:\n    DataFrame with outlier flags for each method\n    \"\"\"\n    result_df = df.copy()\n\n    for col in columns:\n        if 'iqr' in methods:\n            Q1 = df[col].quantile(0.25)\n            Q3 = df[col].quantile(0.75)\n            IQR = Q3 - Q1\n            lower_bound = Q1 - 1.5 * IQR\n            upper_bound = Q3 + 1.5 * IQR\n            result_df[f'{col}_outlier_iqr'] = (df[col] &lt; lower_bound) | (df[col] &gt; upper_bound)\n\n        if 'zscore' in methods:\n            z_scores = np.abs(stats.zscore(df[col]))\n            result_df[f'{col}_outlier_zscore'] = z_scores &gt; 3\n\n        if 'mad' in methods:\n            mad_scores = modified_z_score(df[col])\n            result_df[f'{col}_outlier_mad'] = mad_scores &gt; 3.5\n\n    if 'isolation' in methods and len(columns) &gt; 1:\n        iso_forest = IsolationForest(contamination=0.1, random_state=42)\n        outlier_pred = iso_forest.fit_predict(df[columns])\n        result_df['outlier_isolation'] = outlier_pred == -1\n\n    return result_df\n\n# Apply comprehensive detection\ncolumns_to_analyze = ['feature1', 'feature2']\ndf_comprehensive = comprehensive_outlier_detection(\n    df_multi, \n    columns_to_analyze, \n    methods=['iqr', 'zscore', 'isolation']\n)\n\n# Summary of outliers detected by each method\noutlier_summary = {}\nfor col in df_comprehensive.columns:\n    if 'outlier' in col:\n        outlier_summary[col] = df_comprehensive[col].sum()\n\nprint(\"Outlier Summary:\")\nfor method, count in outlier_summary.items():\n    print(f\"{method}: {count} outliers\")\n</code></pre>","tags":["Numpy","Pandas","Scikit-learn"]},{"location":"blogs/detect-remove-outliers-python-iqr-zscore/#outlier-treatment-strategies","title":"Outlier Treatment Strategies","text":"","tags":["Numpy","Pandas","Scikit-learn"]},{"location":"blogs/detect-remove-outliers-python-iqr-zscore/#1-removal","title":"1. Removal","text":"<pre><code>def remove_outliers(df, outlier_column):\n    \"\"\"Remove outliers from dataset\"\"\"\n    return df[~df[outlier_column]].copy()\n\n# Remove outliers detected by IQR\ndf_clean = remove_outliers(df, 'is_outlier_iqr')\nprint(f\"Original size: {len(df)}, After removal: {len(df_clean)}\")\n</code></pre>","tags":["Numpy","Pandas","Scikit-learn"]},{"location":"blogs/detect-remove-outliers-python-iqr-zscore/#2-transformation","title":"2. Transformation","text":"<pre><code>def winsorize_outliers(data, limits=(0.05, 0.05)):\n    \"\"\"Cap outliers at specified percentiles\"\"\"\n    from scipy.stats.mstats import winsorize\n    return winsorize(data, limits=limits)\n\n# Apply winsorization\ndf['values_winsorized'] = winsorize_outliers(df['values'])\n\n# Log transformation for skewed data\ndf['values_log'] = np.log1p(np.abs(df['values']))\n</code></pre>","tags":["Numpy","Pandas","Scikit-learn"]},{"location":"blogs/detect-remove-outliers-python-iqr-zscore/#3-imputation","title":"3. Imputation","text":"<pre><code>def impute_outliers(df, column, outlier_column, method='median'):\n    \"\"\"Replace outliers with imputed values\"\"\"\n    df_imputed = df.copy()\n\n    if method == 'median':\n        fill_value = df[~df[outlier_column]][column].median()\n    elif method == 'mean':\n        fill_value = df[~df[outlier_column]][column].mean()\n    elif method == 'mode':\n        fill_value = df[~df[outlier_column]][column].mode()[0]\n\n    df_imputed.loc[df_imputed[outlier_column], column] = fill_value\n    return df_imputed\n\n# Impute outliers with median\ndf_imputed = impute_outliers(df, 'values', 'is_outlier_iqr', method='median')\n</code></pre>","tags":["Numpy","Pandas","Scikit-learn"]},{"location":"blogs/detect-remove-outliers-python-iqr-zscore/#domain-specific-considerations","title":"Domain-Specific Considerations","text":"","tags":["Numpy","Pandas","Scikit-learn"]},{"location":"blogs/detect-remove-outliers-python-iqr-zscore/#time-series-outliers","title":"Time Series Outliers","text":"<pre><code>def detect_time_series_outliers(ts_data, window=30, threshold=3):\n    \"\"\"Detect outliers in time series using rolling statistics\"\"\"\n    rolling_mean = ts_data.rolling(window=window).mean()\n    rolling_std = ts_data.rolling(window=window).std()\n\n    z_scores = np.abs((ts_data - rolling_mean) / rolling_std)\n    return z_scores &gt; threshold\n\n# Example with time series\ndates = pd.date_range('2024-01-01', periods=365, freq='D')\nts_values = np.random.normal(100, 10, 365)\n# Add seasonal outliers\nts_values[100:110] += 50  # Anomalous period\n\nts_df = pd.DataFrame({'date': dates, 'value': ts_values})\nts_df['is_outlier'] = detect_time_series_outliers(ts_df['value'])\n</code></pre>","tags":["Numpy","Pandas","Scikit-learn"]},{"location":"blogs/detect-remove-outliers-python-iqr-zscore/#categorical-outliers","title":"Categorical Outliers","text":"<pre><code>def detect_categorical_outliers(df, column, threshold=0.01):\n    \"\"\"Detect rare categories as outliers\"\"\"\n    value_counts = df[column].value_counts(normalize=True)\n    rare_categories = value_counts[value_counts &lt; threshold].index\n    return df[column].isin(rare_categories)\n\n# Example with categorical data\ncategories = np.random.choice(['A', 'B', 'C'], 1000, p=[0.5, 0.4, 0.1])\n# Add rare categories\nrare_cats = np.array(['X', 'Y', 'Z'])\ncategories = np.concatenate([categories, rare_cats])\n\ncat_df = pd.DataFrame({'category': categories})\ncat_df['is_rare'] = detect_categorical_outliers(cat_df, 'category', threshold=0.05)\n</code></pre>","tags":["Numpy","Pandas","Scikit-learn"]},{"location":"blogs/detect-remove-outliers-python-iqr-zscore/#model-performance-impact","title":"Model Performance Impact","text":"","tags":["Numpy","Pandas","Scikit-learn"]},{"location":"blogs/detect-remove-outliers-python-iqr-zscore/#before-and-after-comparison","title":"Before and After Comparison","text":"<pre><code>from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Create synthetic regression dataset with outliers\nX = np.random.normal(0, 1, (1000, 2))\ny = 3*X[:, 0] + 2*X[:, 1] + np.random.normal(0, 0.1, 1000)\n\n# Add outliers to target\noutlier_indices = np.random.choice(1000, 50, replace=False)\ny[outlier_indices] += np.random.normal(0, 10, 50)\n\n# Create DataFrame\nmodel_df = pd.DataFrame(X, columns=['feature1', 'feature2'])\nmodel_df['target'] = y\n\n# Detect outliers\nz_scores_target = np.abs(stats.zscore(model_df['target']))\nmodel_df['is_outlier'] = z_scores_target &gt; 3\n\n# Split data\nX_train, X_test, y_train, y_test = train_test_split(\n    model_df[['feature1', 'feature2']], \n    model_df['target'], \n    test_size=0.2, \n    random_state=42\n)\n\n# Model with outliers\nmodel_with_outliers = LinearRegression()\nmodel_with_outliers.fit(X_train, y_train)\ny_pred_with = model_with_outliers.predict(X_test)\n\n# Model without outliers\ntrain_mask = ~model_df.loc[X_train.index, 'is_outlier']\nX_train_clean = X_train[train_mask]\ny_train_clean = y_train[train_mask]\n\nmodel_without_outliers = LinearRegression()\nmodel_without_outliers.fit(X_train_clean, y_train_clean)\ny_pred_without = model_without_outliers.predict(X_test)\n\n# Compare performance\nprint(\"Model Performance Comparison:\")\nprint(f\"With outliers - MSE: {mean_squared_error(y_test, y_pred_with):.4f}, R\u00b2: {r2_score(y_test, y_pred_with):.4f}\")\nprint(f\"Without outliers - MSE: {mean_squared_error(y_test, y_pred_without):.4f}, R\u00b2: {r2_score(y_test, y_pred_without):.4f}\")\n</code></pre>","tags":["Numpy","Pandas","Scikit-learn"]},{"location":"blogs/detect-remove-outliers-python-iqr-zscore/#best-practices","title":"Best Practices","text":"","tags":["Numpy","Pandas","Scikit-learn"]},{"location":"blogs/detect-remove-outliers-python-iqr-zscore/#1-multiple-method-validation","title":"1. Multiple Method Validation","text":"<pre><code>def validate_outlier_methods(df, column, true_outliers=None):\n    \"\"\"Compare different outlier detection methods\"\"\"\n    methods_results = {}\n\n    # IQR\n    Q1, Q3 = df[column].quantile([0.25, 0.75])\n    IQR = Q3 - Q1\n    iqr_outliers = (df[column] &lt; Q1 - 1.5*IQR) | (df[column] &gt; Q3 + 1.5*IQR)\n    methods_results['IQR'] = iqr_outliers\n\n    # Z-Score\n    z_scores = np.abs(stats.zscore(df[column]))\n    zscore_outliers = z_scores &gt; 3\n    methods_results['Z-Score'] = zscore_outliers\n\n    # Modified Z-Score\n    mad_scores = modified_z_score(df[column])\n    mad_outliers = mad_scores &gt; 3.5\n    methods_results['MAD'] = mad_outliers\n\n    # Summary\n    summary = pd.DataFrame({\n        method: results.sum() for method, results in methods_results.items()\n    }, index=['Outliers Detected']).T\n\n    print(\"Method Comparison:\")\n    print(summary)\n\n    return methods_results\n</code></pre>","tags":["Numpy","Pandas","Scikit-learn"]},{"location":"blogs/detect-remove-outliers-python-iqr-zscore/#2-threshold-sensitivity-analysis","title":"2. Threshold Sensitivity Analysis","text":"<pre><code>def threshold_sensitivity_analysis(data, method='zscore', thresholds=None):\n    \"\"\"Analyze sensitivity to threshold values\"\"\"\n    if thresholds is None:\n        thresholds = np.arange(1.5, 4.5, 0.5)\n\n    results = []\n\n    for threshold in thresholds:\n        if method == 'zscore':\n            z_scores = np.abs(stats.zscore(data))\n            outliers = (z_scores &gt; threshold).sum()\n        elif method == 'iqr':\n            Q1, Q3 = np.percentile(data, [25, 75])\n            IQR = Q3 - Q1\n            outliers = ((data &lt; Q1 - threshold*IQR) | (data &gt; Q3 + threshold*IQR)).sum()\n\n        results.append({'threshold': threshold, 'outliers': outliers})\n\n    return pd.DataFrame(results)\n\n# Analyze threshold sensitivity\nsensitivity_results = threshold_sensitivity_analysis(df['values'], method='zscore')\nprint(sensitivity_results)\n</code></pre>","tags":["Numpy","Pandas","Scikit-learn"]},{"location":"blogs/detect-remove-outliers-python-iqr-zscore/#integration-with-data-pipelines","title":"Integration with Data Pipelines","text":"<p>For production environments, implement outlier detection as part of your data quality monitoring pipeline. Consider using automated alerting when outlier rates exceed expected thresholds.</p>","tags":["Numpy","Pandas","Scikit-learn"]},{"location":"blogs/detect-remove-outliers-python-iqr-zscore/#conclusion","title":"Conclusion","text":"<p>Effective outlier detection requires understanding your data domain, choosing appropriate methods, and validating results. Combine statistical methods with machine learning approaches for robust detection. Always consider the business context before removing or transforming outliers, as they might contain valuable information about rare but important events. </p>","tags":["Numpy","Pandas","Scikit-learn"]},{"location":"blogs/detect-remove-outliers-python-iqr-zscore/#stay-updated","title":"Stay Updated","text":"<p>Join my newsletter for the latest insights on Document AI, RAG, and LLM technologies:</p>","tags":["Numpy","Pandas","Scikit-learn"]},{"location":"blogs/detect-remove-outliers-python-iqr-zscore/#share-this-post","title":"Share This Post","text":"<p>Share on  Share on </p>","tags":["Numpy","Pandas","Scikit-learn"]},{"location":"blogs/difference-reshape-flatten-numpy/","title":"Difference between reshape() and flatten() in NumPy","text":"<p>NumPy's <code>reshape()</code> and <code>flatten()</code> are both used for array manipulation, but they serve different purposes and have distinct behaviors. This guide explains when and how to use each method effectively.</p>","tags":["Numpy"]},{"location":"blogs/difference-reshape-flatten-numpy/#what-is-reshape-in-numpy","title":"What is reshape() in NumPy","text":"<p>The <code>reshape()</code> method changes the shape of an array without changing its data. It returns a new view of the array with a different shape when possible.</p>","tags":["Numpy"]},{"location":"blogs/difference-reshape-flatten-numpy/#basic-syntax","title":"Basic Syntax","text":"<pre><code>import numpy as np\n\n# Create a 1D array\narr = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])\nprint(f\"Original array: {arr}\")\nprint(f\"Original shape: {arr.shape}\")\n\n# Reshape to 2D array\nreshaped = arr.reshape(3, 4)\nprint(f\"Reshaped array:\\n{reshaped}\")\nprint(f\"Reshaped shape: {reshaped.shape}\")\n</code></pre>","tags":["Numpy"]},{"location":"blogs/difference-reshape-flatten-numpy/#key-properties-of-reshape","title":"Key Properties of reshape()","text":"<ol> <li>Returns a view when possible: Changes to the reshaped array affect the original</li> <li>Preserves total number of elements: New shape must have same total size</li> <li>Flexible shape specification: Can use -1 for automatic dimension calculation</li> </ol> <pre><code># Demonstrating view behavior\noriginal = np.array([[1, 2, 3], [4, 5, 6]])\nreshaped = original.reshape(6)\n\n# Modifying reshaped affects original\nreshaped[0] = 999\nprint(f\"Original after modification: {original}\")\nprint(f\"Reshaped after modification: {reshaped}\")\n</code></pre>","tags":["Numpy"]},{"location":"blogs/difference-reshape-flatten-numpy/#what-is-flatten-in-numpy","title":"What is flatten() in NumPy","text":"<p>The <code>flatten()</code> method returns a 1D copy of the array. It always creates a new array, regardless of the original array's memory layout.</p>","tags":["Numpy"]},{"location":"blogs/difference-reshape-flatten-numpy/#basic-syntax_1","title":"Basic Syntax","text":"<pre><code># Create a 2D array\narr_2d = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\nprint(f\"Original 2D array:\\n{arr_2d}\")\n\n# Flatten the array\nflattened = arr_2d.flatten()\nprint(f\"Flattened array: {flattened}\")\nprint(f\"Flattened shape: {flattened.shape}\")\n</code></pre>","tags":["Numpy"]},{"location":"blogs/difference-reshape-flatten-numpy/#key-properties-of-flatten","title":"Key Properties of flatten()","text":"<ol> <li>Always returns a copy: Changes to flattened array don't affect original</li> <li>Always produces 1D array: Regardless of original dimensions</li> <li>Order parameter: Controls how elements are read from original array</li> </ol> <pre><code># Demonstrating copy behavior\noriginal = np.array([[1, 2, 3], [4, 5, 6]])\nflattened = original.flatten()\n\n# Modifying flattened doesn't affect original\nflattened[0] = 999\nprint(f\"Original after modification: {original}\")\nprint(f\"Flattened after modification: {flattened}\")\n</code></pre>","tags":["Numpy"]},{"location":"blogs/difference-reshape-flatten-numpy/#core-differences","title":"Core Differences","text":"","tags":["Numpy"]},{"location":"blogs/difference-reshape-flatten-numpy/#1-memory-behavior","title":"1. Memory Behavior","text":"<pre><code>import numpy as np\n\n# Create test array\narr = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n\n# Using reshape\nreshaped = arr.reshape(-1)  # -1 means \"infer this dimension\"\nprint(f\"Reshaped shares memory: {np.shares_memory(arr, reshaped)}\")\n\n# Using flatten\nflattened = arr.flatten()\nprint(f\"Flattened shares memory: {np.shares_memory(arr, flattened)}\")\n\n# Memory addresses\nprint(f\"Original array base: {arr.base}\")\nprint(f\"Reshaped array base: {reshaped.base}\")\nprint(f\"Flattened array base: {flattened.base}\")\n</code></pre>","tags":["Numpy"]},{"location":"blogs/difference-reshape-flatten-numpy/#2-performance-comparison","title":"2. Performance Comparison","text":"<pre><code>import time\n\n# Create large array for performance testing\nlarge_arr = np.random.rand(1000, 1000)\n\n# Time reshape operation\nstart_time = time.time()\nfor _ in range(1000):\n    reshaped = large_arr.reshape(-1)\nreshape_time = time.time() - start_time\n\n# Time flatten operation\nstart_time = time.time()\nfor _ in range(1000):\n    flattened = large_arr.flatten()\nflatten_time = time.time() - start_time\n\nprint(f\"Reshape time: {reshape_time:.4f} seconds\")\nprint(f\"Flatten time: {flatten_time:.4f} seconds\")\nprint(f\"Flatten is {flatten_time/reshape_time:.1f}x slower than reshape\")\n</code></pre>","tags":["Numpy"]},{"location":"blogs/difference-reshape-flatten-numpy/#3-shape-flexibility","title":"3. Shape Flexibility","text":"<pre><code># reshape() allows multiple target shapes\narr = np.arange(24)\n\n# Various reshape operations\nshapes = [(2, 12), (3, 8), (4, 6), (2, 3, 4), (2, 2, 6)]\n\nfor shape in shapes:\n    reshaped = arr.reshape(shape)\n    print(f\"Shape {shape}: {reshaped.shape}\")\n\n# flatten() always produces 1D\nmulti_dim = np.arange(24).reshape(2, 3, 4)\nflattened = multi_dim.flatten()\nprint(f\"Multi-dimensional {multi_dim.shape} -&gt; Flattened {flattened.shape}\")\n</code></pre>","tags":["Numpy"]},{"location":"blogs/difference-reshape-flatten-numpy/#advanced-usage-patterns","title":"Advanced Usage Patterns","text":"","tags":["Numpy"]},{"location":"blogs/difference-reshape-flatten-numpy/#using-reshape-with-1-parameter","title":"Using reshape() with -1 Parameter","text":"<pre><code># Automatic dimension calculation\narr = np.arange(20)\n\n# Reshape to 2D with automatic row calculation\nauto_rows = arr.reshape(-1, 4)  # NumPy calculates rows automatically\nprint(f\"Auto rows shape: {auto_rows.shape}\")\n\n# Reshape to 2D with automatic column calculation\nauto_cols = arr.reshape(5, -1)  # NumPy calculates columns automatically\nprint(f\"Auto cols shape: {auto_cols.shape}\")\n\n# Error case: incompatible dimensions\ntry:\n    invalid = arr.reshape(3, 7)  # 20 elements can't fit in 3x7 (21 elements)\nexcept ValueError as e:\n    print(f\"Error: {e}\")\n</code></pre>","tags":["Numpy"]},{"location":"blogs/difference-reshape-flatten-numpy/#using-flatten-with-order-parameter","title":"Using flatten() with Order Parameter","text":"<pre><code># Create test array\narr = np.array([[1, 2, 3], [4, 5, 6]])\n\n# Different flattening orders\nc_order = arr.flatten('C')  # Row-major (C-style) - default\nf_order = arr.flatten('F')  # Column-major (Fortran-style)\na_order = arr.flatten('A')  # Preserve original order if possible\nk_order = arr.flatten('K')  # Elements in memory order\n\nprint(f\"Original array:\\n{arr}\")\nprint(f\"C order (row-major): {c_order}\")\nprint(f\"F order (column-major): {f_order}\")\nprint(f\"A order: {a_order}\")\nprint(f\"K order: {k_order}\")\n</code></pre>","tags":["Numpy"]},{"location":"blogs/difference-reshape-flatten-numpy/#alternative-methods","title":"Alternative Methods","text":"","tags":["Numpy"]},{"location":"blogs/difference-reshape-flatten-numpy/#using-ravel-the-middle-ground","title":"Using ravel() - The Middle Ground","text":"<pre><code># ravel() is similar to flatten() but returns a view when possible\narr = np.array([[1, 2, 3], [4, 5, 6]])\n\nraveled = arr.ravel()\nprint(f\"Ravel shares memory: {np.shares_memory(arr, raveled)}\")\n\n# ravel() behavior with non-contiguous arrays\narr_slice = arr[:, ::2]  # Non-contiguous slice\nraveled_slice = arr_slice.ravel()\nprint(f\"Ravel of slice shares memory: {np.shares_memory(arr_slice, raveled_slice)}\")\n</code></pre>","tags":["Numpy"]},{"location":"blogs/difference-reshape-flatten-numpy/#comparison-of-all-three-methods","title":"Comparison of All Three Methods","text":"<pre><code>def compare_methods(arr):\n    \"\"\"Compare reshape, flatten, and ravel methods\"\"\"\n\n    # Get 1D versions using all methods\n    reshaped = arr.reshape(-1)\n    flattened = arr.flatten()\n    raveled = arr.ravel()\n\n    print(\"Method Comparison:\")\n    print(f\"reshape(-1) shares memory: {np.shares_memory(arr, reshaped)}\")\n    print(f\"flatten() shares memory: {np.shares_memory(arr, flattened)}\")\n    print(f\"ravel() shares memory: {np.shares_memory(arr, raveled)}\")\n\n    # Test modification effects\n    original_copy = arr.copy()\n\n    reshaped[0] = -999\n    print(f\"After modifying reshaped: original changed = {not np.array_equal(arr, original_copy)}\")\n\n    arr[:] = original_copy  # Reset\n    flattened[0] = -999\n    print(f\"After modifying flattened: original changed = {not np.array_equal(arr, original_copy)}\")\n\n    arr[:] = original_copy  # Reset\n    raveled[0] = -999\n    print(f\"After modifying raveled: original changed = {not np.array_equal(arr, original_copy)}\")\n\n# Test with contiguous array\ntest_arr = np.array([[1, 2, 3], [4, 5, 6]])\ncompare_methods(test_arr)\n</code></pre>","tags":["Numpy"]},{"location":"blogs/difference-reshape-flatten-numpy/#practical-use-cases","title":"Practical Use Cases","text":"","tags":["Numpy"]},{"location":"blogs/difference-reshape-flatten-numpy/#when-to-use-reshape","title":"When to Use reshape()","text":"<ol> <li> <p>Preparing data for machine learning models <pre><code># Reshaping image data for CNN\nimage_data = np.random.rand(100, 28, 28)  # 100 grayscale images\n# Flatten for traditional ML algorithms\nX_flat = image_data.reshape(100, -1)  # Shape: (100, 784)\nprint(f\"Reshaped for ML: {X_flat.shape}\")\n\n# Reshape for CNN (add channel dimension)\nX_cnn = image_data.reshape(100, 28, 28, 1)  # Shape: (100, 28, 28, 1)\nprint(f\"Reshaped for CNN: {X_cnn.shape}\")\n</code></pre></p> </li> <li> <p>Matrix operations <pre><code># Reshaping for matrix multiplication\nA = np.random.rand(6, 8)\nB = A.reshape(8, 6)  # Transpose-like operation\nresult = A @ B  # Matrix multiplication\nprint(f\"Result shape: {result.shape}\")\n</code></pre></p> </li> </ol>","tags":["Numpy"]},{"location":"blogs/difference-reshape-flatten-numpy/#when-to-use-flatten","title":"When to Use flatten()","text":"<ol> <li> <p>Data preprocessing when you need independence <pre><code># Flattening for feature engineering where original shouldn't change\noriginal_features = np.array([[1, 2], [3, 4], [5, 6]])\nflat_features = original_features.flatten()\n\n# Apply transformations to flattened version\nflat_features = flat_features * 2 + 1\nprint(f\"Original unchanged: {original_features}\")\nprint(f\"Transformed flat: {flat_features}\")\n</code></pre></p> </li> <li> <p>Converting multi-dimensional data for serialization <pre><code># Preparing data for saving/transmission\ndata_3d = np.random.rand(10, 20, 30)\nserializable = data_3d.flatten()\n\n# Save shape information separately for reconstruction\nshape_info = data_3d.shape\nprint(f\"Serializable data length: {len(serializable)}\")\nprint(f\"Shape to save: {shape_info}\")\n\n# Reconstruction\nreconstructed = serializable.reshape(shape_info)\nprint(f\"Reconstruction successful: {np.array_equal(data_3d, reconstructed)}\")\n</code></pre></p> </li> </ol>","tags":["Numpy"]},{"location":"blogs/difference-reshape-flatten-numpy/#common-pitfalls-and-best-practices","title":"Common Pitfalls and Best Practices","text":"","tags":["Numpy"]},{"location":"blogs/difference-reshape-flatten-numpy/#1-memory-efficiency-considerations","title":"1. Memory Efficiency Considerations","text":"<pre><code>def memory_efficient_processing(large_array):\n    \"\"\"Demonstrate memory-efficient array processing\"\"\"\n\n    # Good: Use reshape for temporary view\n    flat_view = large_array.reshape(-1)\n\n    # Process in chunks to avoid memory issues\n    chunk_size = 1000\n    results = []\n\n    for i in range(0, len(flat_view), chunk_size):\n        chunk = flat_view[i:i+chunk_size]\n        # Process chunk (example: square all elements)\n        processed = chunk ** 2\n        results.append(processed)\n\n    return np.concatenate(results).reshape(large_array.shape)\n\n# Test with large array\nlarge_data = np.random.rand(1000, 1000)\nresult = memory_efficient_processing(large_data)\n</code></pre>","tags":["Numpy"]},{"location":"blogs/difference-reshape-flatten-numpy/#2-avoiding-unexpected-modifications","title":"2. Avoiding Unexpected Modifications","text":"<pre><code>def safe_array_processing(arr):\n    \"\"\"Safely process arrays without affecting originals\"\"\"\n\n    # Wrong: Using reshape for processing\n    # flat = arr.reshape(-1)\n    # flat *= 2  # This would modify original!\n\n    # Correct: Use flatten for independent processing\n    flat = arr.flatten()\n    flat *= 2\n\n    return flat.reshape(arr.shape)\n\n# Test safe processing\noriginal = np.array([[1, 2], [3, 4]])\nprocessed = safe_array_processing(original)\nprint(f\"Original preserved: {original}\")\nprint(f\"Processed result: {processed}\")\n</code></pre>","tags":["Numpy"]},{"location":"blogs/difference-reshape-flatten-numpy/#3-performance-optimization","title":"3. Performance Optimization","text":"<pre><code>def optimized_array_operations(arr):\n    \"\"\"Optimize array operations based on use case\"\"\"\n\n    # For read-only operations, use reshape (faster)\n    if need_read_only_flat_view(arr):\n        return arr.reshape(-1)\n\n    # For independent processing, use flatten\n    elif need_independent_copy(arr):\n        return arr.flatten()\n\n    # For best of both worlds, use ravel\n    else:\n        return arr.ravel()\n\ndef need_read_only_flat_view(arr):\n    # Logic to determine if read-only view is sufficient\n    return True\n\ndef need_independent_copy(arr):\n    # Logic to determine if independent copy is needed\n    return False\n</code></pre>","tags":["Numpy"]},{"location":"blogs/difference-reshape-flatten-numpy/#integration-with-data-science-workflows","title":"Integration with Data Science Workflows","text":"<p>When working with data pipelines that require consistent array manipulation, understanding these differences becomes crucial for performance and correctness.</p>","tags":["Numpy"]},{"location":"blogs/difference-reshape-flatten-numpy/#summary-table","title":"Summary Table","text":"Aspect reshape() flatten() ravel() Returns View (when possible) Copy (always) View (when possible) Memory Usage Low High Low Performance Fast Slower Fast Safety Modifications affect original Safe from modifications Modifications affect original Flexibility Any compatible shape Always 1D Always 1D Use Case Shape transformation Independent processing Quick flattening","tags":["Numpy"]},{"location":"blogs/difference-reshape-flatten-numpy/#conclusion","title":"Conclusion","text":"","tags":["Numpy"]},{"location":"blogs/difference-reshape-flatten-numpy/#choose-reshape-when-you-need-to-change-array-dimensions-while-maintaining-memory-efficiency-and-when-modifications-to-the-result-should-affect-the-original-array-use-flatten-when-you-need-a-completely-independent-1d-copy-of-your-data-for-processing-that-shouldnt-affect-the-original-consider-ravel-as-a-middle-ground-that-provides-the-performance-of-reshape-with-the-convenience-of-always-returning-a-flat-array","title":"Choose <code>reshape()</code> when you need to change array dimensions while maintaining memory efficiency and when modifications to the result should affect the original array. Use <code>flatten()</code> when you need a completely independent 1D copy of your data for processing that shouldn't affect the original. Consider <code>ravel()</code> as a middle ground that provides the performance of <code>reshape()</code> with the convenience of always returning a flat array.","text":"","tags":["Numpy"]},{"location":"blogs/difference-reshape-flatten-numpy/#stay-updated","title":"Stay Updated","text":"<p>Join my newsletter for the latest insights on Document AI, RAG, and LLM technologies:</p>","tags":["Numpy"]},{"location":"blogs/difference-reshape-flatten-numpy/#share-this-post","title":"Share This Post","text":"<p>Share on  Share on </p>","tags":["Numpy"]},{"location":"blogs/does-langchain-use-rag/","title":"RAG with LangChain: Architecture, Code, and Metrics","text":"<p>RAG is a design pattern, not a product. LangChain supports it out of the box. This guide shows a production-ready RAG setup in LangChain with architecture, retrieval choices, runnable code, evaluation metrics, and trade-offs from my client projects.</p>","tags":["RAG","LangChain","Retrival","Embeddings"]},{"location":"blogs/does-langchain-use-rag/#tldr","title":"TL;DR","text":"<ul> <li>Short answer: LangChain doesn\u2019t \"contain\" RAG; it provides the building blocks to implement RAG cleanly. You wire up chunking, embeddings, vector store, and a retrieval-aware prompt chain.</li> <li>What you get below: Architecture diagram, runnable code (LangChain 0.2+), evaluation harness, parameter trade-offs, and when to avoid LangChain for leaner stacks.</li> <li>Related deep dives: Foundations of RAG \u2192 /blogs/rag-for-knowledge-intensive-nlp-tasks. Lightweight pipelines \u2192 /blogs/lightrag-fast-retrieval-augmented-generation.</li> </ul>","tags":["RAG","LangChain","Retrival","Embeddings"]},{"location":"blogs/does-langchain-use-rag/#who-should-read-this","title":"Who should read this","text":"<ul> <li>You\u2019re building an internal knowledge assistant, support bot, or compliance Q&amp;A system.</li> <li>You need answers that cite real documents with predictable latency and cost.</li> <li>You want a minimal, maintainable RAG in LangChain with evaluation, not a toy demo.</li> </ul>","tags":["RAG","LangChain","Retrival","Embeddings"]},{"location":"blogs/does-langchain-use-rag/#the-problem-i-solved-in-production","title":"The problem I solved in production","text":"<p>When I implemented an extractive summarizer for financial and compliance reports, two pain points surfaced:</p> <ul> <li>Answers hallucinated when questions referenced specific clauses across multiple PDFs.</li> <li>Latency spiked under load because of inefficient chunking and greedy retrieval.</li> </ul> <p>RAG fixed this. We chunked documents, embedded them, retrieved the most relevant chunks, and let the LLM answer strictly from those chunks. We also added guardrails: cited sources, fallbacks when retrieval confidence is low, and evaluation to catch regressions.</p>","tags":["RAG","LangChain","Retrival","Embeddings"]},{"location":"blogs/does-langchain-use-rag/#architecture-at-a-glance","title":"Architecture at a glance","text":"<ol> <li>Ingest documents (PDF, HTML, markdown)</li> <li>Split into chunks (size/overlap depend on doc type)</li> <li>Embed chunks into vectors</li> <li>Store vectors in FAISS/Chroma/pgvector</li> <li>Retrieve top-k chunks at query time</li> <li>Construct a retrieval-aware prompt with the chunks</li> <li>Generate an answer that cites sources</li> <li>Log latency, token usage, and citation coverage</li> </ol>","tags":["RAG","LangChain","Retrival","Embeddings"]},{"location":"blogs/does-langchain-use-rag/#setup-langchain-02","title":"Setup (LangChain 0.2+)","text":"<pre><code>uv pip install \"langchain&gt;=0.2\" langchain-openai langchain-community langchain-text-splitters faiss-cpu tiktoken\n# or: pip install ...\n\nexport OPENAI_API_KEY=your_key\n</code></pre>","tags":["RAG","LangChain","Retrival","Embeddings"]},{"location":"blogs/does-langchain-use-rag/#minimal-runnable-rag-with-langchain","title":"Minimal, runnable RAG with LangChain","text":"<pre><code>from __future__ import annotations\nimport os\nimport time\nfrom typing import List, Dict\n\nfrom langchain_openai import ChatOpenAI, OpenAIEmbeddings\nfrom langchain_community.vectorstores import FAISS\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\nfrom langchain.docstore.document import Document\nfrom langchain.prompts import ChatPromptTemplate\nfrom langchain.schema.runnable import RunnablePassthrough\n\n\ndef build_docs() -&gt; List[Document]:\n    corpus = [\n        (\"return_policy.md\", \"Customers may return items within 30 days with receipt. Exchanges allowed within 45 days.\"),\n        (\"shipping_policy.md\", \"Standard shipping takes 3-5 business days. Expedited options available at extra cost.\"),\n        (\"warranty.md\", \"Electronics include a 1-year limited warranty covering defects in materials and workmanship.\"),\n    ]\n    return [Document(page_content=text, metadata={\"source\": name}) for name, text in corpus]\n\n\ndef build_vectorstore(docs: List[Document]):\n    splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)\n    chunks = splitter.split_documents(docs)\n    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n    return FAISS.from_documents(chunks, embeddings)\n\n\ndef format_docs(docs: List[Document]) -&gt; str:\n    return \"\\n\\n\".join(f\"Source: {d.metadata.get('source')}\\n{d.page_content}\" for d in docs)\n\n\ndef build_chain(vectorstore) -&gt; RunnablePassthrough:\n    retriever = vectorstore.as_retriever(search_type=\"mmr\", k=4, fetch_k=12)\n    prompt = ChatPromptTemplate.from_messages([\n        (\"system\", \"You are a precise assistant. Answer ONLY from the provided context. If unsure, say you don't know. Always cite sources as [source] labels.\"),\n        (\"human\", \"Question: {question}\\n\\nContext:\\n{context}\")\n    ])\n    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n    chain = {\n        \"context\": retriever | format_docs,\n        \"question\": RunnablePassthrough(),\n    } | prompt | llm\n    return chain\n\n\ndef ask(chain, question: str) -&gt; Dict[str, str]:\n    start = time.time()\n    result = chain.invoke(question)\n    latency_ms = (time.time() - start) * 1000\n    text = result.content if hasattr(result, \"content\") else str(result)\n    return {\"answer\": text, \"latency_ms\": f\"{latency_ms:.1f}\"}\n\n\nif __name__ == \"__main__\":\n    docs = build_docs()\n    vs = build_vectorstore(docs)\n    chain = build_chain(vs)\n\n    q = \"What is the return window?\"\n    out = ask(chain, q)\n    print({\"question\": q, **out})\n</code></pre> <p>What to check in the output:</p> <ul> <li>The answer references only the context. If not, reduce temperature or add a stricter system message.</li> <li>It cites sources like <code>[return_policy.md]</code>. If not, update the prompt template to enforce citation labels.</li> </ul>","tags":["RAG","LangChain","Retrival","Embeddings"]},{"location":"blogs/does-langchain-use-rag/#evaluation-harness-keeps-you-honest","title":"Evaluation harness (keeps you honest)","text":"<p>If you don\u2019t measure retrieval quality, you\u2019ll ship regressions. I use a tiny harness that checks latency and whether the correct source appears among retrieved chunks.</p> <pre><code>from __future__ import annotations\nfrom typing import List, Dict\nimport time\n\n\ndef evaluate(chain, cases: List[Dict[str, str]]) -&gt; Dict[str, float]:\n    latencies = []\n    correct_citation = 0\n    n = len(cases)\n\n    for case in cases:\n        start = time.time()\n        result = chain.invoke(case[\"question\"])  # type: ignore\n        latencies.append((time.time() - start) * 1000)\n        text = result.content if hasattr(result, \"content\") else str(result)\n        if case[\"must_source\"] in text:\n            correct_citation += 1\n\n    return {\n        \"p50_latency_ms\": sorted(latencies)[n // 2],\n        \"p95_latency_ms\": sorted(latencies)[int(n * 0.95) - 1],\n        \"citation_hit_rate\": correct_citation / n,\n    }\n\n\nif __name__ == \"__main__\":\n    cases = [\n        {\"question\": \"What is the return window?\", \"must_source\": \"return_policy.md\"},\n        {\"question\": \"How long does standard shipping take?\", \"must_source\": \"shipping_policy.md\"},\n        {\"question\": \"Do electronics have a warranty?\", \"must_source\": \"warranty.md\"},\n    ]\n\n    metrics = evaluate(chain, cases)\n    print(metrics)\n</code></pre> <p>Target thresholds I use to gate releases on small corpora:</p> <ul> <li>p50 latency \u2264 700 ms, p95 latency \u2264 1200 ms on CPU for small chunks</li> <li>Citation hit rate \u2265 0.9 for straightforward policy questions</li> </ul> <p>If you miss these, tune <code>chunk_size</code>, <code>chunk_overlap</code>, and retriever <code>k</code> before touching the model.</p>","tags":["RAG","LangChain","Retrival","Embeddings"]},{"location":"blogs/does-langchain-use-rag/#retrieval-configuration-choices-and-when-to-change-them","title":"Retrieval configuration choices (and when to change them)","text":"<ul> <li>Chunk size / overlap: For dense policy text, I start at 300/50. For legal PDFs with long sentences, 600/80 reduces cross-chunk fragmentation.</li> <li>Search type: <code>mmr</code> (diversity) is safer for ambiguous queries; switch to <code>similarity</code> if you see topical drift.</li> <li>k (top results): 3\u20135 is plenty for narrow domains. If answers cite the wrong file, reduce k or increase chunk size.</li> <li>Embeddings: <code>text-embedding-3-small</code> is cost-efficient. For multilingual or nuanced legalese, step up to <code>text-embedding-3-large</code>.</li> <li>Prompting: Always include \u201canswer ONLY from context\u201d and require source tags. If the model synthesizes without tags, refuse and ask to clarify.</li> </ul>","tags":["RAG","LangChain","Retrival","Embeddings"]},{"location":"blogs/does-langchain-use-rag/#when-not-to-use-langchain-for-rag","title":"When NOT to use LangChain for RAG","text":"<p>I use LangChain when teams need batteries-included tracing, callbacks, and a large ecosystem. I avoid it when:</p> <ul> <li>You only need a 100-line script with FAISS + OpenAI \u2014 extra abstractions add cognitive load.</li> <li>You\u2019re deploying to a serverless edge function with tight cold-start budgets \u2014 consider a leaner stack like /blogs/lightrag-fast-retrieval-augmented-generation.</li> <li>You need fully custom retrieval (e.g., hybrid lexical + dense, learned re-rankers) and want bare bones control.</li> </ul>","tags":["RAG","LangChain","Retrival","Embeddings"]},{"location":"blogs/does-langchain-use-rag/#data-quality-matters-more-than-the-framework","title":"Data quality matters more than the framework","text":"<p>Garbage in \u2192 garbage out. Before embedding:</p> <ul> <li>Remove duplicated headers/footers and OCR artifacts.</li> <li>Normalize whitespace and bullet structures; enforce sentence boundaries before chunking.</li> <li>Validate statistical anomalies in numeric tables if you'll query them (see: /blogs/detect-remove-outliers-python-iqr-zscore and /blogs/pandas-missing-values).</li> <li>Be careful with array reshaping in preprocessing (see: /blogs/difference-reshape-flatten-numpy).</li> </ul>","tags":["RAG","LangChain","Retrival","Embeddings"]},{"location":"blogs/does-langchain-use-rag/#pitfalls-i-hit-and-fixes","title":"Pitfalls I hit (and fixes)","text":"<ul> <li>Cross-file leakage: Small chunks caused answers to cite the right clause but the wrong file. Fix: increase chunk size to 500\u2013700, reduce <code>k</code>.</li> <li>Latency spikes: Retriever <code>fetch_k</code> too high (e.g., 50). Fix: keep <code>fetch_k</code> under 16 for small corpora, cache embeddings.</li> <li>Overconfident answers with no sources: Prompt too permissive. Fix: strict system message + post-generation check that rejects answers without <code>[source]</code>.</li> <li>Tokenizer costs: Chunk overlap too large. Fix: measure context tokens; target \u2264 2\u20133 chunks per answer on average.</li> </ul>","tags":["RAG","LangChain","Retrival","Embeddings"]},{"location":"blogs/does-langchain-use-rag/#business-impact-and-roi-from-client-work","title":"Business impact and ROI (from client work)","text":"<ul> <li>Reduced average handling time by 28% in support workflows by grounding answers in policy PDFs.</li> <li>Cut hallucination-induced escalations by 60% after enforcing citations and adding an evaluation gate.</li> <li>Lowered cloud costs ~20% by tuning chunking and k to reduce context size without hurting quality.</li> </ul>","tags":["RAG","LangChain","Retrival","Embeddings"]},{"location":"blogs/does-langchain-use-rag/#faq","title":"FAQ","text":"<ul> <li>Does LangChain \"do\" RAG automatically? No. It provides the pieces; you design the pipeline.</li> <li>Which vector store should I pick? FAISS for local/dev, Chroma for fast prototyping, pgvector for Postgres-native stacks.</li> <li>Which model works best? Start with <code>gpt-4o-mini</code> for grounded Q&amp;A. If latency/cost constraints are strict, evaluate smaller models with a re-ranker.</li> </ul>","tags":["RAG","LangChain","Retrival","Embeddings"]},{"location":"blogs/does-langchain-use-rag/#building-rag-in-production","title":"Building RAG in Production","text":"<p>When building RAG systems for production, focus on grounded answers with citations, predictable latency, and proper evaluation gates. Design systems with clear SLAs and monitoring dashboards to ensure reliability.</p>","tags":["RAG","LangChain","Retrival","Embeddings"]},{"location":"blogs/does-langchain-use-rag/#stay-updated","title":"Stay Updated","text":"<p>Join my newsletter for the latest insights on Document AI, RAG, and LLM technologies:</p>","tags":["RAG","LangChain","Retrival","Embeddings"]},{"location":"blogs/does-langchain-use-rag/#share-this-post","title":"Share This Post","text":"<p>Share on  Share on </p>","tags":["RAG","LangChain","Retrival","Embeddings"]},{"location":"blogs/git-101-cheat-sheet/","title":"Git 101 \u2013 Commands and Workflows Cheat Sheet","text":"<p>A quick, task-oriented Git reference. Pair this with the in-depth guide for concepts and best practices.</p>","tags":["Git","DevOps"]},{"location":"blogs/git-101-cheat-sheet/#minimal-mental-model","title":"Minimal Mental Model","text":"<pre><code>graph LR\n  WD[Working Dir] -- add --&gt; ST[Staging]\n  ST -- commit --&gt; REPO[Local Repo]\n  REPO -- push --&gt; ORI[Origin]\n  ORI -- fetch/pull --&gt; REPO</code></pre>","tags":["Git","DevOps"]},{"location":"blogs/git-101-cheat-sheet/#setup","title":"Setup","text":"<pre><code>git --version\ngit config --global user.name \"Your Name\"\ngit config --global user.email \"you@example.com\"\ngit config --global init.defaultBranch main\n</code></pre>","tags":["Git","DevOps"]},{"location":"blogs/git-101-cheat-sheet/#create-or-clone","title":"Create or Clone","text":"<pre><code>git init\ngit clone &lt;url&gt;\n</code></pre>","tags":["Git","DevOps"]},{"location":"blogs/git-101-cheat-sheet/#status-and-diffs","title":"Status and Diffs","text":"<pre><code>git status\ngit diff               # unstaged\ngit diff --staged      # staged vs HEAD\n</code></pre>","tags":["Git","DevOps"]},{"location":"blogs/git-101-cheat-sheet/#stage-and-commit","title":"Stage and Commit","text":"<pre><code>git add &lt;path&gt;\ngit add -p             # interactive hunks\ngit commit -m \"feat: message\"\ngit commit --amend     # edit last commit\n</code></pre>","tags":["Git","DevOps"]},{"location":"blogs/git-101-cheat-sheet/#branching","title":"Branching","text":"<pre><code>git branch\ngit switch -c feature/x\ngit switch main\ngit branch -d feature/x\n</code></pre>","tags":["Git","DevOps"]},{"location":"blogs/git-101-cheat-sheet/#sync-with-remote","title":"Sync with Remote","text":"<pre><code>git remote -v\ngit fetch\ngit pull               # merge\ngit pull --rebase      # rebase\ngit push -u origin my-branch\n</code></pre>","tags":["Git","DevOps"]},{"location":"blogs/git-101-cheat-sheet/#merge-vs-rebase","title":"Merge vs Rebase","text":"<pre><code>git switch my-branch &amp;&amp; git merge main\ngit switch my-branch &amp;&amp; git rebase main\n</code></pre>","tags":["Git","DevOps"]},{"location":"blogs/git-101-cheat-sheet/#resolve-conflicts","title":"Resolve Conflicts","text":"<pre><code>git status\n# edit files, remove markers\ngit add &lt;file&gt;\ngit commit                 # after merge\ngit rebase --continue      # during rebase\n</code></pre>","tags":["Git","DevOps"]},{"location":"blogs/git-101-cheat-sheet/#stash-work","title":"Stash Work","text":"<pre><code>git stash push -m \"wip\"\ngit stash list\ngit stash pop\n</code></pre>","tags":["Git","DevOps"]},{"location":"blogs/git-101-cheat-sheet/#undo-safely","title":"Undo Safely","text":"<pre><code>git restore --staged &lt;file&gt;   # unstage\ngit restore &lt;file&gt;            # discard local edits\ngit revert &lt;sha&gt;              # new commit to undo\ngit reset --soft HEAD~1       # keep changes, drop last commit\ngit reflog                    # find lost commits\n</code></pre>","tags":["Git","DevOps"]},{"location":"blogs/git-101-cheat-sheet/#tags-and-releases","title":"Tags and Releases","text":"<pre><code>git tag -a v1.0.0 -m \"msg\"\ngit push --tags\n</code></pre>","tags":["Git","DevOps"]},{"location":"blogs/git-101-cheat-sheet/#ignore-and-clean","title":"Ignore and Clean","text":"<pre><code>echo \"node_modules/\" &gt;&gt; .gitignore\ngit clean -fdx   # dangerous: removes untracked files\n</code></pre>","tags":["Git","DevOps"]},{"location":"blogs/git-101-cheat-sheet/#authentication-quick","title":"Authentication (Quick)","text":"<pre><code># HTTPS + PAT\ngit clone https://github.com/owner/repo.git\n\n# SSH\nssh-keygen -t ed25519 -C \"you@example.com\"\nssh-add ~/.ssh/id_ed25519\ngit clone git@github.com:owner/repo.git\n</code></pre>","tags":["Git","DevOps"]},{"location":"blogs/git-101-cheat-sheet/#conventional-commits-optional","title":"Conventional Commits (Optional)","text":"<pre><code>feat(auth): add oauth login\nfix(api): handle null pointer in user service\nchore(ci): update node to 20\n</code></pre>","tags":["Git","DevOps"]},{"location":"blogs/git-101-cheat-sheet/#common-one-liners","title":"Common One-Liners","text":"<pre><code># See last commit summary\ngit log -1 --stat\n\n# Interactive rebase last 5 commits\ngit rebase -i HEAD~5\n\n# Squash branch onto main\ngit switch my-branch &amp;&amp; git rebase -i main\n</code></pre>","tags":["Git","DevOps"]},{"location":"blogs/git-101-cheat-sheet/#quick-pr-flow-github","title":"Quick PR Flow (GitHub)","text":"<pre><code>git switch -c feat/x\n# edit, add, commit\ngit push -u origin feat/x\n# open PR on GitHub\n</code></pre> <p>See also: the full guide \"The Definitive Guide to Version Control with Git and GitHub\".</p>","tags":["Git","DevOps"]},{"location":"blogs/git-101-cheat-sheet/#stay-updated","title":"Stay Updated","text":"<p>Join my newsletter for the latest insights on Document AI, RAG, and LLM technologies:</p>","tags":["Git","DevOps"]},{"location":"blogs/git-101-cheat-sheet/#share-this-post","title":"Share This Post","text":"<p>Share on  Share on </p>","tags":["Git","DevOps"]},{"location":"blogs/pandas-missing-values/","title":"Handle Missing Values in Pandas Without Losing Information","text":"<p>Missing values are inevitable in real-world datasets. This guide covers proven methods to handle missing data in pandas without compromising data integrity or analytical accuracy.</p>","tags":["Pandas"]},{"location":"blogs/pandas-missing-values/#what-are-missing-values-in-pandas","title":"What Are Missing Values in Pandas","text":"<p>Missing values in pandas are represented as <code>NaN</code> (Not a Number), <code>None</code>, or <code>NaT</code> (Not a Time) for datetime objects. These occur due to:</p> <ul> <li>Data collection errors</li> <li>System failures during data transmission</li> <li>Intentionally left blank fields</li> <li>Data merging operations</li> <li>File corruption</li> </ul>","tags":["Pandas"]},{"location":"blogs/pandas-missing-values/#how-to-detect-missing-values","title":"How to Detect Missing Values","text":"Basic Detection MethodsAdvanced Detection Techniques <pre><code>import pandas as pd\nimport numpy as np\n\n# Create sample dataset with missing values\ndf = pd.DataFrame({\n    'name': ['Alice', 'Bob', None, 'David'],\n    'age': [25, np.nan, 30, 35],\n    'salary': [50000, 60000, np.nan, 70000],\n    'department': ['IT', 'HR', 'IT', None]\n})\n\n# Check for missing values\nprint(df.isnull().sum())\nprint(df.info())\n</code></pre> <pre><code># Percentage of missing values per column\nmissing_percentage = (df.isnull().sum() / len(df)) * 100\nprint(missing_percentage)\n\n# Identify rows with any missing values\nrows_with_missing = df[df.isnull().any(axis=1)]\nprint(rows_with_missing)\n\n# Count missing values per row\ndf['missing_count'] = df.isnull().sum(axis=1)\n</code></pre>","tags":["Pandas"]},{"location":"blogs/pandas-missing-values/#methods-to-handle-missing-values","title":"Methods to Handle Missing Values","text":"","tags":["Pandas"]},{"location":"blogs/pandas-missing-values/#1-removal-methods","title":"1. Removal Methods","text":"Drop Rows with Missing ValuesDrop Columns with Missing Values <pre><code># Drop rows with any missing values\ndf_dropped_rows = df.dropna()\n\n# Drop rows with missing values in specific columns\ndf_dropped_specific = df.dropna(subset=['age', 'salary'])\n\n# Drop rows with all missing values\ndf_dropped_all = df.dropna(how='all')\n</code></pre> <pre><code># Drop columns with any missing values\ndf_dropped_cols = df.dropna(axis=1)\n\n# Drop columns with more than 50% missing values\nthreshold = len(df) * 0.5\ndf_dropped_threshold = df.dropna(axis=1, thresh=threshold)\n</code></pre>","tags":["Pandas"]},{"location":"blogs/pandas-missing-values/#2-imputation-methods","title":"2. Imputation Methods","text":"Simple ImputationForward and Backward FillInterpolation Methods <pre><code># Fill with constant value\ndf_filled_constant = df.fillna(0)\n\n# Fill with mean for numeric columns\nnumeric_columns = df.select_dtypes(include=[np.number]).columns\ndf[numeric_columns] = df[numeric_columns].fillna(df[numeric_columns].mean())\n\n# Fill with median\ndf[numeric_columns] = df[numeric_columns].fillna(df[numeric_columns].median())\n\n# Fill with mode for categorical columns\ncategorical_columns = df.select_dtypes(include=['object']).columns\nfor col in categorical_columns:\n    df[col] = df[col].fillna(df[col].mode()[0])\n</code></pre> <pre><code># Forward fill (use previous value)\ndf_ffill = df.fillna(method='ffill')\n\n# Backward fill (use next value)\ndf_bfill = df.fillna(method='bfill')\n\n# Combine both methods\ndf_combined = df.fillna(method='ffill').fillna(method='bfill')\n</code></pre> <pre><code># Linear interpolation for time series\ndf_interpolated = df.interpolate(method='linear')\n\n# Polynomial interpolation\ndf_poly = df.interpolate(method='polynomial', order=2)\n\n# Time-based interpolation for datetime index\ndf_time = df.interpolate(method='time')\n</code></pre>","tags":["Pandas"]},{"location":"blogs/pandas-missing-values/#3-advanced-imputation-techniques","title":"3. Advanced Imputation Techniques","text":"","tags":["Pandas"]},{"location":"blogs/pandas-missing-values/#using-scikit-learn-imputers","title":"Using Scikit-learn Imputers","text":"<pre><code>from sklearn.impute import SimpleImputer, KNNImputer\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\n\n# Simple imputer with strategy\nimputer_mean = SimpleImputer(strategy='mean')\ndf_numeric = df.select_dtypes(include=[np.number])\ndf_imputed_mean = pd.DataFrame(\n    imputer_mean.fit_transform(df_numeric),\n    columns=df_numeric.columns\n)\n\n# KNN imputation\nknn_imputer = KNNImputer(n_neighbors=3)\ndf_knn_imputed = pd.DataFrame(\n    knn_imputer.fit_transform(df_numeric),\n    columns=df_numeric.columns\n)\n\n# Iterative imputation (MICE)\niterative_imputer = IterativeImputer(random_state=42)\ndf_iterative = pd.DataFrame(\n    iterative_imputer.fit_transform(df_numeric),\n    columns=df_numeric.columns\n)\n</code></pre>","tags":["Pandas"]},{"location":"blogs/pandas-missing-values/#column-specific-handling-strategies","title":"Column-Specific Handling Strategies","text":"Numeric ColumnsCategorical Columns <pre><code>def handle_numeric_missing(df, column, method='mean'):\n    \"\"\"Handle missing values in numeric columns\"\"\"\n    if method == 'mean':\n        return df[column].fillna(df[column].mean())\n    elif method == 'median':\n        return df[column].fillna(df[column].median())\n    elif method == 'mode':\n        return df[column].fillna(df[column].mode()[0])\n    elif method == 'interpolate':\n        return df[column].interpolate()\n    else:\n        raise ValueError(\"Method must be 'mean', 'median', 'mode', or 'interpolate'\")\n\n# Apply to age column\ndf['age_filled'] = handle_numeric_missing(df, 'age', method='median')\n</code></pre> <pre><code>def handle_categorical_missing(df, column, method='mode'):\n    \"\"\"Handle missing values in categorical columns\"\"\"\n    if method == 'mode':\n        return df[column].fillna(df[column].mode()[0])\n    elif method == 'unknown':\n        return df[column].fillna('Unknown')\n    elif method == 'frequent':\n        most_frequent = df[column].value_counts().index[0]\n        return df[column].fillna(most_frequent)\n    else:\n        raise ValueError(\"Method must be 'mode', 'unknown', or 'frequent'\")\n\n# Apply to department column\ndf['department_filled'] = handle_categorical_missing(df, 'department', method='mode')\n</code></pre>","tags":["Pandas"]},{"location":"blogs/pandas-missing-values/#domain-specific-imputation","title":"Domain-Specific Imputation","text":"Group-Based ImputationConditional Imputation <pre><code># Fill missing values based on group statistics\ndf['salary_group_filled'] = df.groupby('department')['salary'].transform(\n    lambda x: x.fillna(x.mean())\n)\n\n# Fill missing values with group mode\ndf['age_group_filled'] = df.groupby('department')['age'].transform(\n    lambda x: x.fillna(x.median())\n)\n</code></pre> <pre><code># Conditional filling based on other columns\ndef conditional_fill(row):\n    if pd.isna(row['salary']):\n        if row['department'] == 'IT':\n            return 55000  # Average IT salary\n        elif row['department'] == 'HR':\n            return 45000  # Average HR salary\n        else:\n            return 50000  # Default salary\n    return row['salary']\n\ndf['salary_conditional'] = df.apply(conditional_fill, axis=1)\n</code></pre>","tags":["Pandas"]},{"location":"blogs/pandas-missing-values/#validation-and-quality-checks","title":"Validation and Quality Checks","text":"","tags":["Pandas"]},{"location":"blogs/pandas-missing-values/#validate-imputation-results","title":"Validate Imputation Results","text":"<pre><code>def validate_imputation(original_df, imputed_df):\n    \"\"\"Validate imputation results\"\"\"\n    print(\"Original missing values:\", original_df.isnull().sum().sum())\n    print(\"Imputed missing values:\", imputed_df.isnull().sum().sum())\n\n    # Check if distribution is preserved\n    for col in original_df.select_dtypes(include=[np.number]).columns:\n        if col in imputed_df.columns:\n            original_mean = original_df[col].mean()\n            imputed_mean = imputed_df[col].mean()\n            print(f\"{col} - Original mean: {original_mean:.2f}, Imputed mean: {imputed_mean:.2f}\")\n\nvalidate_imputation(df, df_imputed_mean)\n</code></pre>","tags":["Pandas"]},{"location":"blogs/pandas-missing-values/#track-imputation-changes","title":"Track Imputation Changes","text":"<pre><code># Create indicator variables for imputed values\nfor col in df.columns:\n    if df[col].isnull().any():\n        df[f'{col}_was_missing'] = df[col].isnull()\n\n# Analyze impact of missing values\nmissing_impact = df.groupby('salary_was_missing')['age'].mean()\nprint(missing_impact)\n</code></pre>","tags":["Pandas"]},{"location":"blogs/pandas-missing-values/#best-practices","title":"Best Practices","text":"","tags":["Pandas"]},{"location":"blogs/pandas-missing-values/#1-analyze-missing-data-patterns","title":"1. Analyze Missing Data Patterns","text":"<pre><code>import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Visualize missing data patterns\nplt.figure(figsize=(10, 6))\nsns.heatmap(df.isnull(), cbar=True, yticklabels=False)\nplt.title('Missing Data Patterns')\nplt.show()\n</code></pre>","tags":["Pandas"]},{"location":"blogs/pandas-missing-values/#2-choose-appropriate-method","title":"2. Choose Appropriate Method","text":"<ul> <li>Listwise deletion: When missing data is less than 5% and random</li> <li>Mean/Median imputation: For normally distributed numeric data</li> <li>Mode imputation: For categorical variables</li> <li>Interpolation: For time series data</li> <li>KNN imputation: When missing data has patterns</li> <li>MICE: For complex missing data mechanisms</li> </ul>","tags":["Pandas"]},{"location":"blogs/pandas-missing-values/#3-document-imputation-decisions","title":"3. Document Imputation Decisions","text":"<pre><code># Create imputation log\nimputation_log = {\n    'column': [],\n    'missing_count': [],\n    'missing_percentage': [],\n    'imputation_method': [],\n    'imputation_value': []\n}\n\nfor col in df.columns:\n    missing_count = df[col].isnull().sum()\n    if missing_count &gt; 0:\n        imputation_log['column'].append(col)\n        imputation_log['missing_count'].append(missing_count)\n        imputation_log['missing_percentage'].append((missing_count / len(df)) * 100)\n        # Add method and value used\n\nimputation_df = pd.DataFrame(imputation_log)\nprint(imputation_df)\n</code></pre>","tags":["Pandas"]},{"location":"blogs/pandas-missing-values/#common-pitfalls-to-avoid","title":"Common Pitfalls to Avoid","text":"","tags":["Pandas"]},{"location":"blogs/pandas-missing-values/#1-data-leakage-in-imputation","title":"1. Data Leakage in Imputation","text":"<pre><code># Wrong: Using entire dataset statistics\n# df['salary'] = df['salary'].fillna(df['salary'].mean())\n\n# Correct: Use only training set statistics\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test = train_test_split(df, test_size=0.2, random_state=42)\n\n# Calculate imputation values from training set only\ntrain_mean = X_train['salary'].mean()\nX_train['salary'] = X_train['salary'].fillna(train_mean)\nX_test['salary'] = X_test['salary'].fillna(train_mean)\n</code></pre>","tags":["Pandas"]},{"location":"blogs/pandas-missing-values/#2-ignoring-missing-data-mechanism","title":"2. Ignoring Missing Data Mechanism","text":"<pre><code># Test if missing data is random\nfrom scipy.stats import chi2_contingency\n\n# Create missing indicator\ndf['salary_missing'] = df['salary'].isnull()\n\n# Test relationship with other variables\ncontingency_table = pd.crosstab(df['department'], df['salary_missing'])\nchi2, p_value, dof, expected = chi2_contingency(contingency_table)\nprint(f\"P-value: {p_value}\")  # If p &lt; 0.05, missing data is not random\n</code></pre>","tags":["Pandas"]},{"location":"blogs/pandas-missing-values/#integration-with-data-pipelines","title":"Integration with Data Pipelines","text":"<p>When implementing missing value handling in production environments, consider using automated data cleaning pipelines. This approach ensures consistent handling across different datasets and reduces manual intervention.</p>","tags":["Pandas"]},{"location":"blogs/pandas-missing-values/#conclusion","title":"Conclusion","text":"","tags":["Pandas"]},{"location":"blogs/pandas-missing-values/#handling-missing-values-effectively-requires-understanding-your-data-choosing-appropriate-methods-and-validating-results-the-key-is-to-preserve-data-integrity-while-maintaining-statistical-properties-of-your-dataset-always-document-your-imputation-strategy-and-test-its-impact-on-downstream-analysis-or-model-performance","title":"Handling missing values effectively requires understanding your data, choosing appropriate methods, and validating results. The key is to preserve data integrity while maintaining statistical properties of your dataset. Always document your imputation strategy and test its impact on downstream analysis or model performance.","text":"","tags":["Pandas"]},{"location":"blogs/pandas-missing-values/#stay-updated","title":"Stay Updated","text":"<p>Join my newsletter for the latest insights on Document AI, RAG, and LLM technologies:</p>","tags":["Pandas"]},{"location":"blogs/pandas-missing-values/#share-this-post","title":"Share This Post","text":"<p>Share on  Share on </p>","tags":["Pandas"]},{"location":"blogs/lightrag-bm25-hybrid-search/","title":"BM25 Hybrid Search with LightRAG","text":"<p>Vector search misses keyword-heavy queries. BM25 misses semantic similarity. Combine both with hybrid search for better retrieval recall.</p>","tags":["RAG","LightRAG","Retrival"]},{"location":"blogs/lightrag-bm25-hybrid-search/#why-hybrid-search","title":"Why Hybrid Search","text":"<p>Pure vector search struggles with:</p> <ul> <li>Exact product codes, IDs, or technical terms</li> <li>Queries where the user's exact phrasing matters</li> <li>Sparse vocabularies (legal, medical)</li> </ul> <p>BM25 (lexical) handles these well but misses paraphrases and synonyms. Hybrid search combines both for the best of both worlds.</p>","tags":["RAG","LightRAG","Retrival"]},{"location":"blogs/lightrag-bm25-hybrid-search/#implementation","title":"Implementation","text":"<p>Install dependencies:</p> <pre><code>uv pip install faiss-cpu rank-bm25 openai\n</code></pre> <p>Hybrid retriever with Reciprocal Rank Fusion (RRF):</p> <pre><code>from typing import List, Tuple\nimport faiss\nimport numpy as np\nfrom rank_bm25 import BM25Okapi\nfrom openai import OpenAI\n\n\nclass HybridRetriever:\n    \"\"\"Combines FAISS vector search with BM25 lexical search.\"\"\"\n\n    def __init__(\n        self, \n        texts: List[str], \n        sources: List[str],\n        embedding_model: str = \"text-embedding-3-small\"\n    ):\n        self.texts = texts\n        self.sources = sources\n        self.embedding_model = embedding_model\n\n        # Build FAISS index\n        self.faiss_index = self._build_faiss_index()\n\n        # Build BM25 index\n        tokenized = [t.lower().split() for t in texts]\n        self.bm25 = BM25Okapi(tokenized)\n\n    def _build_faiss_index(self) -&gt; faiss.IndexFlatIP:\n        client = OpenAI()\n        vecs = client.embeddings.create(\n            input=self.texts, \n            model=self.embedding_model\n        ).data\n        X = np.array([v.embedding for v in vecs]).astype(\"float32\")\n        faiss.normalize_L2(X)\n\n        idx = faiss.IndexFlatIP(X.shape[1])\n        idx.add(X)\n        return idx\n\n    def _embed_query(self, query: str) -&gt; np.ndarray:\n        client = OpenAI()\n        resp = client.embeddings.create(input=[query], model=self.embedding_model)\n        vec = np.array([resp.data[0].embedding]).astype(\"float32\")\n        faiss.normalize_L2(vec)\n        return vec\n\n    def _vector_search(self, query: str, k: int) -&gt; List[Tuple[int, float]]:\n        q = self._embed_query(query)\n        D, I = self.faiss_index.search(q, k)\n        return [(int(I[0][i]), float(D[0][i])) for i in range(len(I[0]))]\n\n    def _bm25_search(self, query: str, k: int) -&gt; List[Tuple[int, float]]:\n        tokens = query.lower().split()\n        scores = self.bm25.get_scores(tokens)\n        top_k = np.argsort(scores)[::-1][:k]\n        return [(int(i), float(scores[i])) for i in top_k]\n\n    def search(\n        self, \n        query: str, \n        k: int = 4, \n        vector_weight: float = 0.5,\n        rrf_k: int = 60\n    ) -&gt; List[Tuple[str, str, float]]:\n        \"\"\"\n        Hybrid search using Reciprocal Rank Fusion.\n\n        Args:\n            query: Search query\n            k: Number of results to return\n            vector_weight: Weight for vector results (0-1)\n            rrf_k: RRF constant (default 60)\n        \"\"\"\n        # Get more candidates than needed for fusion\n        n_candidates = k * 3\n\n        vector_results = self._vector_search(query, n_candidates)\n        bm25_results = self._bm25_search(query, n_candidates)\n\n        # Build rank maps\n        vector_ranks = {idx: rank for rank, (idx, _) in enumerate(vector_results)}\n        bm25_ranks = {idx: rank for rank, (idx, _) in enumerate(bm25_results)}\n\n        # RRF fusion\n        all_indices = set(vector_ranks.keys()) | set(bm25_ranks.keys())\n        scores = {}\n\n        for idx in all_indices:\n            v_rank = vector_ranks.get(idx, n_candidates)\n            b_rank = bm25_ranks.get(idx, n_candidates)\n\n            v_score = vector_weight / (rrf_k + v_rank)\n            b_score = (1 - vector_weight) / (rrf_k + b_rank)\n            scores[idx] = v_score + b_score\n\n        # Sort and return top k\n        ranked = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:k]\n        return [(self.texts[idx], self.sources[idx], score) for idx, score in ranked]\n</code></pre>","tags":["RAG","LightRAG","Retrival"]},{"location":"blogs/lightrag-bm25-hybrid-search/#usage","title":"Usage","text":"<pre><code>corpus = {\n    \"SKU-12345.md\": \"Product SKU-12345 is a wireless mouse with 2.4GHz connectivity.\",\n    \"returns.md\": \"Customers may return items within 30 days with receipt.\",\n    \"warranty.md\": \"Electronics include a 1-year limited warranty.\",\n}\n\ntexts, sources = [], []\nfor src, text in corpus.items():\n    texts.append(text)\n    sources.append(src)\n\nretriever = HybridRetriever(texts, sources)\n\n# Keyword query - BM25 helps\nresults = retriever.search(\"SKU-12345\", k=3)\n\n# Semantic query - vector helps\nresults = retriever.search(\"how long can I return a product\", k=3)\n</code></pre>","tags":["RAG","LightRAG","Retrival"]},{"location":"blogs/lightrag-bm25-hybrid-search/#tuning-hybrid-search","title":"Tuning Hybrid Search","text":"Parameter Default Notes <code>vector_weight</code> 0.5 Increase for semantic-heavy queries <code>rrf_k</code> 60 Standard RRF constant, rarely needs tuning <code>n_candidates</code> k * 3 More candidates = better fusion, more cost <p>Start with equal weights. If users search exact codes/IDs often, lower <code>vector_weight</code> to 0.3.</p>","tags":["RAG","LightRAG","Retrival"]},{"location":"blogs/lightrag-bm25-hybrid-search/#when-to-use-hybrid","title":"When to Use Hybrid","text":"<p>Use hybrid search when:</p> <ul> <li>Corpus contains technical terms, IDs, or codes</li> <li>Users search with exact phrases</li> <li>Pure vector search shows low recall on keyword queries</li> </ul> <p>Skip hybrid if your queries are purely semantic and corpus is natural language. See LightRAG: Lean RAG for the pure vector approach.</p>","tags":["RAG","LightRAG","Retrival"]},{"location":"blogs/lightrag-bm25-hybrid-search/#related","title":"Related","text":"<ul> <li>LightRAG: Lean RAG with Benchmarks</li> <li>Reranking for Better RAG Retrieval</li> </ul>","tags":["RAG","LightRAG","Retrival"]},{"location":"blogs/lightrag-bm25-hybrid-search/#stay-updated","title":"Stay Updated","text":"<p>Join my newsletter for the latest insights on Document AI, RAG, and LLM technologies:</p>","tags":["RAG","LightRAG","Retrival"]},{"location":"blogs/lightrag-bm25-hybrid-search/#share-this-post","title":"Share This Post","text":"<p>Share on  Share on </p>","tags":["RAG","LightRAG","Retrival"]},{"location":"blogs/lightrag-fast-retrieval-augmented-generation/","title":"LightRAG: Lean RAG with Benchmarks","text":"<p>LightRAG is a minimal RAG toolkit that strips away heavy abstractions. Here\u2019s a complete build with code, performance numbers versus a LangChain baseline, and when LightRAG is the right choice.</p>","tags":["RAG","LightRAG"]},{"location":"blogs/lightrag-fast-retrieval-augmented-generation/#why-lightrag","title":"Why LightRAG","text":"<p>For small, self-hosted RAG services, I often don\u2019t need callbacks, agents, or complex runtime graphs. I need:</p> <ul> <li>Predictable latency on CPU</li> <li>Tiny dependency surface</li> <li>Explicit control over chunking, retrieval, and prompts</li> </ul> <p>LightRAG gives me that \u2014 a thin layer over embeddings, a vector index, and prompt composition. If you\u2019re shipping a single-purpose Q&amp;A with tight cold-start budgets, this approach beats large frameworks.</p>","tags":["RAG","LightRAG"]},{"location":"blogs/lightrag-fast-retrieval-augmented-generation/#architecture","title":"Architecture","text":"<ol> <li>Ingest Markdown/PDF \u2192 normalize text</li> <li>Chunk with conservative overlap</li> <li>Embed with OpenAI (or local) embeddings</li> <li>Index with FAISS (in-memory) or sqlite-backed store</li> <li>Retrieve top-k and compose a strict prompt</li> <li>Generate with a small LLM; enforce citations</li> </ol>","tags":["RAG","LightRAG"]},{"location":"blogs/lightrag-fast-retrieval-augmented-generation/#implementation-minimal-dependency-stack","title":"Implementation (minimal dependency stack)","text":"<pre><code>uv pip install faiss-cpu tiktoken openai\n</code></pre> <pre><code>from __future__ import annotations\nimport os\nimport time\nfrom dataclasses import dataclass\nfrom typing import List, Tuple\n\nimport faiss\nimport numpy as np\nfrom openai import OpenAI\n\n\ndef split_text(text: str, chunk_size: int = 300, overlap: int = 50) -&gt; List[str]:\n    chunks, start = [], 0\n    while start &lt; len(text):\n        end = min(len(text), start + chunk_size)\n        chunks.append(text[start:end])\n        start = end - overlap\n        if start &lt; 0: start = 0\n    return chunks\n\n\ndef embed_texts(texts: List[str], model: str = \"text-embedding-3-small\") -&gt; np.ndarray:\n    client = OpenAI()\n    # batch for throughput in production\n    vecs = client.embeddings.create(input=texts, model=model).data\n    return np.array([v.embedding for v in vecs]).astype(\"float32\")\n\n\n@dataclass\nclass Index:\n    index: faiss.IndexFlatIP\n    vectors: np.ndarray\n    texts: List[str]\n    sources: List[str]\n\n\ndef build_index(pairs: List[Tuple[str, str]]) -&gt; Index:\n    # pairs: (source, text)\n    texts = [t for _, t in pairs]\n    sources = [s for s, _ in pairs]\n    X = embed_texts(texts)\n    # normalize for cosine similarity via inner product\n    faiss.normalize_L2(X)\n    idx = faiss.IndexFlatIP(X.shape[1])\n    idx.add(X)\n    return Index(index=idx, vectors=X, texts=texts, sources=sources)\n\n\ndef search(idx: Index, query: str, k: int = 4):\n    q = embed_texts([query])\n    faiss.normalize_L2(q)\n    D, I = idx.index.search(q, k)\n    hits = [(idx.texts[i], idx.sources[i], float(D[0][j])) for j, i in enumerate(I[0])]\n    return hits\n\n\ndef ask(idx: Index, question: str) -&gt; str:\n    hits = search(idx, question, k=4)\n    context = \"\\n\\n\".join([f\"[{src}]\\n{text}\" for text, src, _ in hits])\n    prompt = (\n        \"You answer strictly from the context. If unsure, say you don't know.\\n\"\n        f\"Question: {question}\\n\\nContext:\\n{context}\\n\\n\"\n        \"Answer with cited sources in [source] form.\"\n    )\n    client = OpenAI()\n    resp = client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        messages=[{\"role\": \"user\", \"content\": prompt}],\n        temperature=0,\n    )\n    return resp.choices[0].message.content\n\n\nif __name__ == \"__main__\":\n    corpus = {\n        \"returns.md\": \"Customers may return items within 30 days with receipt.\",\n        \"shipping.md\": \"Standard shipping 3-5 business days; expedited available.\",\n        \"warranty.md\": \"Electronics include a 1-year limited warranty.\",\n    }\n    pairs = []\n    for src, text in corpus.items():\n        for chunk in split_text(text):\n            pairs.append((src, chunk))\n\n    idx = build_index(pairs)\n    out = ask(idx, \"What is the return window?\")\n    print(out)\n</code></pre> <p>Notes:</p> <ul> <li>This is short, dependency-light, and easy to port to serverless.</li> <li>We normalize embeddings to approximate cosine similarity with FAISS inner product.</li> <li>Replace OpenAI with local embeddings/LLMs as needed.</li> </ul>","tags":["RAG","LightRAG"]},{"location":"blogs/lightrag-fast-retrieval-augmented-generation/#benchmarks-vs-langchain-baseline-my-runs","title":"Benchmarks vs LangChain baseline (my runs)","text":"<p>Environment: M2, 16GB RAM, small corpus (\u2264 500 chunks), <code>gpt-4o-mini</code>.</p> Approach p50 latency p95 latency Context tokens LOC LightRAG (this) 420 ms 790 ms ~900 ~120 LangChain RAG 520 ms 950 ms ~950 ~200 <p>Interpretation:</p> <ul> <li>The difference comes from fewer abstractions and tighter control of retriever parameters.</li> <li>On larger corpora, both converge; network/model latency dominates. Use whichever improves your team\u2019s velocity.</li> </ul>","tags":["RAG","LightRAG"]},{"location":"blogs/lightrag-fast-retrieval-augmented-generation/#retrieval-choices-and-trade-offs","title":"Retrieval choices and trade-offs","text":"<ul> <li>Chunking: Start at 300/50. For long legal text, 600/80 reduces cross-chunk answers.</li> <li>k: 3\u20135 for narrow domains. Reduce if you see mixed sources in answers.</li> <li>Re-ranking: For noisy corpora, add a small lexical pass (BM25) before vector search.</li> <li>Guardrails: Reject answers without <code>[source]</code>; ask a follow-up for clarification.</li> </ul>","tags":["RAG","LightRAG"]},{"location":"blogs/lightrag-fast-retrieval-augmented-generation/#when-to-prefer-lightrag-over-langchain","title":"When to prefer LightRAG over LangChain","text":"<ul> <li>You deploy on serverless/edge with cold start constraints.</li> <li>Team is small, prefers explicit over abstract.</li> <li>You only need retrieval + prompt + LLM, not agents or tools.</li> </ul> <p>When to stick with LangChain: you need tracing, callbacks, streaming tools, or plan to compose multi-step workflows. See /blogs/does-langchain-use-rag.</p>","tags":["RAG","LightRAG"]},{"location":"blogs/lightrag-fast-retrieval-augmented-generation/#data-quality-pre-checks-dont-skip","title":"Data quality pre-checks (don\u2019t skip)","text":"<ul> <li>Remove duplicated headers/footers and OCR noise.</li> <li>Validate anomalies in numeric tables \u2192 /blogs/detect-remove-outliers-python-iqr-zscore</li> <li>Handle missing values appropriately \u2192 /blogs/pandas-missing-values</li> <li>Ensure shapes stay consistent in preprocessing \u2192 /blogs/difference-reshape-flatten-numpy</li> </ul>","tags":["RAG","LightRAG"]},{"location":"blogs/lightrag-fast-retrieval-augmented-generation/#business-value-from-recent-work","title":"Business value from recent work","text":"<ul> <li>18\u201325% latency reduction in FAQ assistants by trimming abstractions and tuning k.</li> <li>15\u201320% cost reduction via smaller contexts and fewer retries.</li> <li>Fewer hallucinations after enforcing citation policy + evaluation gate.</li> </ul>","tags":["RAG","LightRAG"]},{"location":"blogs/lightrag-fast-retrieval-augmented-generation/#shipping-lean-rag-systems","title":"Shipping Lean RAG Systems","text":"<p>For production RAG systems, focus on predictable latency and a minimal stack. Design lean RAG services with clear SLAs, proper dashboards, and evaluation gates to ensure reliability and performance.</p>","tags":["RAG","LightRAG"]},{"location":"blogs/lightrag-fast-retrieval-augmented-generation/#related-articles","title":"Related Articles","text":"<ul> <li>LightRAG as a LangChain Retriever \u2014 Integrate LightRAG with LangChain chains</li> <li>BM25 Hybrid Search with LightRAG \u2014 Combine vector and lexical search</li> <li>FAISS Index Types for Production RAG \u2014 Scale beyond IndexFlatIP</li> <li>Reranking for Better RAG Retrieval \u2014 Add cross-encoder reranking</li> </ul>","tags":["RAG","LightRAG"]},{"location":"blogs/lightrag-fast-retrieval-augmented-generation/#stay-updated","title":"Stay Updated","text":"<p>Join my newsletter for the latest insights on Document AI, RAG, and LLM technologies:</p>","tags":["RAG","LightRAG"]},{"location":"blogs/lightrag-fast-retrieval-augmented-generation/#share-this-post","title":"Share This Post","text":"<p>Share on  Share on </p>","tags":["RAG","LightRAG"]},{"location":"blogs/lightrag-langchain-retriever-integration/","title":"LightRAG as a LangChain Retriever","text":"<p>Want LightRAG's lean retrieval with LangChain's chain ecosystem? Here's how to wrap LightRAG as a LangChain-compatible retriever.</p>","tags":["RAG","LightRAG","LangChain","Retrival"]},{"location":"blogs/lightrag-langchain-retriever-integration/#why-combine-lightrag-with-langchain","title":"Why Combine LightRAG with LangChain","text":"<p>LightRAG gives you minimal, fast retrieval. LangChain gives you chains, agents, and tooling. Sometimes you want both:</p> <ul> <li>Use LightRAG's tight FAISS retrieval for speed</li> <li>Plug into LangChain chains for downstream processing</li> <li>Keep retrieval explicit while using LangChain's callbacks and tracing</li> </ul>","tags":["RAG","LightRAG","LangChain","Retrival"]},{"location":"blogs/lightrag-langchain-retriever-integration/#implementing-the-retriever","title":"Implementing the Retriever","text":"<p>LangChain's <code>BaseRetriever</code> requires implementing <code>_get_relevant_documents</code>. Here's a complete wrapper:</p> <pre><code>from typing import List\nimport faiss\nimport numpy as np\nfrom openai import OpenAI\nfrom langchain_core.retrievers import BaseRetriever\nfrom langchain_core.documents import Document\nfrom langchain_core.callbacks import CallbackManagerForRetrieverRun\n\n\nclass LightRAGRetriever(BaseRetriever):\n    \"\"\"LangChain retriever backed by LightRAG's FAISS index.\"\"\"\n\n    index: faiss.IndexFlatIP\n    texts: List[str]\n    sources: List[str]\n    k: int = 4\n    embedding_model: str = \"text-embedding-3-small\"\n\n    class Config:\n        arbitrary_types_allowed = True\n\n    def _embed(self, text: str) -&gt; np.ndarray:\n        client = OpenAI()\n        resp = client.embeddings.create(input=[text], model=self.embedding_model)\n        vec = np.array([resp.data[0].embedding]).astype(\"float32\")\n        faiss.normalize_L2(vec)\n        return vec\n\n    def _get_relevant_documents(\n        self, \n        query: str, \n        *, \n        run_manager: CallbackManagerForRetrieverRun\n    ) -&gt; List[Document]:\n        q = self._embed(query)\n        D, I = self.index.search(q, self.k)\n\n        docs = []\n        for j, i in enumerate(I[0]):\n            docs.append(Document(\n                page_content=self.texts[i],\n                metadata={\"source\": self.sources[i], \"score\": float(D[0][j])}\n            ))\n        return docs\n</code></pre>","tags":["RAG","LightRAG","LangChain","Retrival"]},{"location":"blogs/lightrag-langchain-retriever-integration/#building-and-using-the-retriever","title":"Building and Using the Retriever","text":"<pre><code>from langchain_openai import ChatOpenAI\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_core.runnables import RunnablePassthrough\nfrom langchain_core.output_parsers import StrOutputParser\n\n# Build FAISS index (from LightRAG)\ndef build_lightrag_index(pairs):\n    client = OpenAI()\n    texts = [t for _, t in pairs]\n    sources = [s for s, _ in pairs]\n\n    vecs = client.embeddings.create(\n        input=texts, \n        model=\"text-embedding-3-small\"\n    ).data\n    X = np.array([v.embedding for v in vecs]).astype(\"float32\")\n    faiss.normalize_L2(X)\n\n    idx = faiss.IndexFlatIP(X.shape[1])\n    idx.add(X)\n    return idx, texts, sources\n\n# Create retriever\nidx, texts, sources = build_lightrag_index(corpus_pairs)\nretriever = LightRAGRetriever(index=idx, texts=texts, sources=sources, k=4)\n\n# Use in LangChain chain\nprompt = ChatPromptTemplate.from_template(\n    \"Answer from context only.\\n\\nContext: {context}\\n\\nQuestion: {question}\"\n)\n\nchain = (\n    {\"context\": retriever, \"question\": RunnablePassthrough()}\n    | prompt\n    | ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n    | StrOutputParser()\n)\n\nanswer = chain.invoke(\"What is the return policy?\")\n</code></pre>","tags":["RAG","LightRAG","LangChain","Retrival"]},{"location":"blogs/lightrag-langchain-retriever-integration/#when-to-use-this-pattern","title":"When to Use This Pattern","text":"<p>Use LightRAG + LangChain when:</p> <ul> <li>You need LangChain's tracing/callbacks but want lean retrieval</li> <li>Your team uses LangChain for other parts of the pipeline</li> <li>You want to gradually migrate from LangChain to pure LightRAG</li> </ul> <p>Stick with pure LightRAG if you don't need LangChain's abstractions. See the main LightRAG guide for the standalone approach.</p>","tags":["RAG","LightRAG","LangChain","Retrival"]},{"location":"blogs/lightrag-langchain-retriever-integration/#related","title":"Related","text":"<ul> <li>LightRAG: Lean RAG with Benchmarks</li> <li>Does LangChain Use RAG?</li> </ul>","tags":["RAG","LightRAG","LangChain","Retrival"]},{"location":"blogs/lightrag-langchain-retriever-integration/#stay-updated","title":"Stay Updated","text":"<p>Join my newsletter for the latest insights on Document AI, RAG, and LLM technologies:</p>","tags":["RAG","LightRAG","LangChain","Retrival"]},{"location":"blogs/lightrag-langchain-retriever-integration/#share-this-post","title":"Share This Post","text":"<p>Share on  Share on </p>","tags":["RAG","LightRAG","LangChain","Retrival"]},{"location":"blogs/modern-ci-pipeline/","title":"How you can set up a Python Code Quality CI Pipeline in 5 minutes","text":"<p>You can create a Python Code Quality CI pipeline using uv, Ruff, and ty within 5 minutes.</p> <p>Most of us begin a Python project with high hopes. We set up a clean virtual environment, organize a requirements file, and plan to add a linter\u2014then forget.</p> <p>But as we add more dependencies, the requirements file can get messy.  The same thing happens with our tests and documentation. They start out organized but quickly become hard to manage. So, we end up with a codebase that is difficult to maintain and understand.</p> <p>Before long, we start wondering why the code is breaking, tests are failing, or the documentation is out of date. So, we need to add a CI pipeline to help us catch these errors early and make sure everything works as it should.</p> <p>In this article, we\u2019ll set up a fast CI pipeline for code quality using <code>uv</code>, <code>Ruff</code>, and <code>ty</code> from Astral. We\u2019ll use a single lockfile (<code>uv.lock</code>), one linter/formatter (<code>ruff</code>), and one type checker (<code>ty</code>). </p> <ul> <li>lockfile consistency ensures the lockfile is in sync with <code>pyproject.toml</code> so installs are reproducible. We will use <code>uv lock --locked</code> for this.</li> <li>lint check spots potential bugs and code smells before they cause problems and helps write better code. We will use <code>ruff</code> for this.</li> <li>formatter check keeps your code style consistent across the entire project and across different editors making it easier to review code. We will use <code>ruff</code> for this.</li> <li>type checker makes sure your functions use the right data types and avoid type errors early. We will use <code>ty</code> for this.</li> </ul>","tags":["Ruff","CI/CD","DevOps"]},{"location":"blogs/modern-ci-pipeline/#dependency-check","title":"Dependency check","text":"<p>When we initialize a new project with <code>uv init</code>, it creates an empty <code>uv.lock</code> alongside <code>pyproject.toml</code>. This lockfile ensures everyone installs identical dependency graphs. If we modify <code>pyproject.toml</code> directly, the lock can drift out of sync. We can verify the lock is up to date with <code>uv lock --locked</code> (fails if regeneration would be required).</p> <p>So in our CI pipeline, we add a step to check that the lockfile is in sync with <code>pyproject.toml</code>. If it isn\u2019t, CI fails. Create <code>.github/workflows/code-quality.yml</code> and add:</p> <pre><code>name: Python Code Quality\non: [push, pull_request]\njobs:\n  lockfile-check:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - name: install uv\n        uses: astral-sh/setup-uv@v6\n        with:\n          version: 0.6.12\n      - run: uv lock --locked\n</code></pre> <p>Since we\u2019ll run lint and format checks in parallel, extract uv setup to a composite action. Create <code>.github/actions/setup/action.yml</code> with:</p> <pre><code>name: Install UV\ndescription: Install UV package manager\nruns:\n  using: composite\n  steps:\n    - name: install uv\n      uses: astral-sh/setup-uv@v6\n      with:\n        version: 0.6.12\n</code></pre> <p>You can then use this action in other workflows via the <code>uses</code> keyword: <pre><code>name: Python Code Quality\non: [push, pull_request]\njobs:\n  lockfile-check:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: ./.github/actions/setup\n      - run: uv lock --locked\n</code></pre></p>","tags":["Ruff","CI/CD","DevOps"]},{"location":"blogs/modern-ci-pipeline/#lint-check","title":"Lint check","text":"<p>The second step is linting. We\u2019ll use <code>ruff</code> to enforce standards and catch likely bugs. Add a <code>lint-check</code> job to <code>.github/workflows/code-quality.yml</code>:</p> <pre><code>lint-check:\n    runs-on: ubuntu-latest\n    needs: [lockfile-check]\n    steps:\n      - uses: actions/checkout@v4\n      - uses: ./.github/actions/setup\n      - run: uvx ruff check .\n</code></pre>","tags":["Ruff","CI/CD","DevOps"]},{"location":"blogs/modern-ci-pipeline/#formatter-check","title":"Formatter check","text":"<p>Use <code>ruff format</code> to enforce consistent formatting. Import sorting is handled by Ruff\u2019s isort rules during linting (not by the formatter). To validate formatting in CI, run <code>ruff format --check</code>. Add a <code>format-check</code> job to <code>.github/workflows/code-quality.yml</code>: <pre><code>format-check:\n    runs-on: ubuntu-latest\n    needs: [lockfile-check]\n    steps:\n      - uses: actions/checkout@v4\n      - uses: ./.github/actions/setup\n      - run: uvx ruff format --check .\n</code></pre></p>","tags":["Ruff","CI/CD","DevOps"]},{"location":"blogs/modern-ci-pipeline/#type-check","title":"Type check","text":"<p>Use <code>ty check</code> to run static type checks. <code>ty</code> is a fast, modern type checker. Add a <code>type-check</code> job to <code>.github/workflows/code-quality.yml</code>: <pre><code>type-check:\n    runs-on: ubuntu-latest\n    needs: [lockfile-check]\n    steps:\n      - uses: actions/checkout@v4\n      - uses: ./.github/actions/setup\n      - run: uvx ty check .\n</code></pre></p> <p>Note</p> <p><code>ty</code> is in preview state. Use this with caution. Another good alternative for static type checking is <code>pyright</code>.</p>","tags":["Ruff","CI/CD","DevOps"]},{"location":"blogs/modern-ci-pipeline/#full-ci-pipeline","title":"Full CI pipeline","text":"<pre><code>name: Python Code Quality\non: [push, pull_request]\njobs:\n  lockfile-check:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: ./.github/actions/setup\n      - run: uv lock --locked\n\n  lint-check:\n    runs-on: ubuntu-latest\n    needs: [lockfile-check]\n    steps:\n      - uses: actions/checkout@v4\n      - uses: ./.github/actions/setup\n      - run: uvx ruff check .\n\n  format-check:\n    runs-on: ubuntu-latest\n    needs: [lockfile-check]\n    steps:\n      - uses: actions/checkout@v4\n      - uses: ./.github/actions/setup\n      - run: uvx ruff format --check .\n\n  type-check:\n    runs-on: ubuntu-latest\n    needs: [lockfile-check]\n    steps:\n      - uses: actions/checkout@v4\n      - uses: ./.github/actions/setup\n      - run: uvx ty check .\n</code></pre>","tags":["Ruff","CI/CD","DevOps"]},{"location":"blogs/modern-ci-pipeline/#quick-walkthrough","title":"Quick walkthrough","text":"<ul> <li>lockfile-check: Verifies <code>uv.lock</code> is in sync with <code>pyproject.toml</code> using <code>uv lock --locked</code>. Fails early if the lock needs regeneration.</li> <li>lint-check: Runs <code>uvx ruff check .</code> to catch bugs and style issues. Import sorting is enforced by Ruff\u2019s isort rules here.</li> <li>format-check: Runs <code>uvx ruff format --check .</code> to ensure consistent formatting without modifying files.</li> <li>type-check: Runs <code>uvx ty check .</code> for fast static type analysis. <code>ty</code> is preview; <code>pyright</code> is a stable alternative.</li> <li>Parallelism: <code>needs: [lockfile-check]</code> means lint, format, and type checks run in parallel after the lockfile passes.</li> </ul>","tags":["Ruff","CI/CD","DevOps"]},{"location":"blogs/modern-ci-pipeline/#conclusion","title":"Conclusion","text":"<p>With just a few lines of YAML, you now have reproducible installs with <code>uv lock --locked</code>, fast linting and formatting via Ruff, and type checks with <code>ty</code> running on every push and pull request. This keeps drift in check, makes reviews calmer, and stops easy-to-miss issues from slipping into main.</p> <p>If you want to take it further, add tests with <code>pytest</code>, coverage thresholds, caching for <code>uv</code> and lint artifacts, and a build matrix across Python versions. Keep it fast and opinionated\u2014the best CI is the one that runs on every change without friction.</p>","tags":["Ruff","CI/CD","DevOps"]},{"location":"blogs/modern-ci-pipeline/#stay-updated","title":"Stay Updated","text":"<p>Join my newsletter for the latest insights on Document AI, RAG, and LLM technologies:</p>","tags":["Ruff","CI/CD","DevOps"]},{"location":"blogs/modern-ci-pipeline/#share-this-post","title":"Share This Post","text":"<p>Share on  Share on </p>","tags":["Ruff","CI/CD","DevOps"]},{"location":"blogs/nlp-document-summarization-eval/","title":"Document Summarization: Eval First","text":"<p>Document summarization is a critical NLP task that helps users quickly grasp key information from long documents. But how do you know if your model is actually working? This guide shows a workflow that starts with evaluation and acceptance criteria before touching models.</p>","tags":["NLP","Document AI"]},{"location":"blogs/nlp-document-summarization-eval/#why-eval-first","title":"Why eval-first","text":"<p>When I built an extractive summarizer for finance reports, we shipped faster by defining evaluation and acceptance criteria before touching models.</p>","tags":["NLP","Document AI"]},{"location":"blogs/nlp-document-summarization-eval/#workflow","title":"Workflow","text":"<ol> <li>Curate a small, representative dataset (20\u201350 docs)</li> <li>Define extractive baseline + abstractive model</li> <li>Compute ROUGE/BERTScore, then human checklist (coverage, faithfulness)</li> <li>Review failure modes and iterate on chunking/prompts</li> </ol> <pre><code>from __future__ import annotations\nfrom datasets import load_metric\n\n\ndef rouge(refs: list[str], hyps: list[str]):\n    metric = load_metric(\"rouge\")\n    scores = metric.compute(predictions=hyps, references=refs)\n    return {k: v.mid.fmeasure for k, v in scores.items()}\n\n\nif __name__ == \"__main__\":\n    refs = [\"Revenue increased due to subscriptions and lower churn.\"]\n    hyps = [\"Revenue increased from new subscriptions; churn was lower.\"]\n    print(rouge(refs, hyps))\n</code></pre>","tags":["NLP","Document AI"]},{"location":"blogs/nlp-document-summarization-eval/#human-checklist-print-and-use","title":"Human checklist (print and use)","text":"<ul> <li>Coverage: all key bullets present?</li> <li>Faithfulness: no invented numbers or facts?</li> <li>Specificity: numbers and entities preserved?</li> <li>Brevity: remove filler and boilerplate?</li> </ul> <p>Related: RAG and data quality posts to improve chunking/grounding:  /blogs/does-langchain-use-rag, /blogs/lightrag-fast-retrieval-augmented-generation, and /blogs/detect-remove-outliers-python-iqr-zscore.</p>","tags":["NLP","Document AI"]},{"location":"blogs/nlp-document-summarization-eval/#architecture","title":"Architecture","text":"<ol> <li>Ingest and clean text (see text-cleaning pipeline)</li> <li>Segment by sections; avoid cross-topic chunks</li> <li>Extractive baseline (TextRank or embedding-based key sentence selection)</li> <li>Abstractive refinement with constrained prompting</li> <li>Score with ROUGE/BERTScore + human checklist</li> </ol>","tags":["NLP","Document AI"]},{"location":"blogs/nlp-document-summarization-eval/#extractive-baseline-example","title":"Extractive baseline example","text":"<pre><code>from __future__ import annotations\nimport numpy as np\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n\ndef textrank_sentences(sentences: list[str], top_k: int = 5) -&gt; list[str]:\n    tfidf = TfidfVectorizer().fit_transform(sentences)\n    sim = (tfidf * tfidf.T).A\n    scores = sim.sum(axis=1)\n    idx = np.argsort(-scores)[:top_k]\n    return [sentences[i] for i in sorted(idx)]\n</code></pre>","tags":["NLP","Document AI"]},{"location":"blogs/nlp-document-summarization-eval/#abstractive-refinement-prompt-llm","title":"Abstractive refinement prompt (LLM)","text":"<pre><code>You are summarizing a section for financial analysts.\nConstraints:\n- Keep numbers and entities accurate.\n- No claims beyond the provided sentences.\n- Max 120 words.\n\nSentences:\n&lt;paste extractive sentences&gt;\n</code></pre>","tags":["NLP","Document AI"]},{"location":"blogs/nlp-document-summarization-eval/#metrics-and-acceptance-criteria","title":"Metrics and acceptance criteria","text":"<ul> <li>ROUGE-L \u2265 0.35 on validation set; BERTScore-F1 \u2265 0.86 on domain corpus.</li> <li>Human checklist pass rate \u2265 0.9 (sampled 20 summaries weekly).</li> <li>Drift alerts if either metric drops \u2265 10% week-over-week.</li> </ul>","tags":["NLP","Document AI"]},{"location":"blogs/nlp-document-summarization-eval/#failure-modes-and-fixes","title":"Failure modes and fixes","text":"<ul> <li>Missing critical bullet: increase top_k extractive or re-segment by section headings.</li> <li>Fabricated numbers: add unit tests scanning for number changes vs source.</li> <li>Repetition/bloat: enforce word cap and remove boilerplate via cleaning.</li> </ul>","tags":["NLP","Document AI"]},{"location":"blogs/nlp-document-summarization-eval/#integration-notes","title":"Integration notes","text":"<ul> <li>Store source sentence IDs alongside summaries for traceability.</li> <li>Log tokens, latency, and scores for each job; create dashboards.</li> <li>For long docs, summarize sections first, then synthesize an executive summary.</li> </ul>","tags":["NLP","Document AI"]},{"location":"blogs/nlp-document-summarization-eval/#stay-updated","title":"Stay Updated","text":"<p>Join my newsletter for the latest insights on Document AI, RAG, and LLM technologies:</p>","tags":["NLP","Document AI"]},{"location":"blogs/nlp-document-summarization-eval/#share-this-post","title":"Share This Post","text":"<p>Share on  Share on </p>","tags":["NLP","Document AI"]},{"location":"blogs/nlp-entity-matching-with-fuzzy-search/","title":"NLP Entity Matching with Fuzzy Search","text":"<p>Product catalogs rarely match 1:1. I combine lexical and semantic similarity with thresholds to minimize false matches.</p>","tags":["NLP"]},{"location":"blogs/nlp-entity-matching-with-fuzzy-search/#problem","title":"Problem","text":"<p>Product catalogs rarely match 1:1. I combine lexical and semantic similarity with thresholds to minimize false matches.</p>","tags":["NLP"]},{"location":"blogs/nlp-entity-matching-with-fuzzy-search/#approach","title":"Approach","text":"<ul> <li>Candidate generation with TF-IDF cosine</li> <li>Re-ranking with Jaro-Winkler for surface similarity</li> <li>Final semantic tie-breaker with small embeddings</li> </ul> <pre><code>from __future__ import annotations\nimport numpy as np\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n\ndef jaro_winkler(a: str, b: str) -&gt; float:\n    try:\n        import jellyfish\n        return jellyfish.jaro_winkler(a, b)\n    except Exception:\n        return 0.0\n\n\ndef match_entities(left: list[str], right: list[str], top_k: int = 5) -&gt; list[tuple[str, str, float]]:\n    tfidf = TfidfVectorizer(min_df=1, ngram_range=(1, 2))\n    Xl = tfidf.fit_transform(left)\n    Xr = tfidf.transform(right)\n    sims = cosine_similarity(Xl, Xr)\n    matches = []\n    for i, row in enumerate(sims):\n        idx = int(np.argmax(row))\n        jw = jaro_winkler(left[i], right[idx])\n        score = 0.7 * row[idx] + 0.3 * jw\n        matches.append((left[i], right[idx], float(score)))\n    return matches\n\n\nif __name__ == \"__main__\":\n    a = [\"Apple iPhone 13 Pro\", \"Samsung Galaxy S22\"]\n    b = [\"iPhone 13 Pro Max by Apple\", \"Galaxy S22 Ultra Samsung\"]\n    for m in match_entities(a, b):\n        print(m)\n</code></pre>","tags":["NLP"]},{"location":"blogs/nlp-entity-matching-with-fuzzy-search/#thresholds-and-qa","title":"Thresholds and QA","text":"<ul> <li>Accept \u2265 0.8 as confident match; 0.6\u20130.8 \u2192 manual review; &lt; 0.6 reject.</li> <li>Evaluate with precision@1 and manual spot-checks.</li> </ul>","tags":["NLP"]},{"location":"blogs/nlp-entity-matching-with-fuzzy-search/#architecture-workflow","title":"Architecture &amp; workflow","text":"<ol> <li>Normalize product titles (case, unicode, punctuation)</li> <li>Generate candidates via TF-IDF cosine (top-10)</li> <li>Re-rank with Jaro-Winkler; compute blended score</li> <li>Optional: embed with <code>text-embedding-3-small</code> for semantic tie-breakers</li> <li>Threshold routing: accept/review/reject</li> </ol>","tags":["NLP"]},{"location":"blogs/nlp-entity-matching-with-fuzzy-search/#evaluation-harness","title":"Evaluation harness","text":"<pre><code>from __future__ import annotations\nimport numpy as np\n\n\ndef precision_at_1(gold: list[tuple[str, str]], preds: list[tuple[str, str, float]]):\n    lookup = {a: b for a, b in gold}\n    hits = 0\n    for a, b, _ in preds:\n        hits += int(lookup.get(a) == b)\n    return hits / max(1, len(preds))\n\n\nif __name__ == \"__main__\":\n    gold = [(\"Apple iPhone 13 Pro\", \"iPhone 13 Pro Max by Apple\"), (\"Samsung Galaxy S22\", \"Galaxy S22 Ultra Samsung\")]\n    preds = match_entities([g[0] for g in gold], [g[1] for g in gold])\n    print({\"p@1\": precision_at_1(gold, preds)})\n</code></pre> <p>Target: \u2265 0.9 p@1 on clean catalogs; add human review queue for ambiguous ranges.</p>","tags":["NLP"]},{"location":"blogs/nlp-entity-matching-with-fuzzy-search/#edge-cases-and-fixes","title":"Edge cases and fixes","text":"<ul> <li>Brand aliases (e.g., Google vs Alphabet) \u2192 maintain alias map pre-match.</li> <li>Units and pack sizes (\"500ml\" vs \"0.5 L\") \u2192 normalize units.</li> <li>Noise tokens (\"new\", \"sale\") \u2192 remove stopwords tailored to catalog domain.</li> </ul>","tags":["NLP"]},{"location":"blogs/nlp-entity-matching-with-fuzzy-search/#integrations","title":"Integrations","text":"<ul> <li>Push accepted matches to MDM with versioned lineage.</li> <li>Emit ambiguous matches to a human-review dashboard with audit logs.</li> <li>Schedule nightly diffs; alert on drift in p@1.</li> </ul>","tags":["NLP"]},{"location":"blogs/nlp-entity-matching-with-fuzzy-search/#stay-updated","title":"Stay Updated","text":"<p>Join my newsletter for the latest insights on Document AI, RAG, and LLM technologies:</p>","tags":["NLP"]},{"location":"blogs/nlp-entity-matching-with-fuzzy-search/#share-this-post","title":"Share This Post","text":"<p>Share on  Share on </p>","tags":["NLP"]},{"location":"blogs/rag-for-knowledge-intensive-nlp-tasks/","title":"RAG for Knowledge-Intensive Tasks","text":"<p>Picture this: You're asking an AI about cancer treatments. It sounds super confident and gives you detailed answers. But here's the problem \u2014 it just made up a medical study that doesn't exist.</p> <p>That's not just embarrassing. When we're talking about healthcare, finance, or legal advice, these AI \"hallucinations\" can be downright dangerous.</p> <p>That's where RAG (Retrieval-Augmented Generation) comes in. Think of it as giving AI a fact-checker that actually works.</p>","tags":["RAG","Retrival","Embeddings","Document AI"]},{"location":"blogs/rag-for-knowledge-intensive-nlp-tasks/#what-youll-learn","title":"What You'll Learn","text":"<ul> <li>What makes some AI tasks need \"real\" knowledge</li> <li>Why even smart AI models mess up</li> <li>How RAG works (no PhD required)</li> <li>A simple code example you can try</li> <li>When to use RAG (and when not to)</li> </ul> <p>Ready? Let's dive in.</p> \u2022 \u2022 \u2022","tags":["RAG","Retrival","Embeddings","Document AI"]},{"location":"blogs/rag-for-knowledge-intensive-nlp-tasks/#what-are-knowledge-heavy-ai-tasks","title":"What Are Knowledge-Heavy AI Tasks?","text":"<p>Some AI tasks are like trivia questions, the answers are already \"baked into\" the AI's training. </p> <p>But others need fresh, specific information that changes over time or lives in private documents.</p> <p>Examples you've probably seen: * Customer service bots that need to know your company's policies * Legal AI that searches through case law * Medical AI that references the latest research * Financial bots that need real-time market data</p> <p>These tasks can't just rely on what the AI learned during training. They need access to live, up-to-date information.</p>","tags":["RAG","Retrival","Embeddings","Document AI"]},{"location":"blogs/rag-for-knowledge-intensive-nlp-tasks/#why-smart-ai-still-gets-things-wrong","title":"Why Smart AI Still Gets Things Wrong","text":"<p>Even the best AI models like GPT-4 have three big problems:</p> <p>1. They make stuff up: When they don't know something, they often invent plausible-sounding answers instead of saying \"I don't know.\"</p> <p>2. They have memory limits: Most AI can't read through thousands of pages at once. They forget things from earlier in long conversations.</p> <p>3. They don't know your private data: Out-of-the-box AI doesn't have access to your company docs, databases, or personal files.</p> <p>The result? Confident answers that are completely wrong.</p>","tags":["RAG","Retrival","Embeddings","Document AI"]},{"location":"blogs/rag-for-knowledge-intensive-nlp-tasks/#how-rag-fixes-this","title":"How RAG Fixes This","text":"<p>RAG is surprisingly simple. Instead of asking AI to remember everything, we give it a research assistant. Here's what happens:</p> <ol> <li>You ask a question</li> <li>The system searches relevant documents </li> <li>AI reads those documents and answers based on what it found</li> <li>You get a fact-based answer</li> </ol> <p></p> <p>It's like having an AI that can Google things before answering \u2014 except way more sophisticated.</p>","tags":["RAG","Retrival","Embeddings","Document AI"]},{"location":"blogs/rag-for-knowledge-intensive-nlp-tasks/#rag-vs-regular-ai-the-difference","title":"RAG vs Regular AI: The Difference","text":"Regular AI RAG-Powered AI Uses only training data Searches live documents Often makes things up Answers from real sources Can't access your files Works with your data Expensive for long texts More cost-effective","tags":["RAG","Retrival","Embeddings","Document AI"]},{"location":"blogs/rag-for-knowledge-intensive-nlp-tasks/#see-it-in-action-simple-code-example","title":"See It In Action: Simple Code Example","text":"<p>Want to try RAG yourself? Here's a basic example using Python:</p> <pre><code>from langchain.chat_models import ChatOpenAI\nfrom langchain.vectorstores import FAISS\nfrom langchain.embeddings import OpenAIEmbeddings\nfrom langchain.chains import RetrievalQA\n\n# Connect to your document database\nretriever = FAISS.load_local(\"my_documents\", OpenAIEmbeddings())\n\n# Set up the AI model\nllm = ChatOpenAI()\n\n# Create the RAG system\nqa_system = RetrievalQA(llm=llm, retriever=retriever)\n\n# Ask a question\nanswer = qa_system.run(\"What's our return policy?\")\nprint(answer)\n</code></pre> <p>This code creates an AI that can search through your documents before answering questions. </p> <p>Pretty cool, right?</p>","tags":["RAG","Retrival","Embeddings","Document AI"]},{"location":"blogs/rag-for-knowledge-intensive-nlp-tasks/#when-rag-might-be-overkill","title":"When RAG Might Be Overkill","text":"<p>RAG isn't always the answer. Skip it if you're doing:</p> <ul> <li>Simple text classification (like spam detection)</li> <li>Creative writing or brainstorming</li> <li>Tasks where the AI already knows enough</li> <li>Projects with very little data to search through</li> </ul> <p>\ud83d\udca1 Pro Tip: Sometimes the simplest solution is the best one.</p>","tags":["RAG","Retrival","Embeddings","Document AI"]},{"location":"blogs/rag-for-knowledge-intensive-nlp-tasks/#should-you-use-rag","title":"Should You Use RAG?","text":"<p>RAG is perfect if you're building:</p> <ul> <li>Company chatbots that need to know policies and procedures</li> <li>Research assistants that search through technical documents  </li> <li>Customer support that references product manuals</li> <li>Legal tools that find relevant case law</li> </ul> <p>Think of RAG as giving your AI both intelligence and access to information. That's a powerful combination.</p>","tags":["RAG","Retrival","Embeddings","Document AI"]},{"location":"blogs/rag-for-knowledge-intensive-nlp-tasks/#ready-to-get-started","title":"Ready to Get Started?","text":"<p>Here's your next steps:</p> <ol> <li>Pick a real problem \u2014 maybe your team's internal wiki or product docs</li> <li>Upload your documents to a vector database (FAISS is a good start)</li> <li>Connect it to an AI model using tools like LangChain</li> <li>Test it out with real questions</li> </ol> <p>The future isn't just about smarter AI \u2014 it's about AI that can actually find and use the right information.</p> <p>Start small, think big, and build something useful.</p> \u2022 \u2022 \u2022","tags":["RAG","Retrival","Embeddings","Document AI"]},{"location":"blogs/rag-for-knowledge-intensive-nlp-tasks/#need-help-building-your-rag-system","title":"Need Help Building Your RAG System?","text":"<p>Building a production-ready RAG system involves more than just connecting a few APIs. You need proper document preprocessing, vector database optimization, retrieval tuning, and seamless integration with your existing systems.</p> <p>I help companies like yours:</p> <ul> <li>Design and implement custom RAG architectures</li> <li>Optimize retrieval performance for your specific use case  </li> <li>Integrate RAG systems with existing workflows</li> <li>Scale AI solutions from prototype to production</li> </ul> <p>RAG is a powerful technique for building internal knowledge assistants, enhancing customer support, or creating domain-specific AI tools. Understanding these fundamentals will help you navigate the technical complexities and deliver results that work in production.</p>","tags":["RAG","Retrival","Embeddings","Document AI"]},{"location":"blogs/rag-for-knowledge-intensive-nlp-tasks/#stay-updated","title":"Stay Updated","text":"<p>Join my newsletter for the latest insights on Document AI, RAG, and LLM technologies:</p>","tags":["RAG","Retrival","Embeddings","Document AI"]},{"location":"blogs/rag-for-knowledge-intensive-nlp-tasks/#share-this-post","title":"Share This Post","text":"<p>Share on  Share on </p>","tags":["RAG","Retrival","Embeddings","Document AI"]},{"location":"blogs/ruff-modern-linter/","title":"Ruff: Modern Python Linter & Formatter Walkthrough","text":"<p>Writing clean, readable code is essential for collaboration and maintainability. Linters and formatters help us keep our codebase consistent and easy to understand.</p> <p>Linters like Flake8, Pylint, and mypy analyze your code and look for errors, stylistic issues, and suspicious constructs. On the other hand, formatters like Black and autopep8 help us format our code according to a consistent style.</p> <p>Although we have many tools to choose from, the main issue is juggling too many tools, which can be time-consuming and confusing.</p> <p>A better alternative is Ruff, a fast, easy-to-use tool that handles both linting and formatting. Similar to other tools, it has excellent defaults and a single, simple CLI.</p> <p>In this walkthrough, we\u2019ll set up Ruff with a simple, one-time configuration that works locally and integrates seamlessly with uv, pre-commit, and GitHub Actions.</p>","tags":["Ruff","CI/CD","Automation"]},{"location":"blogs/ruff-modern-linter/#installing-ruff","title":"Installing Ruff","text":"<p>Let's start by installing Ruff. </p> <p>Ruff works out of the box, so we don\u2019t need complicated setup steps. Here are several ways to install Ruff, depending on your system and preferences:</p> <p>Install Ruff globally using uv (recommended): <pre><code>uv tool install ruff@latest\n</code></pre> Or, add Ruff as a development dependency: <pre><code>uv add --dev ruff\n</code></pre> Or, install Ruff using pip: <pre><code>pip install ruff\n</code></pre> Or, install Ruff using pipx: <pre><code>pipx install ruff\n</code></pre></p> <p>If you use MacOS, you can use brew to install Ruff instead of uv. For other systems, the detailed installation instructions are available in the installation guide.</p> <p>Verify installation: after installing Ruff, you can verify the installation by running the following command:</p> <p><pre><code>ruff --version\n</code></pre> Once you see the version number, you know Ruff is installed correctly and we are ready to start using it. \u00a0</p>","tags":["Ruff","CI/CD","Automation"]},{"location":"blogs/ruff-modern-linter/#linting-your-python-code","title":"Linting Your Python Code","text":"<p>Note</p> <p>linter helps us to keep our code consistent and error-free, it does not mean that our code is bug free</p> <p><code>ruff check</code> is the primary entry point to the Ruff linter.t accepts a list of files or directories and lints all discovered Python files, optionally fixing any fixable errors. When linting a directory, Ruff recursively searches for Python files in that directory and all its subdirectories:</p> <p><pre><code>ruff check . # lint all files in the current directory\nruff check src/ # lint all files in the src directory\nruff check src/main.py # lint the main.py file\n</code></pre> We can also fix the errors using the <code>--fix</code> flag:</p> <p><pre><code>ruff check --fix . # fix all fixableerrors in the current directory\n</code></pre> we can also show only the changed files using the <code>--exit-non-zero-on-fix --quiet</code> flag: <pre><code>ruff check --exit-non-zero-on-fix --quiet . # show only the changed files\n</code></pre> When you\u2019re actively working on code, Ruff can simplify your workflow even more by informing you of errors as you develop. This will speed up the overall process and make you more productive.  </p> <p>To do this, we can use the <code>--watch</code> flag: <pre><code>ruff check  --watch  # lint all files in the current directory and watch for changes\n</code></pre> For the full list of supported options, run <code>ruff check --help</code>.</p>","tags":["Ruff","CI/CD","Automation"]},{"location":"blogs/ruff-modern-linter/#rule-selection","title":"Rule Selection","text":"<p>Ruff's linter mirrors Flake8's rule code system, in which each rule code consists of a one-to-three letter prefix, followed by three digits (e.g., F401). To know more about the rules we can use <code>ruff rule F401</code></p> <p>When you run this command, you get more details in Markdown format in your terminal:  <p>To apply a specific rule, use the <code>--select</code> flag: <pre><code>ruff check --select F401 . # lint all files in the current directory, focusing on the F401 rule\n</code></pre> The set of active rules is managed through the <code>lint.select</code>, <code>lint.extend-select</code>, and <code>lint.ignore</code> configurations in the <code>ruff.toml</code> file: ruff.toml<pre><code>[lint]\nselect = [\"E\", \"F\"]\nignore = [\"F401\"]\n</code></pre></p>","tags":["Ruff","CI/CD","Automation"]},{"location":"blogs/ruff-modern-linter/#formatting","title":"Formatting","text":"","tags":["Ruff","CI/CD","Automation"]},{"location":"blogs/ruff-modern-linter/#formatting_1","title":"Formatting","text":"<p>Ruff also formats code. Use it exactly like a formatter:</p> <pre><code># write changes to disk\nruff format .\n\n# validate formatting without writing\nruff format --check .\n</code></pre> <p>Tip: Import sorting is enforced by Ruff\u2019s lint rules (the <code>I</code> group), not by <code>ruff format</code>. Keep both <code>ruff check</code> and <code>ruff format</code> in your workflow.</p>","tags":["Ruff","CI/CD","Automation"]},{"location":"blogs/ruff-modern-linter/#configuration-pyprojecttoml","title":"Configuration (pyproject.toml)","text":"<p>Create or update <code>pyproject.toml</code> with a minimal Ruff config:</p> <pre><code>[tool.ruff]\nline-length = 100\ntarget-version = \"py311\"\n\n[tool.ruff.lint]\nselect = [\"E\", \"F\", \"I\"] # pycodestyle, pyflakes, isort\nignore = [\n  # add rule codes to ignore here, e.g., \"E203\"\n]\n\n[tool.ruff.format]\ndocstring-code-format = true\ndocstring-code-line-length = 88\n</code></pre> <p>Notes:</p> <ul> <li><code>select</code> adds rule families. <code>I</code> enables isort-style import rules.</li> <li><code>line-length</code> and <code>target-version</code> align formatter and linter expectations.</li> <li>Keep ignores small and documented; prefer fixing code.</li> </ul> <p>The Real Python article has more on configuration and rule groups: <code>realpython.com/ruff-python</code>.</p>","tags":["Ruff","CI/CD","Automation"]},{"location":"blogs/ruff-modern-linter/#pre-commit-hooks","title":"Pre-commit hooks","text":"<p>Add Ruff to <code>.pre-commit-config.yaml</code> to enforce locally before every commit:</p> <pre><code>repos:\n  - repo: https://github.com/astral-sh/ruff-pre-commit\n    rev: v0.6.9 # update to the latest stable\n    hooks:\n      - id: ruff\n        args: [\"--fix\"]\n      - id: ruff-format\n</code></pre> <p>Install hooks:</p> <pre><code>pre-commit install\n</code></pre>","tags":["Ruff","CI/CD","Automation"]},{"location":"blogs/ruff-modern-linter/#ci-with-github-actions-using-uv","title":"CI with GitHub Actions (using uv)","text":"<p>Create <code>.github/workflows/ruff.yml</code>:</p> <pre><code>name: Ruff Quality\non: [push, pull_request]\njobs:\n  ruff:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - name: Setup uv\n        uses: astral-sh/setup-uv@v6\n      - name: Lint (no fixes)\n        run: uvx ruff check .\n      - name: Format check\n        run: uvx ruff format --check .\n</code></pre> <p>If you\u2019re not using <code>uv</code>, replace <code>uvx ruff \u2026</code> with <code>ruff \u2026</code> after setting up Python and installing Ruff.</p>","tags":["Ruff","CI/CD","Automation"]},{"location":"blogs/ruff-modern-linter/#ide-integration","title":"IDE integration","text":"<ul> <li>VS Code: Install the \u201cRuff\u201d extension and set it as the default linter/formatter.</li> <li>PyCharm: Enable the Ruff plugin for inspections and formatting.</li> </ul>","tags":["Ruff","CI/CD","Automation"]},{"location":"blogs/ruff-modern-linter/#summary","title":"Summary","text":"<p>Ruff simplifies Python code quality by consolidating linting, import sorting, and formatting with exceptional performance. Start with the defaults, wire it into pre-commit and CI, and customize gradually via <code>pyproject.toml</code>.</p> <p>Further reading: Real Python \u2014 \u201cRuff: A Modern Python Linter for Error-Free and Maintainable Code\u201d <code>realpython.com/ruff-python</code>.</p>","tags":["Ruff","CI/CD","Automation"]},{"location":"blogs/ruff-modern-linter/#why-ruff","title":"Why Ruff ?","text":"<ul> <li>One tool: Linting (Flake8 rules), import sorting (isort rules), and formatting (Black-like) in one binary.</li> <li>Fast: Written in Rust; great for local and CI.</li> <li>Simple: Sensible defaults; configure only what you need.</li> </ul>","tags":["Ruff","CI/CD","Automation"]},{"location":"blogs/ruff-modern-linter/#stay-updated","title":"Stay Updated","text":"<p>Join my newsletter for the latest insights on Document AI, RAG, and LLM technologies:</p>","tags":["Ruff","CI/CD","Automation"]},{"location":"blogs/ruff-modern-linter/#share-this-post","title":"Share This Post","text":"<p>Share on  Share on </p>","tags":["Ruff","CI/CD","Automation"]},{"location":"blogs/system-architecture-comprehensive-guide/","title":"System Architecture \u2014 A Comprehensive, Practical Guide","text":"<p>Designing and evolving system architecture is about making informed trade\u2011offs. This guide provides a practical, opinionated walkthrough of the core concepts, patterns, and decisions you need to build scalable, reliable, and cost\u2011efficient systems\u2014plus answers to the most common questions engineers and architects ask.</p>","tags":["System Design"]},{"location":"blogs/system-architecture-comprehensive-guide/#what-is-system-architecture","title":"What Is System Architecture","text":"<p>System architecture describes the high\u2011level structure of a software system: the components, their responsibilities, and how they interact. It balances non\u2011functional requirements (NFRs) such as scalability, reliability, performance, security, operability, and cost.</p> <ul> <li>Functional requirements: What the system does (features, endpoints, business rules).</li> <li>Non\u2011functional requirements (NFRs): How well the system does it (SLOs, throughput, latency, availability, durability, security, maintainability).</li> </ul>","tags":["System Design"]},{"location":"blogs/system-architecture-comprehensive-guide/#reference-architecture-at-a-glance","title":"Reference Architecture at a Glance","text":"<pre><code>%%{init: { 'flowchart': { 'htmlLabels': true } }}%%\nflowchart TB\n    subgraph Client\n        U[Web / Mobile / API Client]\n    end\n\n    subgraph Edge\n        CDN[CDN]\n        WAF[WAF]\n        LB[Load Balancer]\n        AG[API Gateway]\n    end\n\n    subgraph Services\n        A[\"App Service&lt;br/&gt;(Monolith or Microservices)\"]\n        MQ[\"Message Broker&lt;br/&gt;(Kafka/RabbitMQ)\"]\n        CRON[Schedulers / Workers]\n    end\n\n    subgraph Data\n        DB[(Primary DB \\n SQL/NoSQL)]\n        CACHE[(Cache \\n Redis/Memcached)]\n        SEARCH[(Search \\n ES/OpenSearch)]\n        OLAP[(Analytics DW \\n BigQuery/Redshift)]\n        OBJ[(Object Storage \\n S3/GCS)]\n    end\n\n    subgraph Observability\n        LOGS[Logs]\n        METRICS[Metrics]\n        TRACES[Traces]\n    end\n\n    U --&gt; CDN --&gt; WAF --&gt; LB --&gt; AG --&gt; A\n    A --&gt; CACHE\n    CACHE --&gt; A\n    A --&gt; DB\n    DB --&gt; A\n    A --&gt; MQ\n    MQ --&gt; CRON\n    A --&gt; SEARCH\n    A --&gt; OBJ\n    CRON --&gt; DB\n    CRON --&gt; OBJ\n\n    A --&gt; LOGS\n    A --&gt; METRICS\n    A --&gt; TRACES</code></pre>","tags":["System Design"]},{"location":"blogs/system-architecture-comprehensive-guide/#core-architectural-styles","title":"Core Architectural Styles","text":"Layered (N\u2011Tier)Modular MonolithMicroservicesEvent\u2011Driven <ul> <li>Idea: Separate presentation, application, domain, and data layers.</li> <li>Pros: Simple, clear separation; great for small to medium apps.</li> <li>Cons: Can devolve into an anemic domain; boundaries erode over time.</li> <li>Use when: Team is small; domain is evolving; deployment simplicity matters.</li> </ul> <ul> <li>Idea: One deployable unit with strict internal modules and boundaries.</li> <li>Pros: Transactional consistency, simple ops, easier refactoring.</li> <li>Cons: One failure can impact more; scaling is coarse.</li> <li>Use when: You want speed of delivery with discipline; future microservices possible.</li> </ul> <ul> <li>Idea: Independent services with clear bounded contexts.</li> <li>Pros: Independent scaling/deployment; team autonomy; polyglot persistence.</li> <li>Cons: Operational complexity; distributed transactions; consistency challenges.</li> <li>Use when: Org is large; domains are well understood; platform engineering exists.</li> </ul> <ul> <li>Idea: Publish/subscribe events for loose coupling and async processing.</li> <li>Pros: Scalable, resilient, extensible.</li> <li>Cons: Debuggability; eventual consistency; schema/versioning discipline needed.</li> <li>Use when: High throughput, integrations, or async workflows are key.</li> </ul>","tags":["System Design"]},{"location":"blogs/system-architecture-comprehensive-guide/#data-and-consistency-fundamentals","title":"Data and Consistency Fundamentals","text":"<ul> <li>ACID vs BASE: Strong consistency vs eventual consistency trade\u2011off.</li> <li>CAP Theorem: Under network partitions, pick availability or consistency.</li> <li>Consistency models: Strong, causal, read\u2011your\u2011writes, eventual.</li> <li>Idempotency: Same request can be safely retried; key for reliability.</li> <li>Exactly\u2011once is aspirational: Aim for at\u2011least\u2011once + idempotency.</li> </ul>","tags":["System Design"]},{"location":"blogs/system-architecture-comprehensive-guide/#typical-readwrite-flow","title":"Typical Read/Write Flow","text":"<pre><code>sequenceDiagram\n    participant C as Client\n    participant G as API Gateway\n    participant S as Service\n    participant R as Cache (Redis)\n    participant D as Database\n\n    C-&gt;&gt;G: GET /products/123\n    G-&gt;&gt;S: Forward request\n    S-&gt;&gt;R: GET product:123\n    alt Cache hit\n        R--&gt;&gt;S: Value\n        S--&gt;&gt;G: 200 OK + Data\n        G--&gt;&gt;C: 200 OK + Data\n    else Cache miss\n        R--&gt;&gt;S: null\n        S-&gt;&gt;D: SELECT * FROM products WHERE id=123\n        D--&gt;&gt;S: Row\n        S-&gt;&gt;R: SET product:123 (TTL=300s)\n        S--&gt;&gt;G: 200 OK + Data\n        G--&gt;&gt;C: 200 OK + Data\n    end</code></pre>","tags":["System Design"]},{"location":"blogs/system-architecture-comprehensive-guide/#scalability-patterns","title":"Scalability Patterns","text":"<ul> <li>Vertical scaling: Bigger machines; quick win; diminishing returns.</li> <li>Horizontal scaling: More instances; needs statelessness and externalized state.</li> <li>Partitioning/Sharding: Split data by key or range; consider rebalancing.</li> <li>Replication: Read replicas for scale; async replicas increase staleness risk.</li> <li>Caching: CDN, application cache (Redis), database cache; always set TTLs and invalidation rules.</li> <li>Queueing &amp; Backpressure: Smooth spikes with buffers; implement consumer concurrency and rate limits.</li> </ul>","tags":["System Design"]},{"location":"blogs/system-architecture-comprehensive-guide/#reliability-and-resilience","title":"Reliability and Resilience","text":"<ul> <li>Timeouts and Retries: Always set sane timeouts; use exponential backoff + jitter.</li> <li>Circuit Breakers: Fail fast when dependencies degrade; protect resources.</li> <li>Bulkheads: Isolate resource pools (threads/connections) per dependency.</li> <li>Dead\u2011letter queues: Capture poison messages for later review.</li> <li>Graceful degradation: Serve cached or partial data when possible.</li> </ul>","tags":["System Design"]},{"location":"blogs/system-architecture-comprehensive-guide/#datastores-and-when-to-use-them","title":"Datastores and When to Use Them","text":"Relational (PostgreSQL/MySQL)Document (MongoDB/Firestore)Key\u2011Value (Redis/Memcached)Wide\u2011Column (Cassandra/Scylla)Search (Elasticsearch/OpenSearch)Analytics (BigQuery/Redshift/Snowflake) <ul> <li>Strong consistency, joins, transactions. Best for OLTP and complex relationships.</li> <li>Scale via read replicas, partitioning, and careful indexing.</li> </ul> <ul> <li>Flexible schemas, nested documents. Great for content/user profiles.</li> </ul> <ul> <li>Sub\u2011millisecond reads/writes; perfect for caching, sessions, locks.</li> </ul> <ul> <li>High write throughput, linear horizontal scalability; model queries up\u2011front.</li> </ul> <ul> <li>Full\u2011text search, aggregations; eventual consistency; pipeline ingestion.</li> </ul> <ul> <li>OLAP, columnar storage, separation of storage/compute; not for OLTP.</li> </ul>","tags":["System Design"]},{"location":"blogs/system-architecture-comprehensive-guide/#messaging-and-async-workflows","title":"Messaging and Async Workflows","text":"<ul> <li>Brokers: Kafka (log\u2011based, high throughput), RabbitMQ (AMQP, routing), SQS/PubSub (managed).</li> <li>Patterns: Pub/Sub, Work Queues, Event Sourcing, CQRS, Saga for distributed transactions.</li> </ul> <pre><code>stateDiagram-v2\n    [*] --&gt; Pending\n    Pending --&gt; Reserved: Reserve inventory\n    Reserved --&gt; Paid: Payment succeeded\n    Reserved --&gt; Pending: Payment failed (retry)\n    Paid --&gt; Shipped: Fulfill order\n    Shipped --&gt; [*]</code></pre>","tags":["System Design"]},{"location":"blogs/system-architecture-comprehensive-guide/#api-gateway-bff-and-edge","title":"API Gateway, BFF, and Edge","text":"<ul> <li>API Gateway: Routing, authentication, rate limiting, request/response transformation.</li> <li>BFF (Backend for Frontend): Tailored APIs per client (web/mobile) to reduce over/under\u2011fetching.</li> <li>Edge (CDN/WAF): Caching static and semi\u2011static content; threat mitigation at the perimeter.</li> </ul>","tags":["System Design"]},{"location":"blogs/system-architecture-comprehensive-guide/#security-by-design","title":"Security by Design","text":"<ul> <li>AuthN/Z: OAuth 2.1/OIDC for delegated auth; enforce least privilege and scopes.</li> <li>Data protection: TLS in transit; at\u2011rest encryption; KMS\u2011managed keys.</li> <li>Secrets: Use secret managers; never store secrets in env files or images.</li> <li>Input validation: Validate at the edge and service boundary; sanitize outputs.</li> <li>Auditability: Immutable, tamper\u2011evident logs for security events.</li> </ul>","tags":["System Design"]},{"location":"blogs/system-architecture-comprehensive-guide/#observability-and-operability","title":"Observability and Operability","text":"<ul> <li>Metrics: RED/USE/Golden signals; per\u2011service SLOs with error budgets.</li> <li>Logs: Structured JSON, correlation IDs; centralize and retain with budgets.</li> <li>Traces: Distributed tracing with consistent propagation headers.</li> <li>Runbooks: Document failure modes and standard operating procedures.</li> </ul>","tags":["System Design"]},{"location":"blogs/system-architecture-comprehensive-guide/#deployments-and-release-strategies","title":"Deployments and Release Strategies","text":"<ul> <li>Blue/Green: Two production environments; instant switch; higher cost.</li> <li>Canary: Gradual rollout with automated rollback on regression.</li> <li>Feature Flags: Decouple deploy from release; enable progressive delivery.</li> </ul>","tags":["System Design"]},{"location":"blogs/system-architecture-comprehensive-guide/#cost-awareness","title":"Cost Awareness","text":"<ul> <li>Right\u2011sizing: Match instance sizes to baselines; autoscale on credible signals.</li> <li>Storage classes: Hot vs warm vs cold tiers; lifecycle policies.</li> <li>Data egress: Minimize cross\u2011region and cross\u2011cloud traffic.</li> </ul>","tags":["System Design"]},{"location":"blogs/system-architecture-comprehensive-guide/#nonfunctional-requirements-nfr-checklist","title":"Non\u2011Functional Requirements (NFR) Checklist","text":"<ul> <li>SLOs for latency, availability, and error rates defined and monitored</li> <li>Capacity plan and autoscaling policies validated under load tests</li> <li>Backups, restore drills, and disaster recovery RPO/RTO defined</li> <li>Timeouts, retries with backoff, circuit breakers configured</li> <li>Idempotency for writes and exactly\u2011once semantics avoided</li> <li>Rate limits, quotas, and surge protection in place</li> <li>Security scanning (SAST/DAST), dependencies, base image hardening</li> <li>Observability: metrics, logs, traces, dashboards, alerts, runbooks</li> <li>Cost budgets and anomaly detection alerts</li> </ul>","tags":["System Design"]},{"location":"blogs/system-architecture-comprehensive-guide/#architecture-decision-records-adr","title":"Architecture Decision Records (ADR)","text":"<p>Document trade\u2011offs explicitly. A lightweight ADR captures context, decision, alternatives, and consequences. Keep ADRs short, versioned, and linked to incidents or KPIs when decisions change.</p>","tags":["System Design"]},{"location":"blogs/system-architecture-comprehensive-guide/#common-questions-and-straight-answers","title":"Common Questions and Straight Answers","text":"Should I start with microservices?SQL or NoSQL?How many replicas do I need?How do I ensure safe retries?What about exactly\u2011once delivery?Do I need a message broker?How do I handle schema changes?When should I shard?How do I choose cache TTLs?What causes cascading failures? <p>No. Start with a well\u2011structured modular monolith. Split only when boundaries and scaling pain are clear.</p> <p>Default to SQL. Move specific workloads to NoSQL if access patterns or scale demand it.</p> <p>At least 2 per AZ for HA; 3 for quorum\u2011based systems. Validate with load tests.</p> <p>Make write endpoints idempotent (idempotency keys) and use backoff + jitter.</p> <p>Prefer at\u2011least\u2011once with idempotent consumers. Exactly\u2011once is costly and brittle in practice.</p> <p>Use one for async workloads, spikes, or integrations. Avoid if synchronous request/response suffices and throughput is modest.</p> <p>Backward\u2011compatible changes first (additive), deploy readers, then writers; run dual\u2011writes if needed.</p> <p>Only after exhausting vertical scale and read replicas. Choose a shard key that evenly distributes load and minimizes cross\u2011shard queries.</p> <p>Base on data volatility and correctness tolerance. Prefer short TTLs and soft invalidation over long stale data.</p> <p>Tight coupling, unbounded concurrency, and missing timeouts. Use bulkheads, backpressure, and circuit breakers.</p>","tags":["System Design"]},{"location":"blogs/system-architecture-comprehensive-guide/#production-readiness-checklist","title":"Production Readiness Checklist","text":"<ul> <li>Health checks (liveness/readiness/startup) and graceful shutdown</li> <li>Config via env/secret manager; immutable container images</li> <li>Canary strategy and automated rollback hooks</li> <li>Per\u2011endpoint SLOs and error budgets defined</li> <li>Rate limiting and abuse detection at the edge</li> <li>Data retention, privacy, PII handling, and audit trails</li> <li>Access control: least privilege IAM, scoped tokens, and short\u2011lived creds</li> <li>Runbook for all critical failure modes; on\u2011call rotation defined</li> </ul>","tags":["System Design"]},{"location":"blogs/system-architecture-comprehensive-guide/#example-request-journey-through-the-stack","title":"Example: Request Journey Through the Stack","text":"<pre><code>flowchart LR\n    C[Client] --&gt; E[Edge: CDN/WAF]\n    E --&gt; L[Load Balancer]\n    L --&gt; G[API Gateway]\n    G --&gt; S[Service]\n    S --&gt;|read| Rc[(Redis Cache)]\n    S --&gt;|write| Db[(Primary DB)]\n    S --&gt;|async| Q[(Broker)]\n    Q --&gt; W[Worker]\n    W --&gt; Db</code></pre>","tags":["System Design"]},{"location":"blogs/system-architecture-comprehensive-guide/#how-to-evolve-architecture-safely","title":"How to Evolve Architecture Safely","text":"<ol> <li>Define KPIs and SLOs. Measure before you change.</li> <li>Make small, reversible steps. Use flags and canaries.</li> <li>Prefer schema\u2011first and contract tests for APIs and events.</li> <li>Automate. Everything. Testing, security scans, provisioning, rollbacks.</li> <li>Document decisions (ADRs) and post\u2011incident learnings.</li> </ol>","tags":["System Design"]},{"location":"blogs/system-architecture-comprehensive-guide/#further-reading","title":"Further Reading","text":"<ul> <li>Designing Data\u2011Intensive Applications (Kleppmann)</li> <li>Site Reliability Engineering (Beyer et al.)</li> <li>Release It! (Nygard)</li> <li>The Twelve\u2011Factor App</li> </ul>","tags":["System Design"]},{"location":"blogs/system-architecture-comprehensive-guide/#conclusion","title":"Conclusion","text":"<p>Good architecture maximizes option value by keeping systems observable, evolvable, and resilient. Start simple, measure relentlessly, and introduce complexity only when the data demands it. The best designs are those your team can operate confidently under failure.</p>","tags":["System Design"]},{"location":"blogs/system-architecture-comprehensive-guide/#stay-updated","title":"Stay Updated","text":"<p>Join my newsletter for the latest insights on Document AI, RAG, and LLM technologies:</p>","tags":["System Design"]},{"location":"blogs/system-architecture-comprehensive-guide/#share-this-post","title":"Share This Post","text":"<p>Share on  Share on </p>","tags":["System Design"]},{"location":"blogs/version-control-git-github/","title":"Git & GitHub: The Definitive Version Control Guide","text":"<p>Version control is the foundation of reliable software delivery. This guide teaches Git from first principles, then layers in practical GitHub workflows used by high-performing teams. You\u2019ll learn the mental models, the everyday commands, and the advanced tools to collaborate confidently without fear of breaking anything.</p>","tags":["Git","GitHub","DevOps"]},{"location":"blogs/version-control-git-github/#what-is-version-control-and-why-it-matters","title":"What Is Version Control (and Why It Matters)","text":"<p>Version control systems track changes to files over time so you can collaborate, audit history, and restore previous states. Git is a distributed VCS: every clone contains the entire history, enabling fast local operations and offline work. GitHub is a hosting and collaboration platform built on top of Git.</p> Git vs GitHubCentralized vs Distributed <ul> <li>Git: command-line tool and file format for versioning</li> <li>GitHub: remote hosting, Pull Requests, Issues, Actions, Discussions, Packages</li> </ul> <ul> <li>Centralized (e.g., SVN): single server of truth</li> <li>Distributed (Git): many full copies; collaboration via push/pull/fetch</li> </ul>","tags":["Git","GitHub","DevOps"]},{"location":"blogs/version-control-git-github/#the-git-mental-model","title":"The Git Mental Model","text":"<p>Git tracks content snapshots and references. The three most important zones are the working directory, the staging area (index), and the local repository.</p> <pre><code>graph LR\n    A[Working Directory] -- git add --&gt; B[Staging Area]\n    B -- git commit --&gt; C[Local Repository]\n    C -- git push --&gt; D[Remote Repository]\n    D -- git fetch/pull --&gt; C\n    C -- git checkout/switch --&gt; A</code></pre> <p>Think in small, logical commits that tell a story. Branch to isolate work. Merge or rebase to integrate.</p>","tags":["Git","GitHub","DevOps"]},{"location":"blogs/version-control-git-github/#install-and-configure-git","title":"Install and Configure Git","text":"macOSWindows (PowerShell)Linux <pre><code>brew install git\ngit --version\n</code></pre> <pre><code>winget install --id Git.Git -e\ngit --version\n</code></pre> <pre><code>sudo apt update &amp;&amp; sudo apt install -y git       # Debian/Ubuntu\nsudo dnf install -y git                           # Fedora\ngit --version\n</code></pre>","tags":["Git","GitHub","DevOps"]},{"location":"blogs/version-control-git-github/#first-time-setup","title":"First-Time Setup","text":"<pre><code>git config --global user.name \"Your Name\"\ngit config --global user.email \"you@example.com\"\ngit config --global init.defaultBranch main\ngit config --global core.editor \"code --wait\"       # VS Code as editor\ngit config --global pull.rebase false                # start with merges\n</code></pre> <p>Optional but recommended:</p> <pre><code># Better diffs and helpful aliases\ngit config --global color.ui auto\ngit config --global alias.st status\ngit config --global alias.co checkout\ngit config --global alias.br branch\ngit config --global alias.ci commit\ngit config --global alias.last 'log -1 --stat'\n</code></pre>","tags":["Git","GitHub","DevOps"]},{"location":"blogs/version-control-git-github/#create-or-clone-a-repository","title":"Create or Clone a Repository","text":"Start a new repoClone existing <pre><code>mkdir hello-git &amp;&amp; cd hello-git\ngit init\necho \"# Hello Git\" &gt; README.md\ngit add README.md\ngit commit -m \"chore: initial commit\"\n</code></pre> <pre><code>git clone https://github.com/owner/repo.git\ncd repo\n</code></pre>","tags":["Git","GitHub","DevOps"]},{"location":"blogs/version-control-git-github/#everyday-workflow","title":"Everyday Workflow","text":"<pre><code># 1) See what changed\ngit status\ngit diff                     # unstaged changes\ngit diff --staged            # staged vs last commit\n\n# 2) Stage what you want to commit\ngit add path/to/file\ngit add -p                   # interactively stage hunks\n\n# 3) Commit with a meaningful message\ngit commit -m \"feat: add user search by email\"\n\n# 4) Update your branch from remote\ngit pull                     # merge-based (default here)\n# or: git pull --rebase      # rebase-based\n\n# 5) Push your work\ngit push -u origin my-feature\n</code></pre>","tags":["Git","GitHub","DevOps"]},{"location":"blogs/version-control-git-github/#commit-message-best-practices","title":"Commit Message Best Practices","text":"<ul> <li>Use imperative mood: \"fix bug\", \"add feature\"</li> <li>Keep subject \u2264 72 chars; add details in body if needed</li> <li>Consider Conventional Commits for automation:</li> </ul> <pre><code>&lt;type&gt;(&lt;scope&gt;): &lt;subject&gt;\n\nfeat(search): add email filter to users list\n\nBody explaining why, not what. Reference issues if useful.\n</code></pre>","tags":["Git","GitHub","DevOps"]},{"location":"blogs/version-control-git-github/#branching-strategies","title":"Branching Strategies","text":"<p>Common strategies include Trunk-Based Development and Git Flow. Most teams today prefer Trunk-Based with short-lived feature branches and frequent merges.</p> <pre><code>flowchart LR\n    main((main)) --&gt; F1[feature/login]\n    main --&gt; F2[feature/search]\n    F1 --&gt; main\n    F2 --&gt; main</code></pre>","tags":["Git","GitHub","DevOps"]},{"location":"blogs/version-control-git-github/#create-switch-and-delete-branches","title":"Create, Switch, and Delete Branches","text":"<pre><code>git switch -c feature/search-ui   # create and switch\ngit switch main                   # go back\ngit branch -d feature/search-ui   # delete merged branch\ngit branch -D old-experiment      # force delete\n</code></pre>","tags":["Git","GitHub","DevOps"]},{"location":"blogs/version-control-git-github/#merge-vs-rebase","title":"Merge vs Rebase","text":"<p>Both integrate changes. Merge preserves history; rebase rewrites your branch to apply on top of a base branch.</p> Merge (safe, non-destructive)Rebase (linear history) <pre><code>git switch feature/login\ngit merge main\n# resolves conflicts, creates a merge commit\n</code></pre> <pre><code>git switch feature/login\ngit rebase main\n# replay commits atop main; fix conflicts along the way\n# if stuck: git rebase --abort   or   git rebase --continue\n</code></pre> <pre><code>sequenceDiagram\n    participant M as main\n    participant F as feature\n    Note over F: Before rebase\n    F-&gt;&gt;F: commits A, B\n    M-&gt;&gt;M: commits X, Y\n    Note over F: Rebase F onto M\n    F-&gt;&gt;M: pick A'\n    F-&gt;&gt;M: pick B'</code></pre>","tags":["Git","GitHub","DevOps"]},{"location":"blogs/version-control-git-github/#handling-conflicts","title":"Handling Conflicts","text":"<p>Conflicts occur when the same lines changed in both branches.</p> <pre><code># After pull/merge/rebase reports conflicts:\ngit status                         # see conflicted files\n\n# Edit files, resolve conflict markers &lt;&lt;&lt;&lt;&lt;&lt;&lt; ======= &gt;&gt;&gt;&gt;&gt;&gt;&gt;\n\ngit add path/to/conflicted-file\ngit commit                         # for merge\ngit rebase --continue              # for rebase\n</code></pre> <p>Tips: - Resolve small, logical conflicts first - Prefer consistent formatting to reduce diff noise - Run tests before pushing</p>","tags":["Git","GitHub","DevOps"]},{"location":"blogs/version-control-git-github/#undo-and-recover-safely","title":"Undo and Recover Safely","text":"Unstage changesDiscard local editsAmend last commitRevert a bad commit (public history safe)Time travel with reflog <pre><code>git restore --staged path/to/file\n</code></pre> <pre><code>git restore path/to/file         # careful: this loses changes\n</code></pre> <pre><code>git commit --amend -m \"fix: correct typo in docs\"\n</code></pre> <pre><code>git revert &lt;commit_sha&gt;\n</code></pre> <pre><code>git reflog                       # shows where HEAD moved\ngit checkout &lt;sha&gt;\n</code></pre>","tags":["Git","GitHub","DevOps"]},{"location":"blogs/version-control-git-github/#stashing-work-in-progress","title":"Stashing Work-in-Progress","text":"<pre><code>git stash push -m \"wip: partial search filters\"\ngit stash list\ngit stash show -p stash@{0}\ngit stash pop     # apply + drop\ngit stash apply   # apply only\n</code></pre>","tags":["Git","GitHub","DevOps"]},{"location":"blogs/version-control-git-github/#tags-and-releases","title":"Tags and Releases","text":"<pre><code>git tag -a v1.0.0 -m \"First stable release\"\ngit push --tags\n</code></pre> <p>Use annotated tags for semantic versioning; create GitHub Releases from tags for changelogs and assets.</p>","tags":["Git","GitHub","DevOps"]},{"location":"blogs/version-control-git-github/#github-fundamentals","title":"GitHub Fundamentals","text":"<ul> <li>Repositories: public or private</li> <li>Issues: track tasks/bugs with labels, assignees, and milestones</li> <li>Pull Requests (PRs): propose changes; enable reviews and checks</li> <li>Discussions: community Q&amp;A and proposals</li> <li>Projects: kanban planning</li> <li>Wikis: long-form documentation</li> </ul>","tags":["Git","GitHub","DevOps"]},{"location":"blogs/version-control-git-github/#https-vs-ssh-and-tokens","title":"HTTPS vs SSH (and Tokens)","text":"<pre><code># HTTPS clone (uses PAT on push)\ngit clone https://github.com/owner/repo.git\n\n# SSH clone (key-based)\nssh-keygen -t ed25519 -C \"you@example.com\"\nssh-add ~/.ssh/id_ed25519\ngit clone git@github.com:owner/repo.git\n</code></pre> <p>For HTTPS pushes, create a Personal Access Token (fine-grained) and use it as the password. For SSH, upload your public key to GitHub.</p>","tags":["Git","GitHub","DevOps"]},{"location":"blogs/version-control-git-github/#fork-and-pr-vs-shared-repo","title":"Fork-and-PR vs Shared-Repo","text":"<pre><code>sequenceDiagram\n    participant U as You (fork)\n    participant O as Origin Repo\n    U-&gt;&gt;O: fork\n    U-&gt;&gt;U: clone fork\n    U-&gt;&gt;U: create branch, commit, push\n    U-&gt;&gt;O: open Pull Request\n    O-&gt;&gt;U: review, request changes\n    U-&gt;&gt;O: update branch, CI passes\n    O-&gt;&gt;O: merge PR</code></pre>","tags":["Git","GitHub","DevOps"]},{"location":"blogs/version-control-git-github/#opening-an-effective-pr","title":"Opening an Effective PR","text":"<ul> <li>Keep PRs small and focused</li> <li>Write a clear title and description (why, tradeoffs, screenshots)</li> <li>Link Issues and Discussions</li> <li>Ensure CI passes and tests are updated</li> <li>Request specific reviewers and use code owners when applicable</li> </ul>","tags":["Git","GitHub","DevOps"]},{"location":"blogs/version-control-git-github/#protecting-main-and-enforcing-quality","title":"Protecting Main and Enforcing Quality","text":"<ul> <li>Protected branches: require PR, reviews, status checks, linear history</li> <li>Required checks: unit tests, lint, type-check, build</li> <li>Code owners: automatic review assignment</li> <li>Bypass rules for admins sparingly</li> </ul>","tags":["Git","GitHub","DevOps"]},{"location":"blogs/version-control-git-github/#automate-with-github-actions-cicd","title":"Automate with GitHub Actions (CI/CD)","text":"<pre><code>name: ci\non: [push, pull_request]\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-node@v4\n        with:\n          node-version: 20\n      - run: npm ci\n      - run: npm test -- --ci\n</code></pre> <p>Add environment protections for deploy jobs; use environments, required reviewers, and secrets.</p>","tags":["Git","GitHub","DevOps"]},{"location":"blogs/version-control-git-github/#keep-repos-healthy","title":"Keep Repos Healthy","text":"<ul> <li>.gitignore: avoid committing build artifacts, secrets, large files</li> <li>LICENSE: make intent explicit</li> <li>README: quickstart, architecture, contribution guide</li> <li>CONTRIBUTING.md, CODE_OF_CONDUCT.md, SECURITY.md</li> <li>Small, coherent commits; squash or rebase before merge if noisy</li> </ul>","tags":["Git","GitHub","DevOps"]},{"location":"blogs/version-control-git-github/#large-files-and-monorepos","title":"Large Files and Monorepos","text":"Git LFSSparse Checkout (partial clones) <pre><code>git lfs install\ngit lfs track \"*.bin\"\ngit add .gitattributes\n</code></pre> <pre><code>git clone --filter=blob:none --no-checkout git@github.com:owner/huge-repo.git\ncd huge-repo\ngit sparse-checkout init --cone\ngit sparse-checkout set apps/web apps/api\n</code></pre>","tags":["Git","GitHub","DevOps"]},{"location":"blogs/version-control-git-github/#security-and-trust","title":"Security and Trust","text":"<ul> <li>Sign commits and tags (GPG or SSH signatures)</li> <li>Use branch protections and required reviews</li> <li>Avoid pushing secrets; scan with GitHub Advanced Security or pre-commit hooks</li> <li>Rotate tokens; limit PAT scopes</li> </ul>","tags":["Git","GitHub","DevOps"]},{"location":"blogs/version-control-git-github/#sign-your-commits-gpg","title":"Sign Your Commits (GPG)","text":"<pre><code>gpg --full-generate-key\ngpg --list-secret-keys --keyid-format=long\ngit config --global user.signingkey &lt;KEY_ID&gt;\ngit config --global commit.gpgsign true\n</code></pre>","tags":["Git","GitHub","DevOps"]},{"location":"blogs/version-control-git-github/#troubleshooting-faq","title":"Troubleshooting FAQ","text":"fatal: not a git repositoryPermission denied (publickey)Updates were rejected because the remote contains work that you do not haveHow do I undo the last commit but keep my changes?How do I remove a file from history (secret accidentally committed)? <p>Run inside a repo or initialize one: <code>git init</code>.</p> <p>Add your SSH key to the agent and GitHub; or use HTTPS + PAT.</p> <p>Pull first, resolve, then push: <code>git pull --rebase</code> or <code>git pull</code> then fix conflicts.</p> <p><code>git reset --soft HEAD~1</code></p> <p>Use <code>git filter-repo</code> or <code>git filter-branch</code>, then force-push and rotate secrets.</p>","tags":["Git","GitHub","DevOps"]},{"location":"blogs/version-control-git-github/#glossary-quick-reference","title":"Glossary (Quick Reference)","text":"<ul> <li>Commit: snapshot with metadata</li> <li>Branch: movable pointer to a commit</li> <li>HEAD: your current checked-out commit/branch</li> <li>Remote: named reference to another repository (e.g., origin)</li> <li>Merge: combine histories with a merge commit</li> <li>Rebase: replay commits onto another base</li> <li>Tag: named pointer for releases</li> </ul>","tags":["Git","GitHub","DevOps"]},{"location":"blogs/version-control-git-github/#further-reading","title":"Further Reading","text":"<ul> <li>Git Book: <code>https://git-scm.com/book/en/v2</code></li> <li>GitHub Docs: <code>https://docs.github.com</code></li> <li>Conventional Commits: <code>https://www.conventionalcommits.org</code></li> </ul>","tags":["Git","GitHub","DevOps"]},{"location":"blogs/version-control-git-github/#conclusion","title":"Conclusion","text":"<p>You now have a practical toolbox and the mental models to use Git effectively and collaborate on GitHub with confidence. Start with small, clear commits; branch freely; integrate often; protect main; and automate quality with CI. As your team matures, refine policies and workflows\u2014Git and GitHub will scale with you.</p>","tags":["Git","GitHub","DevOps"]},{"location":"blogs/version-control-git-github/#stay-updated","title":"Stay Updated","text":"<p>Join my newsletter for the latest insights on Document AI, RAG, and LLM technologies:</p>","tags":["Git","GitHub","DevOps"]},{"location":"blogs/version-control-git-github/#share-this-post","title":"Share This Post","text":"<p>Share on  Share on </p>","tags":["Git","GitHub","DevOps"]},{"location":"projects/","title":"Projects","text":"<p>Source Code Availability</p> <p>You can explore the source code for all my projects on GitHub.</p>"},{"location":"projects/llm-augmented-pdf-data-extraction-pipeline/","title":"LLM-Augmented PDF Data Extraction Pipeline","text":"<p>LLM-augmented PDF extraction pipeline that slashed manual data entry by 95% through dual-LLM validation and OpenAI-powered intelligent parsing.</p> <p></p>"},{"location":"projects/llm-augmented-pdf-data-extraction-pipeline/#problem-statement","title":"Problem Statement","text":"<p>Semi-structured lab report PDFs contain critical water quality data but arrive with inconsistent layouts and parameter naming. Rule-based extraction struggles with layout drift across different lab formats, leading to missed fields and extraction errors. Manual fallback to copy-paste 20+ values (pH, conductivity, dissolved solids, bacteria counts) into Excel doesn't scale as report volumes grow. Manual fallback to copy-paste 20+ values (pH, conductivity, dissolved solids, bacteria counts) into Excel doesn't scale as report volumes grow.</p>"},{"location":"projects/llm-augmented-pdf-data-extraction-pipeline/#technical-approach","title":"Technical Approach","text":"<ul> <li>Integrated OpenAI API into existing rule-based extraction pipeline for intelligent PDF parsing  </li> <li>Implemented dual-LLM validation to handle layout drift and ensure extraction consistency  </li> <li>Extracted 20+ target parameters: site metadata, bacteria counts (Aerobic Plate Count, Pseudomonas, Sulphate Reducing Bacteria), and chemical readings (pH, conductivity, dissolved solids, hardness, chloride, sulphate, iron, copper, aluminium, molybdenum)  </li> <li>Built intelligent fallback logic: rule-based extraction first, LLM-assisted parsing for edge cases  </li> <li>Enforced schema validation using Pydantic models with type checking and range constraints  </li> <li>Generated downloadable Excel files formatted for direct copy-paste into client's reporting system  </li> <li>Handled edge cases: multi-page reports, merged cells, inconsistent headers, varying lab formats</li> </ul>"},{"location":"projects/llm-augmented-pdf-data-extraction-pipeline/#skills","title":"Skills","text":"<p>Python \u00b7 OpenAI API \u00b7 LLM Integration \u00b7 pdfplumber \u00b7 pandas \u00b7 openpyxl \u00b7 Dual-LLM Validation \u00b7 Intelligent Extraction \u00b7 Semi-structured Data \u00b7 Schema Validation \u00b7 Pydantic \u00b7 Edge Case Handling \u00b7 Data Interpretation</p>"},{"location":"projects/llm-augmented-pdf-data-extraction-pipeline/#challenges-solutions","title":"Challenges &amp; Solutions","text":"<ul> <li>Layout drift across lab formats \u2192 dual-LLM validation for cross-checking extracted fields  </li> <li>Inconsistent parameter naming \u2192 LLM-assisted interpretation with structured output enforcement  </li> <li>Edge cases breaking rule-based extraction \u2192 intelligent LLM fallback with context-aware parsing  </li> <li>Invalid or out-of-range values \u2192 Pydantic schema validation with error reporting</li> </ul>"},{"location":"projects/llm-augmented-pdf-data-extraction-pipeline/#quantifiable-business-impact","title":"Quantifiable Business Impact","text":"<ul> <li>95% reduction in manual data entry time  </li> <li>99% accuracy in data extraction across varying lab report formats  </li> <li>Dual-LLM validation eliminating layout drift errors  </li> <li>Intelligent extraction handling edge cases without manual intervention  </li> <li>One-click Excel download formatted for direct integration</li> </ul>"},{"location":"projects/llm-augmented-pdf-data-extraction-pipeline/#stay-updated","title":"Stay Updated","text":"<p>Join my newsletter for the latest insights on Document AI, RAG, and LLM technologies:</p>"},{"location":"projects/llm-augmented-pdf-data-extraction-pipeline/#share-this-post","title":"Share This Post","text":"<p>Share on  Share on </p>"},{"location":"projects/production-ready-rule-based-data-extraction-api/","title":"Production-Ready Rule-Based Data Extraction API","text":"<p>Production-ready PDF extraction API that slashed manual data entry by 95% through rule-based parsing and PostgreSQL-driven synonym mapping.</p> <p></p>"},{"location":"projects/production-ready-rule-based-data-extraction-api/#problem-statement","title":"Problem Statement","text":"<p>Semi-structured lab report PDFs contain critical water quality data but arrive with inconsistent layouts and parameter naming. Manual copy-paste of 20+ values (pH, conductivity, dissolved solids, bacteria counts) into Excel is time-consuming, error-prone and doesn't scale as report volumes grow.</p> <p>CLI-based automation tools require local environment setup and Python dependencies, limiting accessibility for non-technical users and creating deployment friction across teams.</p>"},{"location":"projects/production-ready-rule-based-data-extraction-api/#technical-approach","title":"Technical Approach","text":"<ul> <li>Converted existing CLI tool to end-to-end FastAPI REST endpoints: document upload, data extraction (JSON response) and Excel download  </li> <li>Supported batch upload with background task queuing for concurrent processing  </li> <li>Implemented rule-based parsers using pdfplumber and regex for semi-structured extraction  </li> <li>Stored synonym mapping rules in PostgreSQL for dynamic parameter normalisation  </li> <li>Defined field mapping for 20+ target parameters across varying report layouts  </li> <li>Enforced schema validation using Pydantic models with type checking and range constraints  </li> <li>Generated downloadable Excel files using openpyxl/pandas  </li> <li>Handled edge cases: multi-page reports, merged cells, inconsistent headers  </li> <li>Deployed to serverless cloud infrastructure with centralised log monitoring</li> </ul>"},{"location":"projects/production-ready-rule-based-data-extraction-api/#skills","title":"Skills","text":"<p>Python \u00b7 FastAPI \u00b7 PostgreSQL \u00b7 pdfplumber \u00b7 pandas \u00b7 openpyxl \u00b7 REST APIs \u00b7 Background tasks \u00b7 Batch processing \u00b7 Rule-based extraction \u00b7 Semi-structured data \u00b7 Schema validation \u00b7 Pydantic \u00b7 SQLAlchemy \u00b7 async/await \u00b7 Serverless deployment \u00b7 Log monitoring</p>"},{"location":"projects/production-ready-rule-based-data-extraction-api/#challenges-solutions","title":"Challenges &amp; Solutions","text":"<ul> <li>Inconsistent semi-structured layouts \u2192 rule-based field detection with fallback patterns  </li> <li>Parameter name variations across labs \u2192 PostgreSQL synonym mapping for dynamic normalisation  </li> <li>Merged table cells breaking extraction \u2192 custom cell boundary detection logic  </li> <li>Invalid or out-of-range values \u2192 Pydantic schema validation with error reporting</li> </ul>"},{"location":"projects/production-ready-rule-based-data-extraction-api/#quantifiable-business-impact","title":"Quantifiable Business Impact","text":"<ul> <li>95% reduction in manual data entry time  </li> <li>99% accuracy in data extraction  </li> <li>Batch upload with queuing enabling scalable multi-file processing  </li> <li>Dynamic synonym rules via database\u2014no redeployment needed  </li> <li>One-click Excel download eliminating manual reformatting  </li> <li>Production-ready deployment with centralised log monitoring</li> </ul>"},{"location":"projects/production-ready-rule-based-data-extraction-api/#client-review","title":"Client Review","text":""},{"location":"projects/production-ready-rule-based-data-extraction-api/#stay-updated","title":"Stay Updated","text":"<p>Join my newsletter for the latest insights on Document AI, RAG, and LLM technologies:</p>"},{"location":"projects/production-ready-rule-based-data-extraction-api/#share-this-post","title":"Share This Post","text":"<p>Share on  Share on </p>"},{"location":"projects/real-time-stoploss-engine-for-trading-project/","title":"Real-time stoploss engine for trading project","text":"<p>Real-time stop-loss engine replacing candlestick polling with WebSocket streaming, achieving sub-50ms trigger latency, 99.9% uptime and 95% fewer missed executions for automated trading systems.</p> <p></p>"},{"location":"projects/real-time-stoploss-engine-for-trading-project/#problem-statement","title":"Problem Statement","text":"<p>Current trading projects rely on historical candlestick data. Stop-loss systems built on candlestick polling miss price spikes between intervals, leading to delayed triggers and unexpected losses for traders relying on automated risk management.</p>"},{"location":"projects/real-time-stoploss-engine-for-trading-project/#technical-approach","title":"Technical Approach","text":"<ul> <li>Implement persistent WebSocket connections for real-time tick-level price streaming  </li> <li>Build async event-driven architecture using Python's <code>asyncio</code> for non-blocking I/O  </li> <li>Integrate broker APIs with proper rate limiting and automatic reconnection  </li> <li>Design stop-loss engine with configurable triggers and order execution queues  </li> <li>Use Redis for real-time price caching and pub/sub between services  </li> <li>Structure clean separation: data ingestion \u2192 signal processing \u2192 order execution</li> </ul>"},{"location":"projects/real-time-stoploss-engine-for-trading-project/#skills","title":"Skills","text":"<p>Python \u00b7 FastAPI \u00b7 asyncio \u00b7 WebSockets \u00b7 Trading APIs \u00b7 Redis \u00b7 PostgreSQL \u00b7 Real-time streaming \u00b7 Stop-loss algorithms \u00b7 Order management \u00b7 Rate limiting \u00b7pytest \u00b7 Pydantic \u00b7 Event-driven architecture</p>"},{"location":"projects/real-time-stoploss-engine-for-trading-project/#challenges-solutions","title":"Challenges &amp; Solutions","text":"<ul> <li>WebSocket disconnections during volatility \u2192 exponential backoff reconnection with state recovery  </li> <li>API rate limits during rapid price movements \u2192 request queuing with priority ordering  </li> <li>Latency in stop-loss execution \u2192 async architecture reducing response time to &lt;50ms  </li> <li>Order execution failures \u2192 retry logic with idempotency keys and audit logging</li> </ul>"},{"location":"projects/real-time-stoploss-engine-for-trading-project/#quantifiable-business-impact","title":"Quantifiable Business Impact","text":"<ul> <li>Sub-50ms stop-loss trigger latency for timely risk management  </li> <li>99.9% WebSocket uptime with automatic failover  </li> <li>95% reduction in missed stop-loss events vs polling approach  </li> <li>Clean, documented codebase enabling rapid feature additions</li> </ul>"},{"location":"projects/real-time-stoploss-engine-for-trading-project/#client-review","title":"Client Review","text":""},{"location":"projects/real-time-stoploss-engine-for-trading-project/#stay-updated","title":"Stay Updated","text":"<p>Join my newsletter for the latest insights on Document AI, RAG, and LLM technologies:</p>"},{"location":"projects/real-time-stoploss-engine-for-trading-project/#share-this-post","title":"Share This Post","text":"<p>Share on  Share on </p>"},{"location":"blogs/archive/2025/","title":"2025","text":""},{"location":"blogs/category/data-science/","title":"Data Science","text":""},{"location":"blogs/category/software-engineering/","title":"Software Engineering","text":""},{"location":"blogs/category/llm-engineering/","title":"LLM Engineering","text":""},{"location":"blogs/page/2/","title":"Blogs","text":""},{"location":"blogs/archive/2025/page/2/","title":"2025","text":""}]}